{"id": "http://arxiv.org/abs/1204.1198v1", "guidislink": true, "updated": "2012-04-05T12:28:11Z", "updated_parsed": [2012, 4, 5, 12, 28, 11, 3, 96, 0], "published": "2012-04-05T12:28:11Z", "published_parsed": [2012, 4, 5, 12, 28, 11, 3, 96, 0], "title": "A Complete Workflow for Development of Bangla OCR", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Complete Workflow for Development of Bangla OCR"}, "summary": "Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required."}, "authors": ["Farjana Yeasmin Omee", "Shiam Shabbir Himel", "Md. Abu Naser Bikas"], "author_detail": {"name": "Md. Abu Naser Bikas"}, "author": "Md. Abu Naser Bikas", "links": [{"href": "http://arxiv.org/abs/1204.1198v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1204.1198v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1204.1198v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1204.1198v1", "arxiv_comment": null, "journal_reference": "International Journal of Computer Applications, Volume 21, No.9,\n  May 2011", "doi": null}
{"id": "http://arxiv.org/abs/1009.4586v1", "guidislink": true, "updated": "2010-09-23T11:42:41Z", "updated_parsed": [2010, 9, 23, 11, 42, 41, 3, 266, 0], "published": "2010-09-23T11:42:41Z", "published_parsed": [2010, 9, 23, 11, 42, 41, 3, 266, 0], "title": "Optimal Bangla Keyboard Layout using Association Rule of Data Mining", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Optimal Bangla Keyboard Layout using Association Rule of Data Mining"}, "summary": "In this paper we present an optimal Bangla Keyboard Layout, which distributes\nthe load equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Finally, we propose a Bangla Keyboard Layout. Experimental results on\nseveral keyboard layout shows the effectiveness of the proposed approach with\nbetter performance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper we present an optimal Bangla Keyboard Layout, which distributes\nthe load equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Finally, we propose a Bangla Keyboard Layout. Experimental results on\nseveral keyboard layout shows the effectiveness of the proposed approach with\nbetter performance."}, "authors": ["Md. Hijbul Alam", "Abdul Kadar Muhammad Masum", "Mohammad Mahadi Hassan", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "3 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4586v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4586v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4586v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4586v1", "journal_reference": "Proc. 7th International Conference on Computer and Information\n  Technology (ICCIT 2004), Dhaka, Bangladesh, pp. 679-681, Dec. 2004", "doi": null}
{"id": "http://arxiv.org/abs/1703.10661v1", "guidislink": true, "updated": "2017-02-22T07:57:14Z", "updated_parsed": [2017, 2, 22, 7, 57, 14, 2, 53, 0], "published": "2017-02-22T07:57:14Z", "published_parsed": [2017, 2, 22, 7, 57, 14, 2, 53, 0], "title": "BanglaLekha-Isolated: A Comprehensive Bangla Handwritten Character\n  Dataset", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaLekha-Isolated: A Comprehensive Bangla Handwritten Character\n  Dataset"}, "summary": "Bangla handwriting recognition is becoming a very important issue nowadays.\nIt is potentially a very important task specially for Bangla speaking\npopulation of Bangladesh and West Bengal. By keeping that in our mind we are\nintroducing a comprehensive Bangla handwritten character dataset named\nBanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic\ncharacters and compound characters. This dataset was collected from multiple\ngeographical location within Bangladesh and includes sample collected from a\nvariety of aged groups. This dataset can also be used for other classification\nproblems i.e: gender, age, district. This is the largest dataset on Bangla\nhandwritten characters yet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla handwriting recognition is becoming a very important issue nowadays.\nIt is potentially a very important task specially for Bangla speaking\npopulation of Bangladesh and West Bengal. By keeping that in our mind we are\nintroducing a comprehensive Bangla handwritten character dataset named\nBanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic\ncharacters and compound characters. This dataset was collected from multiple\ngeographical location within Bangladesh and includes sample collected from a\nvariety of aged groups. This dataset can also be used for other classification\nproblems i.e: gender, age, district. This is the largest dataset on Bangla\nhandwritten characters yet."}, "authors": ["Mithun Biswas", "Rafiqul Islam", "Gautam Kumar Shom", "Md Shopon", "Nabeel Mohammed", "Sifat Momen", "Md Anowarul Abedin"], "author_detail": {"name": "Md Anowarul Abedin"}, "author": "Md Anowarul Abedin", "arxiv_comment": "Bangla Handwriting Dataset, OCR", "links": [{"href": "http://arxiv.org/abs/1703.10661v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1703.10661v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1703.10661v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1703.10661v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.07955v1", "guidislink": true, "updated": "2017-01-27T06:30:21Z", "updated_parsed": [2017, 1, 27, 6, 30, 21, 4, 27, 0], "published": "2017-01-27T06:30:21Z", "published_parsed": [2017, 1, 27, 6, 30, 21, 4, 27, 0], "title": "Statistical Analysis on Bangla Newspaper Data to Extract Trending Topic\n  and Visualize Its Change Over Time", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Statistical Analysis on Bangla Newspaper Data to Extract Trending Topic\n  and Visualize Its Change Over Time"}, "summary": "Trending topic of newspapers is an indicator to understand the situation of a\ncountry and also a way to evaluate the particular newspaper. This paper\nrepresents a model describing few techniques to select trending topics from\nBangla Newspaper. Topics that are discussed more frequently than other in\nBangla newspaper will be marked and how a very famous topic loses its\nimportance with the change of time and another topic takes its place will be\ndemonstrated. Data from two popular Bangla Newspaper with date and time were\ncollected. Statistical analysis was performed after on these data after\npreprocessing. Popular and most used keywords were extracted from the stream of\nBangla keyword with this analysis. This model can also cluster category wise\nnews trend or a list of news trend in daily or weekly basis with enough data. A\npattern can be found on their news trend too. Comparison among past news trend\nof Bangla newspapers will give a visualization of the situation of Bangladesh.\nThis visualization will be helpful to predict future trending topics of Bangla\nNewspaper.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Trending topic of newspapers is an indicator to understand the situation of a\ncountry and also a way to evaluate the particular newspaper. This paper\nrepresents a model describing few techniques to select trending topics from\nBangla Newspaper. Topics that are discussed more frequently than other in\nBangla newspaper will be marked and how a very famous topic loses its\nimportance with the change of time and another topic takes its place will be\ndemonstrated. Data from two popular Bangla Newspaper with date and time were\ncollected. Statistical analysis was performed after on these data after\npreprocessing. Popular and most used keywords were extracted from the stream of\nBangla keyword with this analysis. This model can also cluster category wise\nnews trend or a list of news trend in daily or weekly basis with enough data. A\npattern can be found on their news trend too. Comparison among past news trend\nof Bangla newspapers will give a visualization of the situation of Bangladesh.\nThis visualization will be helpful to predict future trending topics of Bangla\nNewspaper."}, "authors": ["Syed Mehedi Hasan Nirob", "Md. Kazi Nayeem", "Md. Saiful Islam"], "author_detail": {"name": "Md. Saiful Islam"}, "author": "Md. Saiful Islam", "arxiv_comment": "8 pages", "links": [{"href": "http://arxiv.org/abs/1701.07955v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.07955v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.07955v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.07955v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2005.02155v2", "guidislink": true, "updated": "2020-05-06T07:59:45Z", "updated_parsed": [2020, 5, 6, 7, 59, 45, 2, 127, 0], "published": "2020-04-29T06:38:12Z", "published_parsed": [2020, 4, 29, 6, 38, 12, 2, 120, 0], "title": "MatriVasha: A Multipurpose Comprehensive Database for Bangla Handwritten\n  Compound Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "MatriVasha: A Multipurpose Comprehensive Database for Bangla Handwritten\n  Compound Characters"}, "summary": "At present, recognition of the Bangla handwriting compound character has been\nan essential issue for many years. In recent years there have been\napplication-based researches in machine learning, and deep learning, which is\ngained interest, and most notably is handwriting recognition because it has a\ntremendous application such as Bangla OCR. MatrriVasha, the project which can\nrecognize Bangla, handwritten several compound characters. Currently, compound\ncharacter recognition is an important topic due to its variant application, and\nhelps to create old forms, and information digitization with reliability. But\nunfortunately, there is a lack of a comprehensive dataset that can categorize\nall types of Bangla compound characters. MatrriVasha is an attempt to align\ncompound character, and it's challenging because each person has a unique style\nof writing shapes. After all, MatrriVasha has proposed a dataset that intends\nto recognize Bangla 120(one hundred twenty) compound characters that consist of\n2552(two thousand five hundred fifty-two) isolated handwritten characters\nwritten unique writers which were collected from within Bangladesh. This\ndataset faced problems in terms of the district, age, and gender-based written\nrelated research because the samples were collected that includes a verity of\nthe district, age group, and the equal number of males, and females. As of now,\nour proposed dataset is so far the most extensive dataset for Bangla compound\ncharacters. It is intended to frame the acknowledgment technique for\nhandwritten Bangla compound character. In the future, this dataset will be made\npublicly available to help to widen the research.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "At present, recognition of the Bangla handwriting compound character has been\nan essential issue for many years. In recent years there have been\napplication-based researches in machine learning, and deep learning, which is\ngained interest, and most notably is handwriting recognition because it has a\ntremendous application such as Bangla OCR. MatrriVasha, the project which can\nrecognize Bangla, handwritten several compound characters. Currently, compound\ncharacter recognition is an important topic due to its variant application, and\nhelps to create old forms, and information digitization with reliability. But\nunfortunately, there is a lack of a comprehensive dataset that can categorize\nall types of Bangla compound characters. MatrriVasha is an attempt to align\ncompound character, and it's challenging because each person has a unique style\nof writing shapes. After all, MatrriVasha has proposed a dataset that intends\nto recognize Bangla 120(one hundred twenty) compound characters that consist of\n2552(two thousand five hundred fifty-two) isolated handwritten characters\nwritten unique writers which were collected from within Bangladesh. This\ndataset faced problems in terms of the district, age, and gender-based written\nrelated research because the samples were collected that includes a verity of\nthe district, age group, and the equal number of males, and females. As of now,\nour proposed dataset is so far the most extensive dataset for Bangla compound\ncharacters. It is intended to frame the acknowledgment technique for\nhandwritten Bangla compound character. In the future, this dataset will be made\npublicly available to help to widen the research."}, "authors": ["Jannatul Ferdous", "Suvrajit Karmaker", "A K M Shahariar Azad Rabby", "Syed Akhter Hossain"], "author_detail": {"name": "Syed Akhter Hossain"}, "author": "Syed Akhter Hossain", "arxiv_comment": "19 fig, 2 table", "links": [{"href": "http://arxiv.org/abs/2005.02155v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2005.02155v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2005.02155v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2005.02155v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1201.2010v1", "guidislink": true, "updated": "2012-01-10T10:33:18Z", "updated_parsed": [2012, 1, 10, 10, 33, 18, 1, 10, 0], "published": "2012-01-10T10:33:18Z", "published_parsed": [2012, 1, 10, 10, 33, 18, 1, 10, 0], "title": "Recognizing Bangla Grammar using Predictive Parser", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recognizing Bangla Grammar using Predictive Parser"}, "summary": "We describe a Context Free Grammar (CFG) for Bangla language and hence we\npropose a Bangla parser based on the grammar. Our approach is very much general\nto apply in Bangla Sentences and the method is well accepted for parsing a\nlanguage of a grammar. The proposed parser is a predictive parser and we\nconstruct the parse table for recognizing Bangla grammar. Using the parse table\nwe recognize syntactical mistakes of Bangla sentences when there is no entry\nfor a terminal in the parse table. If a natural language can be successfully\nparsed then grammar checking from this language becomes possible. The proposed\nscheme is based on Top down parsing method and we have avoided the left\nrecursion of the CFG using the idea of left factoring.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "We describe a Context Free Grammar (CFG) for Bangla language and hence we\npropose a Bangla parser based on the grammar. Our approach is very much general\nto apply in Bangla Sentences and the method is well accepted for parsing a\nlanguage of a grammar. The proposed parser is a predictive parser and we\nconstruct the parse table for recognizing Bangla grammar. Using the parse table\nwe recognize syntactical mistakes of Bangla sentences when there is no entry\nfor a terminal in the parse table. If a natural language can be successfully\nparsed then grammar checking from this language becomes possible. The proposed\nscheme is based on Top down parsing method and we have avoided the left\nrecursion of the CFG using the idea of left factoring."}, "authors": ["K. M. Azharul Hasan", "Al-Mahmud", "Amit Mondal", "Amit Saha"], "author_detail": {"name": "Amit Saha"}, "author": "Amit Saha", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijcsit.2011.3605", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1201.2010v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1201.2010v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "13 pages, 13 figures", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1201.2010v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1201.2010v1", "journal_reference": null, "doi": "10.5121/ijcsit.2011.3605"}
{"id": "http://arxiv.org/abs/1203.0876v1", "guidislink": true, "updated": "2012-03-05T12:06:54Z", "updated_parsed": [2012, 3, 5, 12, 6, 54, 0, 65, 0], "published": "2012-03-05T12:06:54Z", "published_parsed": [2012, 3, 5, 12, 6, 54, 0, 65, 0], "title": "An MLP based Approach for Recognition of Handwritten `Bangla' Numerals", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An MLP based Approach for Recognition of Handwritten `Bangla' Numerals"}, "summary": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased pattern classifier for recognition of handwritten Bangla digits using a\n76 element feature vector. Bangla is the second most popular script and\nlanguage in the Indian subcontinent and the fifth most popular language in the\nworld. The feature set developed for representing handwritten Bangla numerals\nhere includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. On experimentation with a database of 6000 samples, the technique\nyields an average recognition rate of 96.67% evaluated after three-fold cross\nvalidation of results. It is useful for applications related to OCR of\nhandwritten Bangla Digit and can also be extended to include OCR of handwritten\ncharacters of Bangla alphabet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased pattern classifier for recognition of handwritten Bangla digits using a\n76 element feature vector. Bangla is the second most popular script and\nlanguage in the Indian subcontinent and the fifth most popular language in the\nworld. The feature set developed for representing handwritten Bangla numerals\nhere includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. On experimentation with a database of 6000 samples, the technique\nyields an average recognition rate of 96.67% evaluated after three-fold cross\nvalidation of results. It is useful for applications related to OCR of\nhandwritten Bangla Digit and can also be extended to include OCR of handwritten\ncharacters of Bangla alphabet."}, "authors": ["Subhadip Basu", "Nibaran Das", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1203.0876v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.0876v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.0876v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.0876v1", "arxiv_comment": null, "journal_reference": "Proc. 2nd Indian International Conference on Artificial\n  Intelligence, pp. 407-417, Dec. 2005, Pune", "doi": null}
{"id": "http://arxiv.org/abs/1203.0882v1", "guidislink": true, "updated": "2012-03-05T12:22:23Z", "updated_parsed": [2012, 3, 5, 12, 22, 23, 0, 65, 0], "published": "2012-03-05T12:22:23Z", "published_parsed": [2012, 3, 5, 12, 22, 23, 0, 65, 0], "title": "Handwritten Bangla Alphabet Recognition using an MLP Based Classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Alphabet Recognition using an MLP Based Classifier"}, "summary": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased classifier for recognition of handwritten Bangla alphabet using a 76\nelement feature set Bangla is the second most popular script and language in\nthe Indian subcontinent and the fifth most popular language in the world. The\nfeature set developed for representing handwritten characters of Bangla\nalphabet includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. Recognition performances of the MLP designed to work with this\nfeature set are experimentally observed as 86.46% and 75.05% on the samples of\nthe training and the test sets respectively. The work has useful application in\nthe development of a complete OCR system for handwritten Bangla text.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased classifier for recognition of handwritten Bangla alphabet using a 76\nelement feature set Bangla is the second most popular script and language in\nthe Indian subcontinent and the fifth most popular language in the world. The\nfeature set developed for representing handwritten characters of Bangla\nalphabet includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. Recognition performances of the MLP designed to work with this\nfeature set are experimentally observed as 86.46% and 75.05% on the samples of\nthe training and the test sets respectively. The work has useful application in\nthe development of a complete OCR system for handwritten Bangla text."}, "authors": ["Subhadip Basu", "Nibaran Das", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1203.0882v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.0882v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.0882v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.0882v1", "arxiv_comment": null, "journal_reference": "Proc. of the 2nd National Conf. on Computer Processing of Bangla,\n  pp. 285-291, Feb-2005, Dhaka", "doi": null}
{"id": "http://arxiv.org/abs/1410.2045v1", "guidislink": true, "updated": "2014-10-08T10:01:47Z", "updated_parsed": [2014, 10, 8, 10, 1, 47, 2, 281, 0], "published": "2014-10-08T10:01:47Z", "published_parsed": [2014, 10, 8, 10, 1, 47, 2, 281, 0], "title": "Supervised learning Methods for Bangla Web Document Categorization", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Supervised learning Methods for Bangla Web Document Categorization"}, "summary": "This paper explores the use of machine learning approaches, or more\nspecifically, four supervised learning Methods, namely Decision Tree(C 4.5),\nK-Nearest Neighbour (KNN), Na\\\"ive Bays (NB), and Support Vector Machine (SVM)\nfor categorization of Bangla web documents. This is a task of automatically\nsorting a set of documents into categories from a predefined set. Whereas a\nwide range of methods have been applied to English text categorization,\nrelatively few studies have been conducted on Bangla language text\ncategorization. Hence, we attempt to analyze the efficiency of those four\nmethods for categorization of Bangla documents. In order to validate, Bangla\ncorpus from various websites has been developed and used as examples for the\nexperiment. For Bangla, empirical results support that all four methods produce\nsatisfactory performance with SVM attaining good result in terms of high\ndimensional and relatively noisy document feature vectors.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper explores the use of machine learning approaches, or more\nspecifically, four supervised learning Methods, namely Decision Tree(C 4.5),\nK-Nearest Neighbour (KNN), Na\\\"ive Bays (NB), and Support Vector Machine (SVM)\nfor categorization of Bangla web documents. This is a task of automatically\nsorting a set of documents into categories from a predefined set. Whereas a\nwide range of methods have been applied to English text categorization,\nrelatively few studies have been conducted on Bangla language text\ncategorization. Hence, we attempt to analyze the efficiency of those four\nmethods for categorization of Bangla documents. In order to validate, Bangla\ncorpus from various websites has been developed and used as examples for the\nexperiment. For Bangla, empirical results support that all four methods produce\nsatisfactory performance with SVM attaining good result in terms of high\ndimensional and relatively noisy document feature vectors."}, "authors": ["Ashis Kumar Mandal", "Rikta Sen"], "author_detail": {"name": "Rikta Sen"}, "author": "Rikta Sen", "arxiv_comment": "13 pages, International Journal of Artificial Intelligence &\n  Applications (IJAIA), Vol. 5, No. 5, September 2014", "links": [{"href": "http://arxiv.org/abs/1410.2045v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.2045v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.2045v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.2045v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1009.4982v1", "guidislink": true, "updated": "2010-09-25T06:55:27Z", "updated_parsed": [2010, 9, 25, 6, 55, 27, 5, 268, 0], "published": "2010-09-25T06:55:27Z", "published_parsed": [2010, 9, 25, 6, 55, 27, 5, 268, 0], "title": "Optimal Bangla Keyboard Layout using Data Mining Technique", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Optimal Bangla Keyboard Layout using Data Mining Technique"}, "summary": "This paper presents an optimal Bangla Keyboard Layout, which distributes the\nload equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Experimental results on several data show the effectiveness of the\nproposed approach with better performance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents an optimal Bangla Keyboard Layout, which distributes the\nload equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Experimental results on several data show the effectiveness of the\nproposed approach with better performance."}, "authors": ["S. M. Kamruzzaman", "Md. Hijbul Alam", "Abdul Kadar Muhammad Masum", "Md. Mahadi Hassan"], "author_detail": {"name": "Md. Mahadi Hassan"}, "author": "Md. Mahadi Hassan", "arxiv_comment": "9 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4982v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4982v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4982v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4982v1", "journal_reference": "Proc. International Conference on Information and Communication\n  Technology in Management (ICTM 2005), Multimedia University, Malaysia, May\n  2005", "doi": null}
{"id": "http://arxiv.org/abs/1009.5048v1", "guidislink": true, "updated": "2010-09-26T02:09:41Z", "updated_parsed": [2010, 9, 26, 2, 9, 41, 6, 269, 0], "published": "2010-09-26T02:09:41Z", "published_parsed": [2010, 9, 26, 2, 9, 41, 6, 269, 0], "title": "The Most Advantageous Bangla Keyboard Layout Using Data Mining Technique", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The Most Advantageous Bangla Keyboard Layout Using Data Mining Technique"}, "summary": "Bangla alphabet has a large number of letters, for this it is complicated to\ntype faster using Bangla keyboard. The proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Association rule\nof data mining to distribute the Bangla characters in the keyboard is used\nhere. The frequencies of data consisting of monograph, digraph and trigraph are\nanalyzed, which are derived from data wire-house, and then used association\nrule of data mining to distribute the Bangla characters in the layout.\nExperimental results on several data show the effectiveness of the proposed\napproach with better performance. This paper presents an optimal Bangla\nKeyboard Layout, which distributes the load equally on both hands so that\nmaximizing the ease and minimizing the effort.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla alphabet has a large number of letters, for this it is complicated to\ntype faster using Bangla keyboard. The proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Association rule\nof data mining to distribute the Bangla characters in the keyboard is used\nhere. The frequencies of data consisting of monograph, digraph and trigraph are\nanalyzed, which are derived from data wire-house, and then used association\nrule of data mining to distribute the Bangla characters in the layout.\nExperimental results on several data show the effectiveness of the proposed\napproach with better performance. This paper presents an optimal Bangla\nKeyboard Layout, which distributes the load equally on both hands so that\nmaximizing the ease and minimizing the effort."}, "authors": ["Abdul Kadar Muhammad Masum", "Mohammad Mahadi Hassan", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "10 Pages, International Journal", "links": [{"href": "http://arxiv.org/abs/1009.5048v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.5048v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.5048v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.5048v1", "journal_reference": "Journal of Computer Science, IBAIS University, Dkhaka, Bangladesh,\n  Vol. 1, No. 2, Dec. 2007", "doi": null}
{"id": "http://arxiv.org/abs/1002.4040v2", "guidislink": true, "updated": "2010-02-23T06:44:32Z", "updated_parsed": [2010, 2, 23, 6, 44, 32, 1, 54, 0], "published": "2010-02-22T02:58:49Z", "published_parsed": [2010, 2, 22, 2, 58, 49, 0, 53, 0], "title": "Handwritten Bangla Basic and Compound character recognition using MLP\n  and SVM classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Basic and Compound character recognition using MLP\n  and SVM classifier"}, "summary": "A novel approach for recognition of handwritten compound Bangla characters,\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\nto English like Roman script, one of the major stumbling blocks in Optical\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\ncharacter classes, there are nearly 160 complex shaped compound character\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\ncharacters with a suitably designed feature set is a challenging problem.\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\na large varieties of complex shaped characters, some of which have close\nresemblance, makes the problem of OCR of handwritten Bangla characters more\ndifficult. Considering the complexity of the problem, the present approach\nmakes an attempt to identify compound character classes from most frequently to\nless frequently occurred ones, i.e., in order of importance. This is to develop\na frame work for incrementally increasing the number of learned classes of\ncompound characters from more frequently occurred ones to less frequently\noccurred ones along with Basic characters. On experimentation, the technique is\nobserved produce an average recognition rate of 79.25 after three fold cross\nvalidation of data with future scope of improvement and extension.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A novel approach for recognition of handwritten compound Bangla characters,\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\nto English like Roman script, one of the major stumbling blocks in Optical\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\ncharacter classes, there are nearly 160 complex shaped compound character\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\ncharacters with a suitably designed feature set is a challenging problem.\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\na large varieties of complex shaped characters, some of which have close\nresemblance, makes the problem of OCR of handwritten Bangla characters more\ndifficult. Considering the complexity of the problem, the present approach\nmakes an attempt to identify compound character classes from most frequently to\nless frequently occurred ones, i.e., in order of importance. This is to develop\na frame work for incrementally increasing the number of learned classes of\ncompound characters from more frequently occurred ones to less frequently\noccurred ones along with Basic characters. On experimentation, the technique is\nobserved produce an average recognition rate of 79.25 after three fold cross\nvalidation of data with future scope of improvement and extension."}, "authors": ["Nibaran Das", "Bindaban Das", "Ram Sarkar", "Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/1002.4040v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.4040v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.4040v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1002.4040v2", "arxiv_comment": null, "journal_reference": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null}
{"id": "http://arxiv.org/abs/1410.0478v1", "guidislink": true, "updated": "2014-10-02T08:26:38Z", "updated_parsed": [2014, 10, 2, 8, 26, 38, 3, 275, 0], "published": "2014-10-02T08:26:38Z", "published_parsed": [2014, 10, 2, 8, 26, 38, 3, 275, 0], "title": "Recognition of Handwritten Bangla Basic Characters and Digits using\n  Convex Hull based Feature Set", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recognition of Handwritten Bangla Basic Characters and Digits using\n  Convex Hull based Feature Set"}, "summary": "In dealing with the problem of recognition of handwritten character patterns\nof varying shapes and sizes, selection of a proper feature set is important to\nachieve high recognition performance. The current research aims to evaluate the\nperformance of the convex hull based feature set, i.e. 125 features in all\ncomputed over different bays attributes of the convex hull of a pattern, for\neffective recognition of isolated handwritten Bangla basic characters and\ndigits. On experimentation with a database of 10000 samples, the maximum\nrecognition rate of 76.86% is observed for handwritten Bangla characters. For\nBangla numerals the maximum success rate of 99.45%. is achieved on a database\nof 12000 sample. The current work validates the usefulness of a new kind of\nfeature set for recognition of handwritten Bangla basic characters and\nnumerals.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In dealing with the problem of recognition of handwritten character patterns\nof varying shapes and sizes, selection of a proper feature set is important to\nachieve high recognition performance. The current research aims to evaluate the\nperformance of the convex hull based feature set, i.e. 125 features in all\ncomputed over different bays attributes of the convex hull of a pattern, for\neffective recognition of isolated handwritten Bangla basic characters and\ndigits. On experimentation with a database of 10000 samples, the maximum\nrecognition rate of 76.86% is observed for handwritten Bangla characters. For\nBangla numerals the maximum success rate of 99.45%. is achieved on a database\nof 12000 sample. The current work validates the usefulness of a new kind of\nfeature set for recognition of handwritten Bangla basic characters and\nnumerals."}, "authors": ["Nibaran Das", "Sandip Pramanik", "Subhadip Basu", "Punam Kumar Saha", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"title": "doi", "href": "http://dx.doi.org/10.13140/2.1.3689.4089", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1410.0478v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.0478v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.0478v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.0478v1", "arxiv_comment": null, "journal_reference": "2009 International Conference on Artificial Intelligence and\n  Pattern Recognition, At Orlando, Florida pp. 380-386", "doi": "10.13140/2.1.3689.4089"}
{"id": "http://arxiv.org/abs/1701.08702v1", "guidislink": true, "updated": "2017-01-27T18:43:31Z", "updated_parsed": [2017, 1, 27, 18, 43, 31, 4, 27, 0], "published": "2017-01-27T18:43:31Z", "published_parsed": [2017, 1, 27, 18, 43, 31, 4, 27, 0], "title": "Bangla Word Clustering Based on Tri-gram, 4-gram and 5-gram Language\n  Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Word Clustering Based on Tri-gram, 4-gram and 5-gram Language\n  Model"}, "summary": "In this paper, we describe a research method that generates Bangla word\nclusters on the basis of relating to meaning in language and contextual\nsimilarity. The importance of word clustering is in parts of speech (POS)\ntagging, word sense disambiguation, text classification, recommender system,\nspell checker, grammar checker, knowledge discover and for many others Natural\nLanguage Processing (NLP) applications. In the history of word clustering,\nEnglish and some other languages have already implemented some methods on word\nclustering efficiently. But due to lack of the resources, word clustering in\nBangla has not been still implemented efficiently. Presently, its\nimplementation is in the beginning stage. In some research of word clustering\nin English based on preceding and next five words of a key word they found an\nefficient result. Now, we are trying to implement the tri-gram, 4-gram and\n5-gram model of word clustering for Bangla to observe which one is the best\namong them. We have started our research with quite a large corpus of\napproximate 1 lakh Bangla words. We are using a machine learning technique in\nthis research. We will generate word clusters and analyze the clusters by\ntesting some different threshold values.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we describe a research method that generates Bangla word\nclusters on the basis of relating to meaning in language and contextual\nsimilarity. The importance of word clustering is in parts of speech (POS)\ntagging, word sense disambiguation, text classification, recommender system,\nspell checker, grammar checker, knowledge discover and for many others Natural\nLanguage Processing (NLP) applications. In the history of word clustering,\nEnglish and some other languages have already implemented some methods on word\nclustering efficiently. But due to lack of the resources, word clustering in\nBangla has not been still implemented efficiently. Presently, its\nimplementation is in the beginning stage. In some research of word clustering\nin English based on preceding and next five words of a key word they found an\nefficient result. Now, we are trying to implement the tri-gram, 4-gram and\n5-gram model of word clustering for Bangla to observe which one is the best\namong them. We have started our research with quite a large corpus of\napproximate 1 lakh Bangla words. We are using a machine learning technique in\nthis research. We will generate word clusters and analyze the clusters by\ntesting some different threshold values."}, "authors": ["Dipaloke Saha", "Md Saddam Hossain", "MD. Saiful Islam", "Sabir Ismail"], "author_detail": {"name": "Sabir Ismail"}, "author": "Sabir Ismail", "arxiv_comment": "6 pages", "links": [{"href": "http://arxiv.org/abs/1701.08702v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08702v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08702v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08702v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1809.00339v1", "guidislink": true, "updated": "2018-09-02T14:03:30Z", "updated_parsed": [2018, 9, 2, 14, 3, 30, 6, 245, 0], "published": "2018-09-02T14:03:30Z", "published_parsed": [2018, 9, 2, 14, 3, 30, 6, 245, 0], "title": "Chittron: An Automatic Bangla Image Captioning System", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Chittron: An Automatic Bangla Image Captioning System"}, "summary": "Automatic image caption generation aims to produce an accurate description of\nan image in natural language automatically. However, Bangla, the fifth most\nwidely spoken language in the world, is lagging considerably in the research\nand development of such domain. Besides, while there are many established data\nsets to related to image annotation in English, no such resource exists for\nBangla yet. Hence, this paper outlines the development of \"Chittron\", an\nautomatic image captioning system in Bangla. Moreover, to address the data set\navailability issue, a collection of 16,000 Bangladeshi contextual images has\nbeen accumulated and manually annotated in Bangla. This data set is then used\nto train a model which integrates a pre-trained VGG16 image embedding model\nwith stacked LSTM layers. The model is trained to predict the caption when the\ninput is an image, one word at a time. The results show that the model has\nsuccessfully been able to learn a working language model and to generate\ncaptions of images quite accurately in many cases. The results are evaluated\nmainly qualitatively. However, BLEU scores are also reported. It is expected\nthat a better result can be obtained with a bigger and more varied data set.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic image caption generation aims to produce an accurate description of\nan image in natural language automatically. However, Bangla, the fifth most\nwidely spoken language in the world, is lagging considerably in the research\nand development of such domain. Besides, while there are many established data\nsets to related to image annotation in English, no such resource exists for\nBangla yet. Hence, this paper outlines the development of \"Chittron\", an\nautomatic image captioning system in Bangla. Moreover, to address the data set\navailability issue, a collection of 16,000 Bangladeshi contextual images has\nbeen accumulated and manually annotated in Bangla. This data set is then used\nto train a model which integrates a pre-trained VGG16 image embedding model\nwith stacked LSTM layers. The model is trained to predict the caption when the\ninput is an image, one word at a time. The results show that the model has\nsuccessfully been able to learn a working language model and to generate\ncaptions of images quite accurately in many cases. The results are evaluated\nmainly qualitatively. However, BLEU scores are also reported. It is expected\nthat a better result can be obtained with a bigger and more varied data set."}, "authors": ["Motiur Rahman", "Nabeel Mohammed", "Nafees Mansoor", "Sifat Momen"], "author_detail": {"name": "Sifat Momen"}, "author": "Sifat Momen", "links": [{"href": "http://arxiv.org/abs/1809.00339v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1809.00339v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1809.00339v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1809.00339v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1401.1190v1", "guidislink": true, "updated": "2014-01-06T20:25:26Z", "updated_parsed": [2014, 1, 6, 20, 25, 26, 0, 6, 0], "published": "2014-01-06T20:25:26Z", "published_parsed": [2014, 1, 6, 20, 25, 26, 0, 6, 0], "title": "Bangla Text Recognition from Video Sequence: A New Focus", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Text Recognition from Video Sequence: A New Focus"}, "summary": "Extraction and recognition of Bangla text from video frame images is\nchallenging due to complex color background, low-resolution etc. In this paper,\nwe propose an algorithm for extraction and recognition of Bangla text form such\nvideo frames with complex background. Here, a two-step approach has been\nproposed. First, the text line is segmented into words using information based\non line contours. First order gradient value of the text blocks are used to\nfind the word gap. Next, a local binarization technique is applied on each word\nand text line is reconstructed using those words. Secondly, this binarized text\nblock is sent to OCR for recognition purpose.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Extraction and recognition of Bangla text from video frame images is\nchallenging due to complex color background, low-resolution etc. In this paper,\nwe propose an algorithm for extraction and recognition of Bangla text form such\nvideo frames with complex background. Here, a two-step approach has been\nproposed. First, the text line is segmented into words using information based\non line contours. First order gradient value of the text blocks are used to\nfind the word gap. Next, a local binarization technique is applied on each word\nand text line is reconstructed using those words. Secondly, this binarized text\nblock is sent to OCR for recognition purpose."}, "authors": ["Souvik Bhowmick", "Purnendu Banerjee"], "author_detail": {"name": "Purnendu Banerjee"}, "author": "Purnendu Banerjee", "links": [{"href": "http://arxiv.org/abs/1401.1190v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1401.1190v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1401.1190v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1401.1190v1", "arxiv_comment": null, "journal_reference": "NATIONAL CONFERENCE ON COMPUTING AND SYSTEMS (NaCCS), pp.\n  62-67,2012", "doi": null}
{"id": "http://arxiv.org/abs/1610.00369v2", "guidislink": true, "updated": "2016-11-24T02:13:05Z", "updated_parsed": [2016, 11, 24, 2, 13, 5, 3, 329, 0], "published": "2016-10-02T23:45:23Z", "published_parsed": [2016, 10, 2, 23, 45, 23, 6, 276, 0], "title": "Sentiment Analysis on Bangla and Romanized Bangla Text (BRBT) using Deep\n  Recurrent models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Analysis on Bangla and Romanized Bangla Text (BRBT) using Deep\n  Recurrent models"}, "summary": "Sentiment Analysis (SA) is an action research area in the digital age. With\nrapid and constant growth of online social media sites and services, and the\nincreasing amount of textual data such as - statuses, comments, reviews etc.\navailable in them, application of automatic SA is on the rise. However, most of\nthe research works on SA in natural language processing (NLP) are based on\nEnglish language. Despite being the sixth most widely spoken language in the\nworld, Bangla still does not have a large and standard dataset. Because of\nthis, recent research works in Bangla have failed to produce results that can\nbe both comparable to works done by others and reusable as stepping stones for\nfuture researchers to progress in this field. Therefore, we first tried to\nprovide a textual dataset - that includes not just Bangla, but Romanized Bangla\ntexts as well, is substantial, post-processed and multiple validated, ready to\nbe used in SA experiments. We tested this dataset in Deep Recurrent model,\nspecifically, Long Short Term Memory (LSTM), using two types of loss functions\n- binary crossentropy and categorical crossentropy, and also did some\nexperimental pre-training by using data from one validation to pre-train the\nother and vice versa. Lastly, we documented the results along with some\nanalysis on them, which were promising.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Analysis (SA) is an action research area in the digital age. With\nrapid and constant growth of online social media sites and services, and the\nincreasing amount of textual data such as - statuses, comments, reviews etc.\navailable in them, application of automatic SA is on the rise. However, most of\nthe research works on SA in natural language processing (NLP) are based on\nEnglish language. Despite being the sixth most widely spoken language in the\nworld, Bangla still does not have a large and standard dataset. Because of\nthis, recent research works in Bangla have failed to produce results that can\nbe both comparable to works done by others and reusable as stepping stones for\nfuture researchers to progress in this field. Therefore, we first tried to\nprovide a textual dataset - that includes not just Bangla, but Romanized Bangla\ntexts as well, is substantial, post-processed and multiple validated, ready to\nbe used in SA experiments. We tested this dataset in Deep Recurrent model,\nspecifically, Long Short Term Memory (LSTM), using two types of loss functions\n- binary crossentropy and categorical crossentropy, and also did some\nexperimental pre-training by using data from one validation to pre-train the\nother and vice versa. Lastly, we documented the results along with some\nanalysis on them, which were promising."}, "authors": ["A. Hassan", "M. R. Amin", "N. Mohammed", "A. K. A. Azad"], "author_detail": {"name": "A. K. A. Azad"}, "author": "A. K. A. Azad", "links": [{"href": "http://arxiv.org/abs/1610.00369v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1610.00369v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1610.00369v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1610.00369v2", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1705.02680v1", "guidislink": true, "updated": "2017-05-07T18:49:27Z", "updated_parsed": [2017, 5, 7, 18, 49, 27, 6, 127, 0], "published": "2017-05-07T18:49:27Z", "published_parsed": [2017, 5, 7, 18, 49, 27, 6, 127, 0], "title": "Handwritten Bangla Digit Recognition Using Deep Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Digit Recognition Using Deep Learning"}, "summary": "In spite of the advances in pattern recognition technology, Handwritten\nBangla Character Recognition (HBCR) (such as alpha-numeric and special\ncharacters) remains largely unsolved due to the presence of many perplexing\ncharacters and excessive cursive in Bangla handwriting. Even the best existing\nrecognizers do not lead to satisfactory performance for practical applications.\nTo improve the performance of Handwritten Bangla Digit Recognition (HBDR), we\nherein present a new approach based on deep neural networks which have recently\nshown excellent performance in many pattern recognition and machine learning\napplications, but has not been throughly attempted for HBDR. We introduce\nBangla digit recognition techniques based on Deep Belief Network (DBN),\nConvolutional Neural Networks (CNN), CNN with dropout, CNN with dropout and\nGaussian filters, and CNN with dropout and Gabor filters. These networks have\nthe advantage of extracting and using feature information, improving the\nrecognition of two dimensional shapes with a high degree of invariance to\ntranslation, scaling and other pattern distortions. We systematically evaluated\nthe performance of our method on publicly available Bangla numeral image\ndatabase named CMATERdb 3.1.1. From experiments, we achieved 98.78% recognition\nrate using the proposed method: CNN with Gabor features and dropout, which\noutperforms the state-of-the-art algorithms for HDBR.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In spite of the advances in pattern recognition technology, Handwritten\nBangla Character Recognition (HBCR) (such as alpha-numeric and special\ncharacters) remains largely unsolved due to the presence of many perplexing\ncharacters and excessive cursive in Bangla handwriting. Even the best existing\nrecognizers do not lead to satisfactory performance for practical applications.\nTo improve the performance of Handwritten Bangla Digit Recognition (HBDR), we\nherein present a new approach based on deep neural networks which have recently\nshown excellent performance in many pattern recognition and machine learning\napplications, but has not been throughly attempted for HBDR. We introduce\nBangla digit recognition techniques based on Deep Belief Network (DBN),\nConvolutional Neural Networks (CNN), CNN with dropout, CNN with dropout and\nGaussian filters, and CNN with dropout and Gabor filters. These networks have\nthe advantage of extracting and using feature information, improving the\nrecognition of two dimensional shapes with a high degree of invariance to\ntranslation, scaling and other pattern distortions. We systematically evaluated\nthe performance of our method on publicly available Bangla numeral image\ndatabase named CMATERdb 3.1.1. From experiments, we achieved 98.78% recognition\nrate using the proposed method: CNN with Gabor features and dropout, which\noutperforms the state-of-the-art algorithms for HDBR."}, "authors": ["Md Zahangir Alom", "Paheding Sidike", "Tarek M. Taha", "Vijayan K. Asari"], "author_detail": {"name": "Vijayan K. Asari"}, "author": "Vijayan K. Asari", "arxiv_comment": "12 pages, 10 figures, 3 tables", "links": [{"href": "http://arxiv.org/abs/1705.02680v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1705.02680v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1705.02680v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1705.02680v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1208.0995v1", "guidislink": true, "updated": "2012-08-05T09:22:06Z", "updated_parsed": [2012, 8, 5, 9, 22, 6, 6, 218, 0], "published": "2012-08-05T09:22:06Z", "published_parsed": [2012, 8, 5, 9, 22, 6, 6, 218, 0], "title": "Design and implementation of a digital clock showing digits in Bangla\n  font using microcontroller AT89C4051", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Design and implementation of a digital clock showing digits in Bangla\n  font using microcontroller AT89C4051"}, "summary": "In this paper, a digital clock is designed where the microcontroller is used\nfor timing controller and the font of the Bangla digits are designed, and\nprogrammed within the microcontroller. The design is cost effective, simple and\neasy for maintenance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, a digital clock is designed where the microcontroller is used\nfor timing controller and the font of the Bangla digits are designed, and\nprogrammed within the microcontroller. The design is cost effective, simple and\neasy for maintenance."}, "authors": ["Nasif Muslim", "Md. Tanvir Adnan", "Mohammad Zahidul Kabir", "Md. Humayun Kabir", "Sheikh Mominul Islam"], "author_detail": {"name": "Sheikh Mominul Islam"}, "author": "Sheikh Mominul Islam", "links": [{"href": "http://arxiv.org/abs/1208.0995v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1208.0995v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1208.0995v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1208.0995v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1308.3785v1", "guidislink": true, "updated": "2013-08-17T14:04:00Z", "updated_parsed": [2013, 8, 17, 14, 4, 0, 5, 229, 0], "published": "2013-08-17T14:04:00Z", "published_parsed": [2013, 8, 17, 14, 4, 0, 5, 229, 0], "title": "Implementation Of Back-Propagation Neural Network For Isolated Bangla\n  Speech Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Implementation Of Back-Propagation Neural Network For Isolated Bangla\n  Speech Recognition"}, "summary": "This paper is concerned with the development of Back-propagation Neural\nNetwork for Bangla Speech Recognition. In this paper, ten bangla digits were\nrecorded from ten speakers and have been recognized. The features of these\nspeech digits were extracted by the method of Mel Frequency Cepstral\nCoefficient (MFCC) analysis. The mfcc features of five speakers were used to\ntrain the network with Back propagation algorithm. The mfcc features of ten\nbangla digit speeches, from 0 to 9, of another five speakers were used to test\nthe system. All the methods and algorithms used in this research were\nimplemented using the features of Turbo C and C++ languages. From our\ninvestigation it is seen that the developed system can successfully encode and\nanalyze the mfcc features of the speech signal to recognition. The developed\nsystem achieved recognition rate about 96.332% for known speakers (i.e.,\nspeaker dependent) and 92% for unknown speakers (i.e., speaker independent).", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper is concerned with the development of Back-propagation Neural\nNetwork for Bangla Speech Recognition. In this paper, ten bangla digits were\nrecorded from ten speakers and have been recognized. The features of these\nspeech digits were extracted by the method of Mel Frequency Cepstral\nCoefficient (MFCC) analysis. The mfcc features of five speakers were used to\ntrain the network with Back propagation algorithm. The mfcc features of ten\nbangla digit speeches, from 0 to 9, of another five speakers were used to test\nthe system. All the methods and algorithms used in this research were\nimplemented using the features of Turbo C and C++ languages. From our\ninvestigation it is seen that the developed system can successfully encode and\nanalyze the mfcc features of the speech signal to recognition. The developed\nsystem achieved recognition rate about 96.332% for known speakers (i.e.,\nspeaker dependent) and 92% for unknown speakers (i.e., speaker independent)."}, "authors": ["Md. Ali Hossain", "Md. Mijanur Rahman", "Uzzal Kumar Prodhan", "Md. Farukuzzaman Khan"], "author_detail": {"name": "Md. Farukuzzaman Khan"}, "author": "Md. Farukuzzaman Khan", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijist.2013.3401", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1308.3785v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1308.3785v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "9 pages, 3 figures, 1 table", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1308.3785v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1308.3785v1", "journal_reference": "International Journal of Information Sciences and Techniques\n  (IJIST) Vol.3, No.4, July 2013", "doi": "10.5121/ijist.2013.3401"}
{"id": "http://arxiv.org/abs/1003.5897v1", "guidislink": true, "updated": "2010-03-30T18:54:57Z", "updated_parsed": [2010, 3, 30, 18, 54, 57, 1, 89, 0], "published": "2010-03-30T18:54:57Z", "published_parsed": [2010, 3, 30, 18, 54, 57, 1, 89, 0], "title": "Development of a Multi-User Recognition Engine for Handwritten Bangla\n  Basic Characters and Digits", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Development of a Multi-User Recognition Engine for Handwritten Bangla\n  Basic Characters and Digits"}, "summary": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset."}, "authors": ["Sandip Rakshit", "Debkumar Ghosal", "Tanmoy Das", "Subhrajit Dutta", "Subhadip Basu"], "author_detail": {"name": "Subhadip Basu"}, "author": "Subhadip Basu", "arxiv_comment": "Proc. (CD) Int. Conf. on Information Technology and Business\n  Intelligence (2009)", "links": [{"href": "http://arxiv.org/abs/1003.5897v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1003.5897v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1003.5897v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1003.5897v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1602.07803v1", "guidislink": true, "updated": "2016-02-25T05:35:16Z", "updated_parsed": [2016, 2, 25, 5, 35, 16, 3, 56, 0], "published": "2016-02-25T05:35:16Z", "published_parsed": [2016, 2, 25, 5, 35, 16, 3, 56, 0], "title": "Automated Word Prediction in Bangla Language Using Stochastic Language\n  Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automated Word Prediction in Bangla Language Using Stochastic Language\n  Models"}, "summary": "Word completion and word prediction are two important phenomena in typing\nthat benefit users who type using keyboard or other similar devices. They can\nhave profound impact on the typing of disable people. Our work is based on word\nprediction on Bangla sentence by using stochastic, i.e. N-gram language model\nsuch as unigram, bigram, trigram, deleted Interpolation and backoff models for\nauto completing a sentence by predicting a correct word in a sentence which\nsaves time and keystrokes of typing and also reduces misspelling. We use large\ndata corpus of Bangla language of different word types to predict correct word\nwith the accuracy as much as possible. We have found promising results. We hope\nthat our work will impact on the baseline for automated Bangla typing.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word completion and word prediction are two important phenomena in typing\nthat benefit users who type using keyboard or other similar devices. They can\nhave profound impact on the typing of disable people. Our work is based on word\nprediction on Bangla sentence by using stochastic, i.e. N-gram language model\nsuch as unigram, bigram, trigram, deleted Interpolation and backoff models for\nauto completing a sentence by predicting a correct word in a sentence which\nsaves time and keystrokes of typing and also reduces misspelling. We use large\ndata corpus of Bangla language of different word types to predict correct word\nwith the accuracy as much as possible. We have found promising results. We hope\nthat our work will impact on the baseline for automated Bangla typing."}, "authors": ["Md. Masudul Haque", "Md. Tarek Habib", "Md. Mokhlesur Rahman"], "author_detail": {"name": "Md. Mokhlesur Rahman"}, "author": "Md. Mokhlesur Rahman", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijfcst.2015.5607", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1602.07803v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1602.07803v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "in International Journal in Foundations of Computer Science &\n  Technology (IJFCST) Vol.5, No.6, November 2015", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1602.07803v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1602.07803v1", "journal_reference": null, "doi": "10.5121/ijfcst.2015.5607"}
{"id": "http://arxiv.org/abs/1310.1590v1", "guidislink": true, "updated": "2013-10-06T14:37:05Z", "updated_parsed": [2013, 10, 6, 14, 37, 5, 6, 279, 0], "published": "2013-10-06T14:37:05Z", "published_parsed": [2013, 10, 6, 14, 37, 5, 6, 279, 0], "title": "Evolution of the Modern Phase of Written Bangla: A Statistical Study", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Evolution of the Modern Phase of Written Bangla: A Statistical Study"}, "summary": "Active languages such as Bangla (or Bengali) evolve over time due to a\nvariety of social, cultural, economic, and political issues. In this paper, we\nanalyze the change in the written form of the modern phase of Bangla\nquantitatively in terms of character-level, syllable-level, morpheme-level and\nword-level features. We collect three different types of corpora---classical,\nnewspapers and blogs---and test whether the differences in their features are\nstatistically significant. Results suggest that there are significant changes\nin the length of a word when measured in terms of characters, but there is not\nmuch difference in usage of different characters, syllables and morphemes in a\nword or of different words in a sentence. To the best of our knowledge, this is\nthe first work on Bangla of this kind.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Active languages such as Bangla (or Bengali) evolve over time due to a\nvariety of social, cultural, economic, and political issues. In this paper, we\nanalyze the change in the written form of the modern phase of Bangla\nquantitatively in terms of character-level, syllable-level, morpheme-level and\nword-level features. We collect three different types of corpora---classical,\nnewspapers and blogs---and test whether the differences in their features are\nstatistically significant. Results suggest that there are significant changes\nin the length of a word when measured in terms of characters, but there is not\nmuch difference in usage of different characters, syllables and morphemes in a\nword or of different words in a sentence. To the best of our knowledge, this is\nthe first work on Bangla of this kind."}, "authors": ["Paheli Bhattacharya", "Arnab Bhattacharya"], "author_detail": {"name": "Arnab Bhattacharya"}, "author": "Arnab Bhattacharya", "arxiv_comment": "LCC 2013", "links": [{"href": "http://arxiv.org/abs/1310.1590v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1310.1590v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1310.1590v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1310.1590v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1809.00905v1", "guidislink": true, "updated": "2018-09-04T11:55:34Z", "updated_parsed": [2018, 9, 4, 11, 55, 34, 1, 247, 0], "published": "2018-09-04T11:55:34Z", "published_parsed": [2018, 9, 4, 11, 55, 34, 1, 247, 0], "title": "Bangla License Plate Recognition Using Convolutional Neural Networks\n  (CNN)", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla License Plate Recognition Using Convolutional Neural Networks\n  (CNN)"}, "summary": "In the last few years, the deep learning technique in particular\nConvolutional Neural Networks (CNNs) is using massively in the field of\ncomputer vision and machine learning. This deep learning technique provides\nstate-of-the-art accuracy in different classification, segmentation, and\ndetection tasks on different benchmarks such as MNIST, CIFAR-10, CIFAR-100,\nMicrosoft COCO, and ImageNet. However, there are a lot of research has been\nconducted for Bangla License plate recognition with traditional machine\nlearning approaches in last decade. None of them are used to deploy a physical\nsystem for Bangla License Plate Recognition System (BLPRS) due to their poor\nrecognition accuracy. In this paper, we have implemented CNNs based Bangla\nlicense plate recognition system with better accuracy that can be applied for\ndifferent purposes including roadside assistance, automatic parking lot\nmanagement system, vehicle license status detection and so on. Along with that,\nwe have also created and released a very first and standard database for BLPRS.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In the last few years, the deep learning technique in particular\nConvolutional Neural Networks (CNNs) is using massively in the field of\ncomputer vision and machine learning. This deep learning technique provides\nstate-of-the-art accuracy in different classification, segmentation, and\ndetection tasks on different benchmarks such as MNIST, CIFAR-10, CIFAR-100,\nMicrosoft COCO, and ImageNet. However, there are a lot of research has been\nconducted for Bangla License plate recognition with traditional machine\nlearning approaches in last decade. None of them are used to deploy a physical\nsystem for Bangla License Plate Recognition System (BLPRS) due to their poor\nrecognition accuracy. In this paper, we have implemented CNNs based Bangla\nlicense plate recognition system with better accuracy that can be applied for\ndifferent purposes including roadside assistance, automatic parking lot\nmanagement system, vehicle license status detection and so on. Along with that,\nwe have also created and released a very first and standard database for BLPRS."}, "authors": ["M M Shaifur Rahman", "Mst Shamima Nasrin", "Moin Mostakim", "Md Zahangir Alom"], "author_detail": {"name": "Md Zahangir Alom"}, "author": "Md Zahangir Alom", "arxiv_comment": "6 pages,10 figures", "links": [{"href": "http://arxiv.org/abs/1809.00905v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1809.00905v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1809.00905v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1809.00905v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1911.07613v1", "guidislink": true, "updated": "2019-11-15T08:22:33Z", "updated_parsed": [2019, 11, 15, 8, 22, 33, 4, 319, 0], "published": "2019-11-15T08:22:33Z", "published_parsed": [2019, 11, 15, 8, 22, 33, 4, 319, 0], "title": "A Subword Level Language Model for Bangla Language", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Subword Level Language Model for Bangla Language"}, "summary": "Language models are at the core of natural language processing. The ability\nto represent natural language gives rise to its applications in numerous NLP\ntasks including text classification, summarization, and translation. Research\nin this area is very limited in Bangla due to the scarcity of resources, except\nfor some count-based models and very recent neural language models being\nproposed, which are all based on words and limited in practical tasks due to\ntheir high perplexity. This paper attempts to approach this issue of perplexity\nand proposes a subword level neural language model with the AWD-LSTM\narchitecture and various other techniques suitable for training in Bangla\nlanguage. The model is trained on a corpus of Bangla newspaper articles of an\nappreciable size consisting of more than 28.5 million word tokens. The\nperformance comparison with various other models depicts the significant\nreduction in perplexity the proposed model provides, reaching as low as 39.84,\nin just 20 epochs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Language models are at the core of natural language processing. The ability\nto represent natural language gives rise to its applications in numerous NLP\ntasks including text classification, summarization, and translation. Research\nin this area is very limited in Bangla due to the scarcity of resources, except\nfor some count-based models and very recent neural language models being\nproposed, which are all based on words and limited in practical tasks due to\ntheir high perplexity. This paper attempts to approach this issue of perplexity\nand proposes a subword level neural language model with the AWD-LSTM\narchitecture and various other techniques suitable for training in Bangla\nlanguage. The model is trained on a corpus of Bangla newspaper articles of an\nappreciable size consisting of more than 28.5 million word tokens. The\nperformance comparison with various other models depicts the significant\nreduction in perplexity the proposed model provides, reaching as low as 39.84,\nin just 20 epochs."}, "authors": ["Aisha Khatun", "Anisur Rahman", "Hemayet Ahmed Chowdhury", "Md. Saiful Islam", "Ayesha Tasnim"], "author_detail": {"name": "Ayesha Tasnim"}, "author": "Ayesha Tasnim", "arxiv_comment": "12 pages, Conference Paper", "links": [{"href": "http://arxiv.org/abs/1911.07613v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1911.07613v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1911.07613v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1911.07613v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2005.14627v1", "guidislink": true, "updated": "2020-05-29T15:38:54Z", "updated_parsed": [2020, 5, 29, 15, 38, 54, 4, 150, 0], "published": "2020-05-29T15:38:54Z", "published_parsed": [2020, 5, 29, 15, 38, 54, 4, 150, 0], "title": "Detection of Bangla Fake News using MNB and SVM Classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Detection of Bangla Fake News using MNB and SVM Classifier"}, "summary": "Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%."}, "authors": ["Md Gulzar Hussain", "Md Rashidul Hasan", "Mahmuda Rahman", "Joy Protim", "Sakib Al Hasan"], "author_detail": {"name": "Sakib Al Hasan"}, "author": "Sakib Al Hasan", "links": [{"href": "http://arxiv.org/abs/2005.14627v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2005.14627v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2005.14627v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2005.14627v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.09872v3", "guidislink": true, "updated": "2018-02-10T18:40:54Z", "updated_parsed": [2018, 2, 10, 18, 40, 54, 5, 41, 0], "published": "2017-12-28T14:31:56Z", "published_parsed": [2017, 12, 28, 14, 31, 56, 3, 362, 0], "title": "Handwritten Bangla Character Recognition Using The State-of-Art Deep\n  Convolutional Neural Networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Character Recognition Using The State-of-Art Deep\n  Convolutional Neural Networks"}, "summary": "In spite of advances in object recognition technology, Handwritten Bangla\nCharacter Recognition (HBCR) remains largely unsolved due to the presence of\nmany ambiguous handwritten characters and excessively cursive Bangla\nhandwritings. Even the best existing recognizers do not lead to satisfactory\nperformance for practical applications related to Bangla character recognition\nand have much lower performance than those developed for English alpha-numeric\ncharacters. To improve the performance of HBCR, we herein present the\napplication of the state-of-the-art Deep Convolutional Neural Networks (DCNN)\nincluding VGG Network, All Convolution Network (All-Conv Net), Network in\nNetwork (NiN), Residual Network, FractalNet, and DenseNet for HBCR. The deep\nlearning approaches have the advantage of extracting and using feature\ninformation, improving the recognition of 2D shapes with a high degree of\ninvariance to translation, scaling and other distortions. We systematically\nevaluated the performance of DCNN models on publicly available Bangla\nhandwritten character dataset called CMATERdb and achieved the superior\nrecognition accuracy when using DCNN models. This improvement would help in\nbuilding an automatic HBCR system for practical applications.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In spite of advances in object recognition technology, Handwritten Bangla\nCharacter Recognition (HBCR) remains largely unsolved due to the presence of\nmany ambiguous handwritten characters and excessively cursive Bangla\nhandwritings. Even the best existing recognizers do not lead to satisfactory\nperformance for practical applications related to Bangla character recognition\nand have much lower performance than those developed for English alpha-numeric\ncharacters. To improve the performance of HBCR, we herein present the\napplication of the state-of-the-art Deep Convolutional Neural Networks (DCNN)\nincluding VGG Network, All Convolution Network (All-Conv Net), Network in\nNetwork (NiN), Residual Network, FractalNet, and DenseNet for HBCR. The deep\nlearning approaches have the advantage of extracting and using feature\ninformation, improving the recognition of 2D shapes with a high degree of\ninvariance to translation, scaling and other distortions. We systematically\nevaluated the performance of DCNN models on publicly available Bangla\nhandwritten character dataset called CMATERdb and achieved the superior\nrecognition accuracy when using DCNN models. This improvement would help in\nbuilding an automatic HBCR system for practical applications."}, "authors": ["Md Zahangir Alom", "Peheding Sidike", "Mahmudul Hasan", "Tark M. Taha", "Vijayan K. Asari"], "author_detail": {"name": "Vijayan K. Asari"}, "author": "Vijayan K. Asari", "arxiv_comment": "12 pages,22 figures, 5 tables. arXiv admin note: text overlap with\n  arXiv:1705.02680", "links": [{"href": "http://arxiv.org/abs/1712.09872v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.09872v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.09872v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.09872v3", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2101.00204v1", "guidislink": true, "updated": "2021-01-01T09:28:45Z", "updated_parsed": [2021, 1, 1, 9, 28, 45, 4, 1, 0], "published": "2021-01-01T09:28:45Z", "published_parsed": [2021, 1, 1, 9, 28, 45, 4, 1, 0], "title": "BanglaBERT: Combating Embedding Barrier for Low-Resource Language\n  Understanding", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaBERT: Combating Embedding Barrier for Low-Resource Language\n  Understanding"}, "summary": "Pre-training language models on large volume of data with self-supervised\nobjectives has become a standard practice in natural language processing.\nHowever, most such state-of-the-art models are available in only English and\nother resource-rich languages. Even in multilingual models, which are trained\non hundreds of languages, low-resource ones still remain underrepresented.\nBangla, the seventh most widely spoken language in the world, is still low in\nterms of resources. Few downstream task datasets for language understanding in\nBangla are publicly available, and there is a clear shortage of good quality\ndata for pre-training. In this work, we build a Bangla natural language\nunderstanding model pre-trained on 18.6 GB data we crawled from top Bangla\nsites on the internet. We introduce a new downstream task dataset and benchmark\non four tasks on sentence classification, document classification, natural\nlanguage understanding, and sequence tagging. Our model outperforms\nmultilingual baselines and previous state-of-the-art results by 1-6%. In the\nprocess, we identify a major shortcoming of multilingual models that hurt\nperformance for low-resource languages that don't share writing scripts with\nany high resource one, which we name the `Embedding Barrier'. We perform\nextensive experiments to study this barrier. We release all our datasets and\npre-trained models to aid future NLP research on Bangla and other low-resource\nlanguages. Our code and data are available at\nhttps://github.com/csebuetnlp/banglabert.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Pre-training language models on large volume of data with self-supervised\nobjectives has become a standard practice in natural language processing.\nHowever, most such state-of-the-art models are available in only English and\nother resource-rich languages. Even in multilingual models, which are trained\non hundreds of languages, low-resource ones still remain underrepresented.\nBangla, the seventh most widely spoken language in the world, is still low in\nterms of resources. Few downstream task datasets for language understanding in\nBangla are publicly available, and there is a clear shortage of good quality\ndata for pre-training. In this work, we build a Bangla natural language\nunderstanding model pre-trained on 18.6 GB data we crawled from top Bangla\nsites on the internet. We introduce a new downstream task dataset and benchmark\non four tasks on sentence classification, document classification, natural\nlanguage understanding, and sequence tagging. Our model outperforms\nmultilingual baselines and previous state-of-the-art results by 1-6%. In the\nprocess, we identify a major shortcoming of multilingual models that hurt\nperformance for low-resource languages that don't share writing scripts with\nany high resource one, which we name the `Embedding Barrier'. We perform\nextensive experiments to study this barrier. We release all our datasets and\npre-trained models to aid future NLP research on Bangla and other low-resource\nlanguages. Our code and data are available at\nhttps://github.com/csebuetnlp/banglabert."}, "authors": ["Abhik Bhattacharjee", "Tahmid Hasan", "Kazi Samin", "M. Sohel Rahman", "Anindya Iqbal", "Rifat Shahriyar"], "author_detail": {"name": "Rifat Shahriyar"}, "author": "Rifat Shahriyar", "links": [{"href": "http://arxiv.org/abs/2101.00204v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2101.00204v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2101.00204v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2101.00204v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.10106v1", "guidislink": true, "updated": "2020-11-19T21:06:28Z", "updated_parsed": [2020, 11, 19, 21, 6, 28, 3, 324, 0], "published": "2020-11-19T21:06:28Z", "published_parsed": [2020, 11, 19, 21, 6, 28, 3, 324, 0], "title": "Sentiment Classification in Bangla Textual Content: A Comparative Study", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Classification in Bangla Textual Content: A Comparative Study"}, "summary": "Sentiment analysis has been widely used to understand our views on social and\npolitical agendas or user experiences over a product. It is one of the cores\nand well-researched areas in NLP. However, for low-resource languages, like\nBangla, one of the prominent challenge is the lack of resources. Another\nimportant limitation, in the current literature for Bangla, is the absence of\ncomparable results due to the lack of a well-defined train/test split. In this\nstudy, we explore several publicly available sentiment labeled datasets and\ndesigned classifiers using both classical and deep learning algorithms. In our\nstudy, the classical algorithms include SVM and Random Forest, and deep\nlearning algorithms include CNN, FastText, and transformer-based models. We\ncompare these models in terms of model performance and time-resource\ncomplexity. Our finding suggests transformer-based models, which have not been\nexplored earlier for Bangla, outperform all other models. Furthermore, we\ncreated a weighted list of lexicon content based on the valence score per\nclass. We then analyzed the content for high significance entries per class, in\nthe datasets. For reproducibility, we make publicly available data splits and\nthe ranked lexicon list. The presented results can be used for future studies\nas a benchmark.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment analysis has been widely used to understand our views on social and\npolitical agendas or user experiences over a product. It is one of the cores\nand well-researched areas in NLP. However, for low-resource languages, like\nBangla, one of the prominent challenge is the lack of resources. Another\nimportant limitation, in the current literature for Bangla, is the absence of\ncomparable results due to the lack of a well-defined train/test split. In this\nstudy, we explore several publicly available sentiment labeled datasets and\ndesigned classifiers using both classical and deep learning algorithms. In our\nstudy, the classical algorithms include SVM and Random Forest, and deep\nlearning algorithms include CNN, FastText, and transformer-based models. We\ncompare these models in terms of model performance and time-resource\ncomplexity. Our finding suggests transformer-based models, which have not been\nexplored earlier for Bangla, outperform all other models. Furthermore, we\ncreated a weighted list of lexicon content based on the valence score per\nclass. We then analyzed the content for high significance entries per class, in\nthe datasets. For reproducibility, we make publicly available data splits and\nthe ranked lexicon list. The presented results can be used for future studies\nas a benchmark."}, "authors": ["Md. Arid Hasan", "Jannatul Tajrin", "Shammur Absar Chowdhury", "Firoj Alam"], "author_detail": {"name": "Firoj Alam"}, "author": "Firoj Alam", "arxiv_comment": "Accepted at ICCIT-2020", "links": [{"href": "http://arxiv.org/abs/2011.10106v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.10106v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T50", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.10106v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.10106v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1002.4007v1", "guidislink": true, "updated": "2010-02-21T19:48:16Z", "updated_parsed": [2010, 2, 21, 19, 48, 16, 6, 52, 0], "published": "2010-02-21T19:48:16Z", "published_parsed": [2010, 2, 21, 19, 48, 16, 6, 52, 0], "title": "Word level Script Identification from Bangla and Devanagri Handwritten\n  Texts mixed with Roman Script", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word level Script Identification from Bangla and Devanagri Handwritten\n  Texts mixed with Roman Script"}, "summary": "India is a multi-lingual country where Roman script is often used alongside\ndifferent Indic scripts in a text document. To develop a script specific\nhandwritten Optical Character Recognition (OCR) system, it is therefore\nnecessary to identify the scripts of handwritten text correctly. In this paper,\nwe present a system, which automatically separates the scripts of handwritten\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\nIn this script separation technique, we first, extract the text lines and words\nfrom document pages using a script independent Neighboring Component Analysis\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\nclassifier for script separation, trained with 8 different wordlevel holistic\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\nOn respective independent text samples, word-level script identification\naccuracies of 99.29% and 98.43% are achieved.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "India is a multi-lingual country where Roman script is often used alongside\ndifferent Indic scripts in a text document. To develop a script specific\nhandwritten Optical Character Recognition (OCR) system, it is therefore\nnecessary to identify the scripts of handwritten text correctly. In this paper,\nwe present a system, which automatically separates the scripts of handwritten\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\nIn this script separation technique, we first, extract the text lines and words\nfrom document pages using a script independent Neighboring Component Analysis\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\nclassifier for script separation, trained with 8 different wordlevel holistic\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\nOn respective independent text samples, word-level script identification\naccuracies of 99.29% and 98.43% are achieved."}, "authors": ["Ram Sarkar", "Nibaran Das", "Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1002.4007v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.4007v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.4007v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1002.4007v1", "arxiv_comment": null, "journal_reference": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null}
{"id": "http://arxiv.org/abs/1206.0381v1", "guidislink": true, "updated": "2012-06-02T13:23:18Z", "updated_parsed": [2012, 6, 2, 13, 23, 18, 5, 154, 0], "published": "2012-06-02T13:23:18Z", "published_parsed": [2012, 6, 2, 13, 23, 18, 5, 154, 0], "title": "UNL Based Bangla Natural Text Conversion - Predicate Preserving Parser\n  Approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "UNL Based Bangla Natural Text Conversion - Predicate Preserving Parser\n  Approach"}, "summary": "Universal Networking Language (UNL) is a declarative formal language that is\nused to represent semantic data extracted from natural language texts. This\npaper presents a novel approach to converting Bangla natural language text into\nUNL using a method known as Predicate Preserving Parser (PPP) technique. PPP\nperforms morphological, syntactic and semantic, and lexical analysis of text\nsynchronously. This analysis produces a semantic-net like structure represented\nusing UNL. We demonstrate how Bangla texts are analyzed following the PPP\ntechnique to produce UNL documents which can then be translated into any other\nsuitable natural language facilitating the opportunity to develop a universal\nlanguage translation method via UNL.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Universal Networking Language (UNL) is a declarative formal language that is\nused to represent semantic data extracted from natural language texts. This\npaper presents a novel approach to converting Bangla natural language text into\nUNL using a method known as Predicate Preserving Parser (PPP) technique. PPP\nperforms morphological, syntactic and semantic, and lexical analysis of text\nsynchronously. This analysis produces a semantic-net like structure represented\nusing UNL. We demonstrate how Bangla texts are analyzed following the PPP\ntechnique to produce UNL documents which can then be translated into any other\nsuitable natural language facilitating the opportunity to develop a universal\nlanguage translation method via UNL."}, "authors": ["Md. Nawab Yousuf Ali", "Shamim Ripon", "Shaikh Muhammad Allayear"], "author_detail": {"name": "Shaikh Muhammad Allayear"}, "author": "Shaikh Muhammad Allayear", "arxiv_comment": "7 pages, International Journal of Computer Science Issues (IJCSI),\n  Volume 9, Issue 3 May 2012", "links": [{"href": "http://arxiv.org/abs/1206.0381v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1206.0381v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1206.0381v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1206.0381v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1310.1426v1", "guidislink": true, "updated": "2013-10-05T00:39:02Z", "updated_parsed": [2013, 10, 5, 0, 39, 2, 5, 278, 0], "published": "2013-10-05T00:39:02Z", "published_parsed": [2013, 10, 5, 0, 39, 2, 5, 278, 0], "title": "Local Feature or Mel Frequency Cepstral Coefficients - Which One is\n  Better for MLN-Based Bangla Speech Recognition?", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Local Feature or Mel Frequency Cepstral Coefficients - Which One is\n  Better for MLN-Based Bangla Speech Recognition?"}, "summary": "This paper discusses the dominancy of local features (LFs), as input to the\nmultilayer neural network (MLN), extracted from a Bangla input speech over mel\nfrequency cepstral coefficients (MFCCs). Here, LF-based method comprises three\nstages: (i) LF extraction from input speech, (ii) phoneme probabilities\nextraction using MLN from LF and (iii) the hidden Markov model (HMM) based\nclassifier to obtain more accurate phoneme strings. In the experiments on\nBangla speech corpus prepared by us, it is observed that the LFbased automatic\nspeech recognition (ASR) system provides higher phoneme correct rate than the\nMFCC-based system. Moreover, the proposed system requires fewer mixture\ncomponents in the HMMs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper discusses the dominancy of local features (LFs), as input to the\nmultilayer neural network (MLN), extracted from a Bangla input speech over mel\nfrequency cepstral coefficients (MFCCs). Here, LF-based method comprises three\nstages: (i) LF extraction from input speech, (ii) phoneme probabilities\nextraction using MLN from LF and (iii) the hidden Markov model (HMM) based\nclassifier to obtain more accurate phoneme strings. In the experiments on\nBangla speech corpus prepared by us, it is observed that the LFbased automatic\nspeech recognition (ASR) system provides higher phoneme correct rate than the\nMFCC-based system. Moreover, the proposed system requires fewer mixture\ncomponents in the HMMs."}, "authors": ["Foyzul Hassan", "Mohammed Rokibul Alam Kotwal", "Md. Mostafizur Rahman", "Mohammad Nasiruddin", "Md. Abdul Latif", "Mohammad Nurul Huda"], "author_detail": {"name": "Mohammad Nurul Huda"}, "author": "Mohammad Nurul Huda", "arxiv_comment": "9 pages Advances in Computing and Communications (ACC) 2011", "links": [{"href": "http://arxiv.org/abs/1310.1426v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1310.1426v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T50", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1310.1426v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1310.1426v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1911.11062v1", "guidislink": true, "updated": "2019-11-19T20:37:03Z", "updated_parsed": [2019, 11, 19, 20, 37, 3, 1, 323, 0], "published": "2019-11-19T20:37:03Z", "published_parsed": [2019, 11, 19, 20, 37, 3, 1, 323, 0], "title": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model"}, "summary": "Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%."}, "authors": ["Arnab Sen Sharma", "Maruf Ahmed Mridul", "Md Saiful Islam"], "author_detail": {"name": "Md Saiful Islam"}, "author": "Md Saiful Islam", "arxiv_comment": "5 pages, Conference paper", "links": [{"href": "http://arxiv.org/abs/1911.11062v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1911.11062v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1911.11062v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1911.11062v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2001.05316v1", "guidislink": true, "updated": "2020-01-11T14:54:04Z", "updated_parsed": [2020, 1, 11, 14, 54, 4, 5, 11, 0], "published": "2020-01-11T14:54:04Z", "published_parsed": [2020, 1, 11, 14, 54, 4, 5, 11, 0], "title": "Authorship Attribution in Bangla literature using Character-level CNN", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Authorship Attribution in Bangla literature using Character-level CNN"}, "summary": "Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results."}, "authors": ["Aisha Khatun", "Anisur Rahman", "Md. Saiful Islam", "Marium-E-Jannat"], "author_detail": {"name": "Marium-E-Jannat"}, "author": "Marium-E-Jannat", "arxiv_comment": "5 pages", "links": [{"href": "http://arxiv.org/abs/2001.05316v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2001.05316v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2001.05316v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2001.05316v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2004.08789v1", "guidislink": true, "updated": "2020-04-19T07:42:22Z", "updated_parsed": [2020, 4, 19, 7, 42, 22, 6, 110, 0], "published": "2020-04-19T07:42:22Z", "published_parsed": [2020, 4, 19, 7, 42, 22, 6, 110, 0], "title": "BanFakeNews: A Dataset for Detecting Fake News in Bangla", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanFakeNews: A Dataset for Detecting Fake News in Bangla"}, "summary": "Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages."}, "authors": ["Md Zobaer Hossain", "Md Ashraful Rahman", "Md Saiful Islam", "Sudipta Kar"], "author_detail": {"name": "Sudipta Kar"}, "author": "Sudipta Kar", "arxiv_comment": "LREC 2020", "links": [{"href": "http://arxiv.org/abs/2004.08789v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.08789v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.08789v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.08789v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2010.13404v2", "guidislink": true, "updated": "2021-01-12T13:51:27Z", "updated_parsed": [2021, 1, 12, 13, 51, 27, 1, 12, 0], "published": "2020-10-26T08:00:48Z", "published_parsed": [2020, 10, 26, 8, 0, 48, 0, 300, 0], "title": "Robust and Consistent Estimation of Word Embedding for Bangla Language\n  by fine-tuning Word2Vec Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Robust and Consistent Estimation of Word Embedding for Bangla Language\n  by fine-tuning Word2Vec Model"}, "summary": "In recent times, data is growing rapidly in every domain such as news, social\nmedia, banking, education, etc. Due to the excessiveness of data, there is a\nneed for an automatic keyword extractor that can help to summarize the data.\nKeyword extraction is a text analysis technique that consists of automatically\nextracting the most important words and expressions in a text. It helps\nsummarize the content of a text and recognize the main topics which are being\ndiscussed. Earlier works regarding this topic have been done but no significant\nwork was done for the Bangla language. So, we tried to achieve the same things\nwhich could be done with other languages in the Bangla language.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In recent times, data is growing rapidly in every domain such as news, social\nmedia, banking, education, etc. Due to the excessiveness of data, there is a\nneed for an automatic keyword extractor that can help to summarize the data.\nKeyword extraction is a text analysis technique that consists of automatically\nextracting the most important words and expressions in a text. It helps\nsummarize the content of a text and recognize the main topics which are being\ndiscussed. Earlier works regarding this topic have been done but no significant\nwork was done for the Bangla language. So, we tried to achieve the same things\nwhich could be done with other languages in the Bangla language."}, "authors": ["Rifat Rahman"], "author_detail": {"name": "Rifat Rahman"}, "author": "Rifat Rahman", "arxiv_comment": "I have implemented some approaches that are wrong. Now I am fixing\n  these issues. The methodology used my previous script may be harmful for\n  relevant researchers", "links": [{"href": "http://arxiv.org/abs/2010.13404v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.13404v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.13404v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.13404v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.04446v1", "guidislink": true, "updated": "2020-11-09T14:12:07Z", "updated_parsed": [2020, 11, 9, 14, 12, 7, 0, 314, 0], "published": "2020-11-09T14:12:07Z", "published_parsed": [2020, 11, 9, 14, 12, 7, 0, 314, 0], "title": "Bangla Text Classification using Transformers", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Text Classification using Transformers"}, "summary": "Text classification has been one of the earliest problems in NLP. Over time\nthe scope of application areas has broadened and the difficulty of dealing with\nnew areas (e.g., noisy social media content) has increased. The problem-solving\nstrategy switched from classical machine learning to deep learning algorithms.\nOne of the recent deep neural network architecture is the Transformer. Models\ndesigned with this type of network and its variants recently showed their\nsuccess in many downstream natural language processing tasks, especially for\nresource-rich languages, e.g., English. However, these models have not been\nexplored fully for Bangla text classification tasks. In this work, we fine-tune\nmultilingual transformer models for Bangla text classification tasks in\ndifferent domains, including sentiment analysis, emotion detection, news\ncategorization, and authorship attribution. We obtain the state of the art\nresults on six benchmark datasets, improving upon the previous results by 5-29%\naccuracy across different tasks.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Text classification has been one of the earliest problems in NLP. Over time\nthe scope of application areas has broadened and the difficulty of dealing with\nnew areas (e.g., noisy social media content) has increased. The problem-solving\nstrategy switched from classical machine learning to deep learning algorithms.\nOne of the recent deep neural network architecture is the Transformer. Models\ndesigned with this type of network and its variants recently showed their\nsuccess in many downstream natural language processing tasks, especially for\nresource-rich languages, e.g., English. However, these models have not been\nexplored fully for Bangla text classification tasks. In this work, we fine-tune\nmultilingual transformer models for Bangla text classification tasks in\ndifferent domains, including sentiment analysis, emotion detection, news\ncategorization, and authorship attribution. We obtain the state of the art\nresults on six benchmark datasets, improving upon the previous results by 5-29%\naccuracy across different tasks."}, "authors": ["Tanvirul Alam", "Akib Khan", "Firoj Alam"], "author_detail": {"name": "Firoj Alam"}, "author": "Firoj Alam", "links": [{"href": "http://arxiv.org/abs/2011.04446v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.04446v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.04446v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.04446v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.07499v2", "guidislink": true, "updated": "2020-12-08T09:30:02Z", "updated_parsed": [2020, 12, 8, 9, 30, 2, 1, 343, 0], "published": "2020-11-15T11:08:53Z", "published_parsed": [2020, 11, 15, 11, 8, 53, 6, 320, 0], "title": "BanglaWriting: A multi-purpose offline Bangla handwriting dataset", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaWriting: A multi-purpose offline Bangla handwriting dataset"}, "summary": "This article presents a Bangla handwriting dataset named BanglaWriting that\ncontains single-page handwritings of 260 individuals of different personalities\nand ages. Each page includes bounding-boxes that bounds each word, along with\nthe unicode representation of the writing. This dataset contains 21,234 words\nand 32,787 characters in total. Moreover, this dataset includes 5,470 unique\nwords of Bangla vocabulary. Apart from the usual words, the dataset comprises\n261 comprehensible overwriting and 450 handwritten strikes and mistakes. All of\nthe bounding-boxes and word labels are manually-generated. The dataset can be\nused for complex optical character/word recognition, writer identification,\nhandwritten word segmentation, and word generation. Furthermore, this dataset\nis suitable for extracting age-based and gender-based variation of handwriting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This article presents a Bangla handwriting dataset named BanglaWriting that\ncontains single-page handwritings of 260 individuals of different personalities\nand ages. Each page includes bounding-boxes that bounds each word, along with\nthe unicode representation of the writing. This dataset contains 21,234 words\nand 32,787 characters in total. Moreover, this dataset includes 5,470 unique\nwords of Bangla vocabulary. Apart from the usual words, the dataset comprises\n261 comprehensible overwriting and 450 handwritten strikes and mistakes. All of\nthe bounding-boxes and word labels are manually-generated. The dataset can be\nused for complex optical character/word recognition, writer identification,\nhandwritten word segmentation, and word generation. Furthermore, this dataset\nis suitable for extracting age-based and gender-based variation of handwriting."}, "authors": ["M. F. Mridha", "Abu Quwsar Ohi", "M. Ameer Ali", "Mazedul Islam Emon", "Muhammad Mohsin Kabir"], "author_detail": {"name": "Muhammad Mohsin Kabir"}, "author": "Muhammad Mohsin Kabir", "arxiv_comment": "Accepted in journal Data in Brief. The dataset is available on\n  https://data.mendeley.com/datasets/r43wkvdk4w/", "links": [{"href": "http://arxiv.org/abs/2011.07499v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.07499v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.07499v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.07499v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1901.05613v1", "guidislink": true, "updated": "2019-01-17T04:27:34Z", "updated_parsed": [2019, 1, 17, 4, 27, 34, 3, 17, 0], "published": "2019-01-17T04:27:34Z", "published_parsed": [2019, 1, 17, 4, 27, 34, 3, 17, 0], "title": "Hand Sign to Bangla Speech: A Deep Learning in Vision based system for\n  Recognizing Hand Sign Digits and Generating Bangla Speech", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Hand Sign to Bangla Speech: A Deep Learning in Vision based system for\n  Recognizing Hand Sign Digits and Generating Bangla Speech"}, "summary": "Recent advancements in the field of computer vision with the help of deep\nneural networks have led us to explore and develop many existing challenges\nthat were once unattended due to the lack of necessary technologies. Hand\nSign/Gesture Recognition is one of the significant areas where the deep neural\nnetwork is making a substantial impact. In the last few years, a large number\nof researches has been conducted to recognize hand signs and hand gestures,\nwhich we aim to extend to our mother-tongue, Bangla (also known as Bengali).\nThe primary goal of our work is to make an automated tool to aid the people who\nare unable to speak. We developed a system that automatically detects hand sign\nbased digits and speaks out the result in Bangla language. According to the\nreport of the World Health Organization (WHO), 15% of people in the world live\nwith some kind of disabilities. Among them, individuals with communication\nimpairment such as speech disabilities experience substantial barrier in social\ninteraction. The proposed system can be invaluable to mitigate such a barrier.\nThe core of the system is built with a deep learning model which is based on\nconvolutional neural networks (CNN). The model classifies hand sign based\ndigits with 92% accuracy over validation data which ensures it a highly\ntrustworthy system. Upon classification of the digits, the resulting output is\nfed to the text to speech engine and the translator unit eventually which\ngenerates audio output in Bangla language. A web application to demonstrate our\ntool is available at http://bit.ly/signdigits2banglaspeech.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recent advancements in the field of computer vision with the help of deep\nneural networks have led us to explore and develop many existing challenges\nthat were once unattended due to the lack of necessary technologies. Hand\nSign/Gesture Recognition is one of the significant areas where the deep neural\nnetwork is making a substantial impact. In the last few years, a large number\nof researches has been conducted to recognize hand signs and hand gestures,\nwhich we aim to extend to our mother-tongue, Bangla (also known as Bengali).\nThe primary goal of our work is to make an automated tool to aid the people who\nare unable to speak. We developed a system that automatically detects hand sign\nbased digits and speaks out the result in Bangla language. According to the\nreport of the World Health Organization (WHO), 15% of people in the world live\nwith some kind of disabilities. Among them, individuals with communication\nimpairment such as speech disabilities experience substantial barrier in social\ninteraction. The proposed system can be invaluable to mitigate such a barrier.\nThe core of the system is built with a deep learning model which is based on\nconvolutional neural networks (CNN). The model classifies hand sign based\ndigits with 92% accuracy over validation data which ensures it a highly\ntrustworthy system. Upon classification of the digits, the resulting output is\nfed to the text to speech engine and the translator unit eventually which\ngenerates audio output in Bangla language. A web application to demonstrate our\ntool is available at http://bit.ly/signdigits2banglaspeech."}, "authors": ["Shahjalal Ahmed", "Md. Rafiqul Islam", "Jahid Hassan", "Minhaz Uddin Ahmed", "Bilkis Jamal Ferdosi", "Sanjay Saha", "Md. Shopon"], "author_detail": {"name": "Md. Shopon"}, "author": "Md. Shopon", "links": [{"href": "http://arxiv.org/abs/1901.05613v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1901.05613v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1901.05613v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1901.05613v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.08706v1", "guidislink": true, "updated": "2017-01-27T12:54:52Z", "updated_parsed": [2017, 1, 27, 12, 54, 52, 4, 27, 0], "published": "2017-01-27T12:54:52Z", "published_parsed": [2017, 1, 27, 12, 54, 52, 4, 27, 0], "title": "Document Decomposition of Bangla Printed Text", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Document Decomposition of Bangla Printed Text"}, "summary": "Today all kind of information is getting digitized and along with all this\ndigitization, the huge archive of various kinds of documents is being digitized\ntoo. We know that, Optical Character Recognition is the method through which,\nnewspapers and other paper documents convert into digital resources. But, it is\na fact that this method works on texts only. As a result, if we try to process\nany document which contains non-textual zones, then we will get garbage texts\nas output. That is why; in order to digitize documents properly they should be\nprepossessed carefully. And while preprocessing, segmenting document in\ndifferent regions according to the category properly is most important. But,\nthe Optical Character Recognition processes available for Bangla language have\nno such algorithm that can categorize a newspaper/book page fully. So we worked\nto decompose a document into its several parts like headlines, sub headlines,\ncolumns, images etc. And if the input is skewed and rotated, then the input was\nalso deskewed and de-rotated. To decompose any Bangla document we found out the\nedges of the input image. Then we find out the horizontal and vertical area of\nevery pixel where it lies in. Later on the input image was cut according to\nthese areas. Then we pick each and every sub image and found out their\nheight-width ratio, line height. Then according to these values the sub images\nwere categorized. To deskew the image we found out the skew angle and de skewed\nthe image according to this angle. To de-rotate the image we used the line\nheight, matra line, pixel ratio of matra line.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Today all kind of information is getting digitized and along with all this\ndigitization, the huge archive of various kinds of documents is being digitized\ntoo. We know that, Optical Character Recognition is the method through which,\nnewspapers and other paper documents convert into digital resources. But, it is\na fact that this method works on texts only. As a result, if we try to process\nany document which contains non-textual zones, then we will get garbage texts\nas output. That is why; in order to digitize documents properly they should be\nprepossessed carefully. And while preprocessing, segmenting document in\ndifferent regions according to the category properly is most important. But,\nthe Optical Character Recognition processes available for Bangla language have\nno such algorithm that can categorize a newspaper/book page fully. So we worked\nto decompose a document into its several parts like headlines, sub headlines,\ncolumns, images etc. And if the input is skewed and rotated, then the input was\nalso deskewed and de-rotated. To decompose any Bangla document we found out the\nedges of the input image. Then we find out the horizontal and vertical area of\nevery pixel where it lies in. Later on the input image was cut according to\nthese areas. Then we pick each and every sub image and found out their\nheight-width ratio, line height. Then according to these values the sub images\nwere categorized. To deskew the image we found out the skew angle and de skewed\nthe image according to this angle. To de-rotate the image we used the line\nheight, matra line, pixel ratio of matra line."}, "authors": ["Md. Fahad Hasan", "Tasmin Afroz", "Sabir Ismail", "Md. Saiful Islam"], "author_detail": {"name": "Md. Saiful Islam"}, "author": "Md. Saiful Islam", "arxiv_comment": "6 pages", "links": [{"href": "http://arxiv.org/abs/1701.08706v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08706v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08706v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08706v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1707.08398v1", "guidislink": true, "updated": "2017-07-26T12:03:39Z", "updated_parsed": [2017, 7, 26, 12, 3, 39, 2, 207, 0], "published": "2017-07-26T12:03:39Z", "published_parsed": [2017, 7, 26, 12, 3, 39, 2, 207, 0], "title": "A Harmony Search Based Wrapper Feature Selection Method for Holistic\n  Bangla word Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Harmony Search Based Wrapper Feature Selection Method for Holistic\n  Bangla word Recognition"}, "summary": "A lot of search approaches have been explored for the selection of features\nin pattern classification domain in order to discover significant subset of the\nfeatures which produces better accuracy. In this paper, we introduced a Harmony\nSearch (HS) algorithm based feature selection method for feature dimensionality\nreduction in handwritten Bangla word recognition problem. This algorithm has\nbeen implemented to reduce the feature dimensionality of a technique described\nin one of our previous papers by S. Bhowmik et al.[1]. In the said paper, a set\nof 65 elliptical features were computed for handwritten Bangla word recognition\npurpose and a recognition accuracy of 81.37% was achieved using Multi Layer\nPerceptron (MLP) classifier. In the present work, a subset containing 48\nfeatures (approximately 75% of said feature vector) has been selected by HS\nbased wrapper feature selection method which produces an accuracy rate of\n90.29%. Reasonable outcomes also validates that the introduced algorithm\nutilizes optimal number of features while showing higher classification\naccuracies when compared to two standard evolutionary algorithms like Genetic\nAlgorithm (GA), Particle Swarm Optimization (PSO) and statistical feature\ndimensionality reduction technique like Principal Component Analysis (PCA).\nThis confirms the suitability of HS algorithm to the holistic handwritten word\nrecognition problem.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A lot of search approaches have been explored for the selection of features\nin pattern classification domain in order to discover significant subset of the\nfeatures which produces better accuracy. In this paper, we introduced a Harmony\nSearch (HS) algorithm based feature selection method for feature dimensionality\nreduction in handwritten Bangla word recognition problem. This algorithm has\nbeen implemented to reduce the feature dimensionality of a technique described\nin one of our previous papers by S. Bhowmik et al.[1]. In the said paper, a set\nof 65 elliptical features were computed for handwritten Bangla word recognition\npurpose and a recognition accuracy of 81.37% was achieved using Multi Layer\nPerceptron (MLP) classifier. In the present work, a subset containing 48\nfeatures (approximately 75% of said feature vector) has been selected by HS\nbased wrapper feature selection method which produces an accuracy rate of\n90.29%. Reasonable outcomes also validates that the introduced algorithm\nutilizes optimal number of features while showing higher classification\naccuracies when compared to two standard evolutionary algorithms like Genetic\nAlgorithm (GA), Particle Swarm Optimization (PSO) and statistical feature\ndimensionality reduction technique like Principal Component Analysis (PCA).\nThis confirms the suitability of HS algorithm to the holistic handwritten word\nrecognition problem."}, "authors": ["Supratim Das", "Pawan Kumar Singh", "Showmik Bhowmik", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/1707.08398v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1707.08398v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T10", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1707.08398v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1707.08398v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1501.05497v1", "guidislink": true, "updated": "2015-01-22T13:50:25Z", "updated_parsed": [2015, 1, 22, 13, 50, 25, 3, 22, 0], "published": "2015-01-22T13:50:25Z", "published_parsed": [2015, 1, 22, 13, 50, 25, 3, 22, 0], "title": "An Improved Feature Descriptor for Recognition of Handwritten Bangla\n  Alphabet", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An Improved Feature Descriptor for Recognition of Handwritten Bangla\n  Alphabet"}, "summary": "Appropriate feature set for representation of pattern classes is one of the\nmost important aspects of handwritten character recognition. The effectiveness\nof features depends on the discriminating power of the features chosen to\nrepresent patterns of different classes. However, discriminatory features are\nnot easily measurable. Investigative experimentation is necessary for\nidentifying discriminatory features. In the present work we have identified a\nnew variation of feature set which significantly outperforms on handwritten\nBangla alphabet from the previously used feature set. 132 number of features in\nall viz. modified shadow features, octant and centroid features, distance based\nfeatures, quad tree based longest run features are used here. Using this\nfeature set the recognition performance increases sharply from the 75.05%\nobserved in our previous work [7], to 85.40% on 50 character classes with MLP\nbased classifier on the same dataset.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Appropriate feature set for representation of pattern classes is one of the\nmost important aspects of handwritten character recognition. The effectiveness\nof features depends on the discriminating power of the features chosen to\nrepresent patterns of different classes. However, discriminatory features are\nnot easily measurable. Investigative experimentation is necessary for\nidentifying discriminatory features. In the present work we have identified a\nnew variation of feature set which significantly outperforms on handwritten\nBangla alphabet from the previously used feature set. 132 number of features in\nall viz. modified shadow features, octant and centroid features, distance based\nfeatures, quad tree based longest run features are used here. Using this\nfeature set the recognition performance increases sharply from the 75.05%\nobserved in our previous work [7], to 85.40% on 50 character classes with MLP\nbased classifier on the same dataset."}, "authors": ["Nibaran Das", "Subhadip Basu", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak kumar Basu"], "author_detail": {"name": "Dipak kumar Basu"}, "author": "Dipak kumar Basu", "arxiv_comment": "In proceedings of ICSIP 2009, pp. 451 to 454, August 2009, Mysore,\n  India. arXiv admin note: substantial text overlap with arXiv:1203.0882,\n  arXiv:1002.4040, arXiv:1410.0478", "links": [{"href": "http://arxiv.org/abs/1501.05497v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1501.05497v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1501.05497v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1501.05497v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.01434v1", "guidislink": true, "updated": "2017-12-05T01:12:25Z", "updated_parsed": [2017, 12, 5, 1, 12, 25, 1, 339, 0], "published": "2017-12-05T01:12:25Z", "published_parsed": [2017, 12, 5, 1, 12, 25, 1, 339, 0], "title": "Zone-based Keyword Spotting in Bangla and Devanagari Documents", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Zone-based Keyword Spotting in Bangla and Devanagari Documents"}, "summary": "In this paper we present a word spotting system in text lines for offline\nIndic scripts such as Bangla (Bengali) and Devanagari. Recently, it was shown\nthat zone-wise recognition method improves the word recognition performance\nthan conventional full word recognition system in Indic scripts. Inspired with\nthis idea we consider the zone segmentation approach and use middle zone\ninformation to improve the traditional word spotting performance. To avoid the\nproblem of zone segmentation using heuristic approach, we propose here an HMM\nbased approach to segment the upper and lower zone components from the text\nline images. The candidate keywords are searched from a line without segmenting\ncharacters or words. Also, we propose a novel feature combining foreground and\nbackground information of text line images for keyword-spotting by character\nfiller models. A significant improvement in performance is noted by using both\nforeground and background information than their individual one. Pyramid\nHistogram of Oriented Gradient (PHOG) feature has been used in our word\nspotting framework. From the experiment, it has been noted that the proposed\nzone-segmentation based system outperforms traditional approaches of word\nspotting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper we present a word spotting system in text lines for offline\nIndic scripts such as Bangla (Bengali) and Devanagari. Recently, it was shown\nthat zone-wise recognition method improves the word recognition performance\nthan conventional full word recognition system in Indic scripts. Inspired with\nthis idea we consider the zone segmentation approach and use middle zone\ninformation to improve the traditional word spotting performance. To avoid the\nproblem of zone segmentation using heuristic approach, we propose here an HMM\nbased approach to segment the upper and lower zone components from the text\nline images. The candidate keywords are searched from a line without segmenting\ncharacters or words. Also, we propose a novel feature combining foreground and\nbackground information of text line images for keyword-spotting by character\nfiller models. A significant improvement in performance is noted by using both\nforeground and background information than their individual one. Pyramid\nHistogram of Oriented Gradient (PHOG) feature has been used in our word\nspotting framework. From the experiment, it has been noted that the proposed\nzone-segmentation based system outperforms traditional approaches of word\nspotting."}, "authors": ["Ayan Kumar Bhunia", "Partha Pratim Roy", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "arxiv_comment": "Preprint Submitted", "links": [{"href": "http://arxiv.org/abs/1712.01434v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.01434v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.01434v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.01434v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1802.00671v1", "guidislink": true, "updated": "2018-02-02T13:06:43Z", "updated_parsed": [2018, 2, 2, 13, 6, 43, 4, 33, 0], "published": "2018-02-02T13:06:43Z", "published_parsed": [2018, 2, 2, 13, 6, 43, 4, 33, 0], "title": "Handwritten Isolated Bangla Compound Character Recognition: a new\n  benchmark using a novel deep learning approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Isolated Bangla Compound Character Recognition: a new\n  benchmark using a novel deep learning approach"}, "summary": "In this work, a novel deep learning technique for the recognition of\nhandwritten Bangla isolated compound character is presented and a new benchmark\nof recognition accuracy on the CMATERdb 3.1.3.3 dataset is reported. Greedy\nlayer wise training of Deep Neural Network has helped to make significant\nstrides in various pattern recognition problems. We employ layerwise training\nto Deep Convolutional Neural Networks (DCNN) in a supervised fashion and\naugment the training process with the RMSProp algorithm to achieve faster\nconvergence. We compare results with those obtained from standard shallow\nlearning methods with predefined features, as well as standard DCNNs.\nSupervised layerwise trained DCNNs are found to outperform standard shallow\nlearning models such as Support Vector Machines as well as regular DCNNs of\nsimilar architecture by achieving error rate of 9.67% thereby setting a new\nbenchmark on the CMATERdb 3.1.3.3 with recognition accuracy of 90.33%,\nrepresenting an improvement of nearly 10%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this work, a novel deep learning technique for the recognition of\nhandwritten Bangla isolated compound character is presented and a new benchmark\nof recognition accuracy on the CMATERdb 3.1.3.3 dataset is reported. Greedy\nlayer wise training of Deep Neural Network has helped to make significant\nstrides in various pattern recognition problems. We employ layerwise training\nto Deep Convolutional Neural Networks (DCNN) in a supervised fashion and\naugment the training process with the RMSProp algorithm to achieve faster\nconvergence. We compare results with those obtained from standard shallow\nlearning methods with predefined features, as well as standard DCNNs.\nSupervised layerwise trained DCNNs are found to outperform standard shallow\nlearning models such as Support Vector Machines as well as regular DCNNs of\nsimilar architecture by achieving error rate of 9.67% thereby setting a new\nbenchmark on the CMATERdb 3.1.3.3 with recognition accuracy of 90.33%,\nrepresenting an improvement of nearly 10%."}, "authors": ["Saikat Roy", "Nibaran Das", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patrec.2017.03.004", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1802.00671v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1802.00671v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1802.00671v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1802.00671v1", "arxiv_comment": null, "journal_reference": "Pattern Recognition Letters, Elsevier, Vol. 90, Pages 15-21, 2017", "doi": "10.1016/j.patrec.2017.03.004"}
{"id": "http://arxiv.org/abs/1806.08037v1", "guidislink": true, "updated": "2018-06-21T01:30:30Z", "updated_parsed": [2018, 6, 21, 1, 30, 30, 3, 172, 0], "published": "2018-06-21T01:30:30Z", "published_parsed": [2018, 6, 21, 1, 30, 30, 3, 172, 0], "title": "Pixel-level Reconstruction and Classification for Noisy Handwritten\n  Bangla Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Pixel-level Reconstruction and Classification for Noisy Handwritten\n  Bangla Characters"}, "summary": "Classification techniques for images of handwritten characters are\nsusceptible to noise. Quadtrees can be an efficient representation for learning\nfrom sparse features. In this paper, we improve the effectiveness of\nprobabilistic quadtrees by using a pixel level classifier to extract the\ncharacter pixels and remove noise from handwritten character images. The pixel\nlevel denoiser (a deep belief network) uses the map responses obtained from a\npretrained CNN as features for reconstructing the characters eliminating noise.\nWe experimentally demonstrate the effectiveness of our approach by\nreconstructing and classifying a noisy version of handwritten Bangla Numeral\nand Basic Character datasets.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Classification techniques for images of handwritten characters are\nsusceptible to noise. Quadtrees can be an efficient representation for learning\nfrom sparse features. In this paper, we improve the effectiveness of\nprobabilistic quadtrees by using a pixel level classifier to extract the\ncharacter pixels and remove noise from handwritten character images. The pixel\nlevel denoiser (a deep belief network) uses the map responses obtained from a\npretrained CNN as features for reconstructing the characters eliminating noise.\nWe experimentally demonstrate the effectiveness of our approach by\nreconstructing and classifying a noisy version of handwritten Bangla Numeral\nand Basic Character datasets."}, "authors": ["Manohar Karki", "Qun Liu", "Robert DiBiano", "Saikat Basu", "Supratik Mukhopadhyay"], "author_detail": {"name": "Supratik Mukhopadhyay"}, "author": "Supratik Mukhopadhyay", "arxiv_comment": "Paper was accepted at the 16th International Conference on Frontiers\n  in Handwriting Recognition (ICFHR 2018)", "links": [{"href": "http://arxiv.org/abs/1806.08037v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1806.08037v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1806.08037v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1806.08037v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1907.07826v1", "guidislink": true, "updated": "2019-07-18T01:00:42Z", "updated_parsed": [2019, 7, 18, 1, 0, 42, 3, 199, 0], "published": "2019-07-18T01:00:42Z", "published_parsed": [2019, 7, 18, 1, 0, 42, 3, 199, 0], "title": "Comparison of Classical Machine Learning Approaches on Bangla Textual\n  Emotion Analysis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Comparison of Classical Machine Learning Approaches on Bangla Textual\n  Emotion Analysis"}, "summary": "Detecting emotions from text is an extension of simple sentiment polarity\ndetection. Instead of considering only positive or negative sentiments,\nemotions are conveyed using more tangible manner; thus, they can be expressed\nas many shades of gray. This paper manifests the results of our experimentation\nfor fine-grained emotion analysis on Bangla text. We gathered and annotated a\ntext corpus consisting of user comments from several Facebook groups regarding\nsocio-economic and political issues, and we made efforts to extract the basic\nemotions (sadness, happiness, disgust, surprise, fear, anger) conveyed through\nthese comments. Finally, we compared the results of the five most popular\nclassical machine learning techniques namely Naive Bayes, Decision Tree,\nk-Nearest Neighbor (k-NN), Support Vector Machine (SVM) and K-Means Clustering\nwith several combinations of features. Our best model (SVM with a non-linear\nradial-basis function (RBF) kernel) achieved an overall average accuracy score\nof 52.98% and an F1 score (macro) of 0.3324", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Detecting emotions from text is an extension of simple sentiment polarity\ndetection. Instead of considering only positive or negative sentiments,\nemotions are conveyed using more tangible manner; thus, they can be expressed\nas many shades of gray. This paper manifests the results of our experimentation\nfor fine-grained emotion analysis on Bangla text. We gathered and annotated a\ntext corpus consisting of user comments from several Facebook groups regarding\nsocio-economic and political issues, and we made efforts to extract the basic\nemotions (sadness, happiness, disgust, surprise, fear, anger) conveyed through\nthese comments. Finally, we compared the results of the five most popular\nclassical machine learning techniques namely Naive Bayes, Decision Tree,\nk-Nearest Neighbor (k-NN), Support Vector Machine (SVM) and K-Means Clustering\nwith several combinations of features. Our best model (SVM with a non-linear\nradial-basis function (RBF) kernel) achieved an overall average accuracy score\nof 52.98% and an F1 score (macro) of 0.3324"}, "authors": ["Md. Ataur Rahman", "Md. Hanif Seddiqui"], "author_detail": {"name": "Md. Hanif Seddiqui"}, "author": "Md. Hanif Seddiqui", "links": [{"href": "http://arxiv.org/abs/1907.07826v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1907.07826v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1907.07826v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1907.07826v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1908.08987v1", "guidislink": true, "updated": "2019-08-11T08:01:58Z", "updated_parsed": [2019, 8, 11, 8, 1, 58, 6, 223, 0], "published": "2019-08-11T08:01:58Z", "published_parsed": [2019, 8, 11, 8, 1, 58, 6, 223, 0], "title": "PCGAN-CHAR: Progressively Trained Classifier Generative Adversarial\n  Networks for Classification of Noisy Handwritten Bangla Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "PCGAN-CHAR: Progressively Trained Classifier Generative Adversarial\n  Networks for Classification of Noisy Handwritten Bangla Characters"}, "summary": "Due to the sparsity of features, noise has proven to be a great inhibitor in\nthe classification of handwritten characters. To combat this, most techniques\nperform denoising of the data before classification. In this paper, we\nconsolidate the approach by training an all-in-one model that is able to\nclassify even noisy characters. For classification, we progressively train a\nclassifier generative adversarial network on the characters from low to high\nresolution. We show that by learning the features at each resolution\nindependently a trained model is able to accurately classify characters even in\nthe presence of noise. We experimentally demonstrate the effectiveness of our\napproach by classifying noisy versions of MNIST, handwritten Bangla Numeral,\nand Basic Character datasets.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Due to the sparsity of features, noise has proven to be a great inhibitor in\nthe classification of handwritten characters. To combat this, most techniques\nperform denoising of the data before classification. In this paper, we\nconsolidate the approach by training an all-in-one model that is able to\nclassify even noisy characters. For classification, we progressively train a\nclassifier generative adversarial network on the characters from low to high\nresolution. We show that by learning the features at each resolution\nindependently a trained model is able to accurately classify characters even in\nthe presence of noise. We experimentally demonstrate the effectiveness of our\napproach by classifying noisy versions of MNIST, handwritten Bangla Numeral,\nand Basic Character datasets."}, "authors": ["Qun Liu", "Edward Collier", "Supratik Mukhopadhyay"], "author_detail": {"name": "Supratik Mukhopadhyay"}, "author": "Supratik Mukhopadhyay", "arxiv_comment": "Paper was accepted at the 21st International Conference on\n  Asia-Pacific Digital Libraries (ICADL 2019)", "links": [{"href": "http://arxiv.org/abs/1908.08987v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1908.08987v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1908.08987v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1908.08987v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1912.11612v1", "guidislink": true, "updated": "2019-12-25T07:31:44Z", "updated_parsed": [2019, 12, 25, 7, 31, 44, 2, 359, 0], "published": "2019-12-25T07:31:44Z", "published_parsed": [2019, 12, 25, 7, 31, 44, 2, 359, 0], "title": "N-gram Statistical Stemmer for Bangla Corpus", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "N-gram Statistical Stemmer for Bangla Corpus"}, "summary": "Stemming is a process that can be utilized to trim inflected words to stem or\nroot form. It is useful for enhancing the retrieval effectiveness, especially\nfor text search in order to solve the mismatch problems. Previous research on\nBangla stemming mostly relied on eliminating multiple suffixes from a solitary\nword through a recursive rule based procedure to recover progressively\napplicable relative root. Our proposed system has enhanced the aforementioned\nexploration by actualizing one of the stemming algorithms called N-gram\nstemming. By utilizing an affiliation measure called dice coefficient, related\nsets of words are clustered depending on their character structure. The\nsmallest word in one cluster may be considered as the stem. We additionally\nanalyzed Affinity Propagation clustering algorithms with coefficient similarity\nas well as with median similarity. Our result indicates N-gram stemming\ntechniques to be effective in general which gave us around 87% accurate\nclusters.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Stemming is a process that can be utilized to trim inflected words to stem or\nroot form. It is useful for enhancing the retrieval effectiveness, especially\nfor text search in order to solve the mismatch problems. Previous research on\nBangla stemming mostly relied on eliminating multiple suffixes from a solitary\nword through a recursive rule based procedure to recover progressively\napplicable relative root. Our proposed system has enhanced the aforementioned\nexploration by actualizing one of the stemming algorithms called N-gram\nstemming. By utilizing an affiliation measure called dice coefficient, related\nsets of words are clustered depending on their character structure. The\nsmallest word in one cluster may be considered as the stem. We additionally\nanalyzed Affinity Propagation clustering algorithms with coefficient similarity\nas well as with median similarity. Our result indicates N-gram stemming\ntechniques to be effective in general which gave us around 87% accurate\nclusters."}, "authors": ["Rabeya Sadia", "Md Ataur Rahman", "Md Hanif Seddiqui"], "author_detail": {"name": "Md Hanif Seddiqui"}, "author": "Md Hanif Seddiqui", "links": [{"href": "http://arxiv.org/abs/1912.11612v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1912.11612v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1912.11612v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1912.11612v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2004.12769v1", "guidislink": true, "updated": "2020-04-27T13:18:58Z", "updated_parsed": [2020, 4, 27, 13, 18, 58, 0, 118, 0], "published": "2020-04-27T13:18:58Z", "published_parsed": [2020, 4, 27, 13, 18, 58, 0, 118, 0], "title": "A Skip-connected Multi-column Network for Isolated Handwritten Bangla\n  Character and Digit recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Skip-connected Multi-column Network for Isolated Handwritten Bangla\n  Character and Digit recognition"}, "summary": "Finding local invariant patterns in handwrit-ten characters and/or digits for\noptical character recognition is a difficult task. Variations in writing styles\nfrom one person to another make this task challenging. We have proposed a\nnon-explicit feature extraction method using a multi-scale multi-column skip\nconvolutional neural network in this work. Local and global features extracted\nfrom different layers of the proposed architecture are combined to derive the\nfinal feature descriptor encoding a character or digit image. Our method is\nevaluated on four publicly available datasets of isolated handwritten Bangla\ncharacters and digits. Exhaustive comparative analysis against contemporary\nmethods establishes the efficacy of our proposed approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Finding local invariant patterns in handwrit-ten characters and/or digits for\noptical character recognition is a difficult task. Variations in writing styles\nfrom one person to another make this task challenging. We have proposed a\nnon-explicit feature extraction method using a multi-scale multi-column skip\nconvolutional neural network in this work. Local and global features extracted\nfrom different layers of the proposed architecture are combined to derive the\nfinal feature descriptor encoding a character or digit image. Our method is\nevaluated on four publicly available datasets of isolated handwritten Bangla\ncharacters and digits. Exhaustive comparative analysis against contemporary\nmethods establishes the efficacy of our proposed approach."}, "authors": ["Animesh Singh", "Ritesh Sarkhel", "Nibaran Das", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/2004.12769v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.12769v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.12769v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.12769v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2009.08037v1", "guidislink": true, "updated": "2020-09-17T03:14:27Z", "updated_parsed": [2020, 9, 17, 3, 14, 27, 3, 261, 0], "published": "2020-09-17T03:14:27Z", "published_parsed": [2020, 9, 17, 3, 14, 27, 3, 261, 0], "title": "Word Segmentation from Unconstrained Handwritten Bangla Document Images\n  using Distance Transform", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word Segmentation from Unconstrained Handwritten Bangla Document Images\n  using Distance Transform"}, "summary": "Segmentation of handwritten document images into text lines and words is one\nof the most significant and challenging tasks in the development of a complete\nOptical Character Recognition (OCR) system. This paper addresses the automatic\nsegmentation of text words directly from unconstrained Bangla handwritten\ndocument images. The popular Distance transform (DT) algorithm is applied for\nlocating the outer boundary of the word images. This technique is free from\ngenerating the over-segmented words. A simple post-processing procedure is\napplied to isolate the under-segmented word images, if any. The proposed\ntechnique is tested on 50 random images taken from CMATERdb1.1.1 database.\nSatisfactory result is achieved with a segmentation accuracy of 91.88% which\nconfirms the robustness of the proposed methodology.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Segmentation of handwritten document images into text lines and words is one\nof the most significant and challenging tasks in the development of a complete\nOptical Character Recognition (OCR) system. This paper addresses the automatic\nsegmentation of text words directly from unconstrained Bangla handwritten\ndocument images. The popular Distance transform (DT) algorithm is applied for\nlocating the outer boundary of the word images. This technique is free from\ngenerating the over-segmented words. A simple post-processing procedure is\napplied to isolate the under-segmented word images, if any. The proposed\ntechnique is tested on 50 random images taken from CMATERdb1.1.1 database.\nSatisfactory result is achieved with a segmentation accuracy of 91.88% which\nconfirms the robustness of the proposed methodology."}, "authors": ["Pawan Kumar Singh", "Shubham Sinha", "Sagnik Pal Chowdhury", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "12 pages, 5 figures, conference", "links": [{"href": "http://arxiv.org/abs/2009.08037v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2009.08037v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.MM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68U10, 68U15", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2009.08037v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2009.08037v1", "journal_reference": "7th International Conference on Advances in Communication, Network\n  and Computing (CNC),pp. 271-282, 2016", "doi": null}
{"id": "http://arxiv.org/abs/1206.0238v1", "guidislink": true, "updated": "2012-06-01T16:20:41Z", "updated_parsed": [2012, 6, 1, 16, 20, 41, 4, 153, 0], "published": "2012-06-01T16:20:41Z", "published_parsed": [2012, 6, 1, 16, 20, 41, 4, 153, 0], "title": "Rapid Feature Extraction for Optical Character Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Rapid Feature Extraction for Optical Character Recognition"}, "summary": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection."}, "authors": ["M. Zahid Hossain", "M. Ashraful Amin", "Hong Yan"], "author_detail": {"name": "Hong Yan"}, "author": "Hong Yan", "arxiv_comment": "5 pages, 1 figure", "links": [{"href": "http://arxiv.org/abs/1206.0238v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1206.0238v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.5.2; I.7.5", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1206.0238v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1206.0238v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.08156v2", "guidislink": true, "updated": "2018-04-26T18:17:00Z", "updated_parsed": [2018, 4, 26, 18, 17, 0, 3, 116, 0], "published": "2017-01-27T12:38:47Z", "published_parsed": [2017, 1, 27, 12, 38, 47, 4, 27, 0], "title": "A Comprehensive Survey on Bengali Phoneme Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Comprehensive Survey on Bengali Phoneme Recognition"}, "summary": "Hidden Markov model based various phoneme recognition methods for Bengali\nlanguage is reviewed. Automatic phoneme recognition for Bengali language using\nmultilayer neural network is reviewed. Usefulness of multilayer neural network\nover single layer neural network is discussed. Bangla phonetic feature table\nconstruction and enhancement for Bengali speech recognition is also discussed.\nComparison among these methods is discussed.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Hidden Markov model based various phoneme recognition methods for Bengali\nlanguage is reviewed. Automatic phoneme recognition for Bengali language using\nmultilayer neural network is reviewed. Usefulness of multilayer neural network\nover single layer neural network is discussed. Bangla phonetic feature table\nconstruction and enhancement for Bengali speech recognition is also discussed.\nComparison among these methods is discussed."}, "authors": ["Sadia Tasnim Swarna", "Shamim Ehsan", "Md. Saiful Islam", "Marium E Jannat"], "author_detail": {"name": "Marium E Jannat"}, "author": "Marium E Jannat", "arxiv_comment": "7 pages, reference added in phoneme recognition methods", "links": [{"href": "http://arxiv.org/abs/1701.08156v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08156v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.SD", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SD", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08156v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08156v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2008.07853v1", "guidislink": true, "updated": "2020-08-18T11:02:25Z", "updated_parsed": [2020, 8, 18, 11, 2, 25, 1, 231, 0], "published": "2020-08-18T11:02:25Z", "published_parsed": [2020, 8, 18, 11, 2, 25, 1, 231, 0], "title": "Image Pre-processing on NumtaDB for Bengali Handwritten Digit\n  Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Image Pre-processing on NumtaDB for Bengali Handwritten Digit\n  Recognition"}, "summary": "NumtaDB is by far the largest data-set collection for handwritten digits in\nBengali. This is a diverse dataset containing more than 85000 images. But this\ndiversity also makes this dataset very difficult to work with. The goal of this\npaper is to find the benchmark for pre-processed images which gives good\naccuracy on any machine learning models. The reason being, there are no\navailable pre-processed data for Bengali digit recognition to work with like\nthe English digits for MNIST.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "NumtaDB is by far the largest data-set collection for handwritten digits in\nBengali. This is a diverse dataset containing more than 85000 images. But this\ndiversity also makes this dataset very difficult to work with. The goal of this\npaper is to find the benchmark for pre-processed images which gives good\naccuracy on any machine learning models. The reason being, there are no\navailable pre-processed data for Bengali digit recognition to work with like\nthe English digits for MNIST."}, "authors": ["Ovi Paul"], "author_detail": {"name": "Ovi Paul"}, "author": "Ovi Paul", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ICBSLP.2018.8554910", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/2008.07853v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2008.07853v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "5 pages, 8 figures and 4 tables", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2008.07853v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2008.07853v1", "journal_reference": "2018 International Conference on Bangla Speech and Language\n  Processing (ICBSLP), Sylhet, 2018, pp. 1-6", "doi": "10.1109/ICBSLP.2018.8554910"}
{"id": "http://arxiv.org/abs/1501.05495v1", "guidislink": true, "updated": "2015-01-22T13:46:06Z", "updated_parsed": [2015, 1, 22, 13, 46, 6, 3, 22, 0], "published": "2015-01-22T13:46:06Z", "published_parsed": [2015, 1, 22, 13, 46, 6, 3, 22, 0], "title": "A GA Based approach for selection of local features for recognition of\n  handwritten Bangla numerals", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A GA Based approach for selection of local features for recognition of\n  handwritten Bangla numerals"}, "summary": "Soft computing approaches are mainly designed to address the real world\nill-defined, imprecisely formulated problems, combining different kind of novel\nmodels of computation, such as neural networks, genetic algorithms (GAs.\nHandwritten digit recognition is a typical example of one such problem. In the\ncurrent work we have developed a two-pass approach where the first pass\nclassifier performs a coarse classification, based on some global features of\nthe input pattern by restricting the possibility of classification decisions\nwithin a group of classes, smaller than the number of classes considered\ninitially. In the second pass, the group specific classifiers concentrate on\nthe features extracted from the selected local regions, and refine the earlier\ndecision by combining the local and the global features for selecting the true\nclass of the input pattern from the group of candidate classes selected in the\nfirst pass. To optimize the selection of local regions a GA based approach has\nbeen developed here. The maximum recognition performance on Bangla digit\nsamples as achieved on the test set, during the first pass of the two pass\napproach is 93.35%. After combining the results of the two stage classifiers,\nan overall success rate of 95.25% is achieved.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Soft computing approaches are mainly designed to address the real world\nill-defined, imprecisely formulated problems, combining different kind of novel\nmodels of computation, such as neural networks, genetic algorithms (GAs.\nHandwritten digit recognition is a typical example of one such problem. In the\ncurrent work we have developed a two-pass approach where the first pass\nclassifier performs a coarse classification, based on some global features of\nthe input pattern by restricting the possibility of classification decisions\nwithin a group of classes, smaller than the number of classes considered\ninitially. In the second pass, the group specific classifiers concentrate on\nthe features extracted from the selected local regions, and refine the earlier\ndecision by combining the local and the global features for selecting the true\nclass of the input pattern from the group of candidate classes selected in the\nfirst pass. To optimize the selection of local regions a GA based approach has\nbeen developed here. The maximum recognition performance on Bangla digit\nsamples as achieved on the test set, during the first pass of the two pass\napproach is 93.35%. After combining the results of the two stage classifiers,\nan overall success rate of 95.25% is achieved."}, "authors": ["Nibaran Das", "Subhadip Basu", "Punam Kumar Saha", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "In proceedings of UB NE ASEE 2009 conference, University of\n  Bridgeport, USA", "links": [{"href": "http://arxiv.org/abs/1501.05495v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1501.05495v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1501.05495v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1501.05495v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1605.00420v1", "guidislink": true, "updated": "2016-05-02T10:28:07Z", "updated_parsed": [2016, 5, 2, 10, 28, 7, 0, 123, 0], "published": "2016-05-02T10:28:07Z", "published_parsed": [2016, 5, 2, 10, 28, 7, 0, 123, 0], "title": "An Enhanced Harmony Search Method for Bangla Handwritten Character\n  Recognition Using Region Sampling", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An Enhanced Harmony Search Method for Bangla Handwritten Character\n  Recognition Using Region Sampling"}, "summary": "Identification of minimum number of local regions of a handwritten character\nimage, containing well-defined discriminating features which are sufficient for\na minimal but complete description of the character is a challenging task. A\nnew region selection technique based on the idea of an enhanced Harmony Search\nmethodology has been proposed here. The powerful framework of Harmony Search\nhas been utilized to search the region space and detect only the most\ninformative regions for correctly recognizing the handwritten character. The\nproposed method has been tested on handwritten samples of Bangla Basic,\nCompound and mixed (Basic and Compound characters) characters separately with\nSVM based classifier using a longest run based feature-set obtained from the\nimage subregions formed by a CG based quad-tree partitioning approach. Applying\nthis methodology on the above mentioned three types of datasets, respectively\n43.75%, 12.5% and 37.5% gains have been achieved in terms of region reduction\nand 2.3%, 0.6% and 1.2% gains have been achieved in terms of recognition\naccuracy. The results show a sizeable reduction in the minimal number of\ndescriptive regions as well a significant increase in recognition accuracy for\nall the datasets using the proposed technique. Thus the time and cost related\nto feature extraction is decreased without dampening the corresponding\nrecognition accuracy.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Identification of minimum number of local regions of a handwritten character\nimage, containing well-defined discriminating features which are sufficient for\na minimal but complete description of the character is a challenging task. A\nnew region selection technique based on the idea of an enhanced Harmony Search\nmethodology has been proposed here. The powerful framework of Harmony Search\nhas been utilized to search the region space and detect only the most\ninformative regions for correctly recognizing the handwritten character. The\nproposed method has been tested on handwritten samples of Bangla Basic,\nCompound and mixed (Basic and Compound characters) characters separately with\nSVM based classifier using a longest run based feature-set obtained from the\nimage subregions formed by a CG based quad-tree partitioning approach. Applying\nthis methodology on the above mentioned three types of datasets, respectively\n43.75%, 12.5% and 37.5% gains have been achieved in terms of region reduction\nand 2.3%, 0.6% and 1.2% gains have been achieved in terms of recognition\naccuracy. The results show a sizeable reduction in the minimal number of\ndescriptive regions as well a significant increase in recognition accuracy for\nall the datasets using the proposed technique. Thus the time and cost related\nto feature extraction is decreased without dampening the corresponding\nrecognition accuracy."}, "authors": ["Ritesh Sarkhel", "Amit K Saha", "Nibaran Das"], "author_detail": {"name": "Nibaran Das"}, "author": "Nibaran Das", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ReTIS.2015.7232899", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1605.00420v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1605.00420v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "2nd IEEE International Conference on Recent Trends in Information\n  Systems, 2015", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1605.00420v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1605.00420v1", "journal_reference": null, "doi": "10.1109/ReTIS.2015.7232899"}
{"id": "http://arxiv.org/abs/2101.05081v1", "guidislink": true, "updated": "2020-12-10T15:36:41Z", "updated_parsed": [2020, 12, 10, 15, 36, 41, 3, 345, 0], "published": "2020-12-10T15:36:41Z", "published_parsed": [2020, 12, 10, 15, 36, 41, 3, 345, 0], "title": "Deep Learning Approach Combining Lightweight CNN Architecture with\n  Transfer Learning: An Automatic Approach for the Detection and Recognition of\n  Bangladeshi Banknotes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Deep Learning Approach Combining Lightweight CNN Architecture with\n  Transfer Learning: An Automatic Approach for the Detection and Recognition of\n  Bangladeshi Banknotes"}, "summary": "Automatic detection and recognition of banknotes can be a very useful\ntechnology for people with visual difficulties and also for the banks itself by\nproviding efficient management for handling different paper currencies.\nLightweight models can easily be integrated into any handy IoT based\ngadgets/devices. This article presents our experiments on several\nstate-of-the-art deep learning methods based on Lightweight Convolutional\nNeural Network architectures combining with transfer learning. ResNet152v2,\nMobileNet, and NASNetMobile were used as the base models with two different\ndatasets containing Bangladeshi banknote images. The Bangla Currency dataset\nhas 8000 Bangladeshi banknote images where the Bangla Money dataset consists of\n1970 images. The performances of the models were measured using both the\ndatasets and the combination of the two datasets. In order to achieve maximum\nefficiency, we used various augmentations, hyperparameter tuning, and\noptimizations techniques. We have achieved maximum test accuracy of 98.88\\% on\n8000 images dataset using MobileNet, 100\\% on the 1970 images dataset using\nNASNetMobile, and 97.77\\% on the combined dataset (9970 images) using\nMobileNet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic detection and recognition of banknotes can be a very useful\ntechnology for people with visual difficulties and also for the banks itself by\nproviding efficient management for handling different paper currencies.\nLightweight models can easily be integrated into any handy IoT based\ngadgets/devices. This article presents our experiments on several\nstate-of-the-art deep learning methods based on Lightweight Convolutional\nNeural Network architectures combining with transfer learning. ResNet152v2,\nMobileNet, and NASNetMobile were used as the base models with two different\ndatasets containing Bangladeshi banknote images. The Bangla Currency dataset\nhas 8000 Bangladeshi banknote images where the Bangla Money dataset consists of\n1970 images. The performances of the models were measured using both the\ndatasets and the combination of the two datasets. In order to achieve maximum\nefficiency, we used various augmentations, hyperparameter tuning, and\noptimizations techniques. We have achieved maximum test accuracy of 98.88\\% on\n8000 images dataset using MobileNet, 100\\% on the 1970 images dataset using\nNASNetMobile, and 97.77\\% on the combined dataset (9970 images) using\nMobileNet."}, "authors": ["Ali Hasan Md. Linkon", "Md. Mahir Labib", "Faisal Haque Bappy", "Soumik Sarker", "Marium-E-Jannat", "Md Saiful Islam"], "author_detail": {"name": "Md Saiful Islam"}, "author": "Md Saiful Islam", "arxiv_comment": "4 pages", "links": [{"href": "http://arxiv.org/abs/2101.05081v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2101.05081v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2101.05081v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2101.05081v1", "journal_reference": "2020 11th International Conference on Electrical and Computer\n  Engineering (ICECE)", "doi": null}
{"id": "http://arxiv.org/abs/1708.00227v1", "guidislink": true, "updated": "2017-08-01T09:52:03Z", "updated_parsed": [2017, 8, 1, 9, 52, 3, 1, 213, 0], "published": "2017-08-01T09:52:03Z", "published_parsed": [2017, 8, 1, 9, 52, 3, 1, 213, 0], "title": "HMM-based Indic Handwritten Word Recognition using Zone Segmentation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "HMM-based Indic Handwritten Word Recognition using Zone Segmentation"}, "summary": "This paper presents a novel approach towards Indic handwritten word\nrecognition using zone-wise information. Because of complex nature due to\ncompound characters, modifiers, overlapping and touching, etc., character\nsegmentation and recognition is a tedious job in Indic scripts (e.g.\nDevanagari, Bangla, Gurumukhi, and other similar scripts). To avoid character\nsegmentation in such scripts, HMM-based sequence modeling has been used earlier\nin holistic way. This paper proposes an efficient word recognition framework by\nsegmenting the handwritten word images horizontally into three zones (upper,\nmiddle and lower) and recognize the corresponding zones. The main aim of this\nzone segmentation approach is to reduce the number of distinct component\nclasses compared to the total number of classes in Indic scripts. As a result,\nuse of this zone segmentation approach enhances the recognition performance of\nthe system. The components in middle zone where characters are mostly touching\nare recognized using HMM. After the recognition of middle zone, HMM based\nViterbi forced alignment is applied to mark the left and right boundaries of\nthe characters. Next, the residue components, if any, in upper and lower zones\nin their respective boundary are combined to achieve the final word level\nrecognition. Water reservoir feature has been integrated in this framework to\nimprove the zone segmentation and character alignment defects while\nsegmentation. A novel sliding window-based feature, called Pyramid Histogram of\nOriented Gradient (PHOG) is proposed for middle zone recognition. An exhaustive\nexperiment is performed on two Indic scripts namely, Bangla and Devanagari for\nthe performance evaluation. From the experiment, it has been noted that\nproposed zone-wise recognition improves accuracy with respect to the\ntraditional way of Indic word recognition.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents a novel approach towards Indic handwritten word\nrecognition using zone-wise information. Because of complex nature due to\ncompound characters, modifiers, overlapping and touching, etc., character\nsegmentation and recognition is a tedious job in Indic scripts (e.g.\nDevanagari, Bangla, Gurumukhi, and other similar scripts). To avoid character\nsegmentation in such scripts, HMM-based sequence modeling has been used earlier\nin holistic way. This paper proposes an efficient word recognition framework by\nsegmenting the handwritten word images horizontally into three zones (upper,\nmiddle and lower) and recognize the corresponding zones. The main aim of this\nzone segmentation approach is to reduce the number of distinct component\nclasses compared to the total number of classes in Indic scripts. As a result,\nuse of this zone segmentation approach enhances the recognition performance of\nthe system. The components in middle zone where characters are mostly touching\nare recognized using HMM. After the recognition of middle zone, HMM based\nViterbi forced alignment is applied to mark the left and right boundaries of\nthe characters. Next, the residue components, if any, in upper and lower zones\nin their respective boundary are combined to achieve the final word level\nrecognition. Water reservoir feature has been integrated in this framework to\nimprove the zone segmentation and character alignment defects while\nsegmentation. A novel sliding window-based feature, called Pyramid Histogram of\nOriented Gradient (PHOG) is proposed for middle zone recognition. An exhaustive\nexperiment is performed on two Indic scripts namely, Bangla and Devanagari for\nthe performance evaluation. From the experiment, it has been noted that\nproposed zone-wise recognition improves accuracy with respect to the\ntraditional way of Indic word recognition."}, "authors": ["Partha Pratim Roy", "Ayan Kumar Bhunia", "Ayan Das", "Prasenjit Dey", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patcog.2016.04.012", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1708.00227v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1708.00227v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in Pattern Recognition(2016)", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1708.00227v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1708.00227v1", "journal_reference": "Pattern Recognition, Volume 60, December 2016, Pages 1057-1075", "doi": "10.1016/j.patcog.2016.04.012"}
{"id": "http://arxiv.org/abs/1708.05529v6", "guidislink": true, "updated": "2018-07-30T10:41:30Z", "updated_parsed": [2018, 7, 30, 10, 41, 30, 0, 211, 0], "published": "2017-08-18T07:47:05Z", "published_parsed": [2017, 8, 18, 7, 47, 5, 4, 230, 0], "title": "Word Searching in Scene Image and Video Frame in Multi-Script Scenario\n  using Dynamic Shape Coding", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word Searching in Scene Image and Video Frame in Multi-Script Scenario\n  using Dynamic Shape Coding"}, "summary": "Retrieval of text information from natural scene images and video frames is a\nchallenging task due to its inherent problems like complex character shapes,\nlow resolution, background noise, etc. Available OCR systems often fail to\nretrieve such information in scene/video frames. Keyword spotting, an\nalternative way to retrieve information, performs efficient text searching in\nsuch scenarios. However, current word spotting techniques in scene/video images\nare script-specific and they are mainly developed for Latin script. This paper\npresents a novel word spotting framework using dynamic shape coding for text\nretrieval in natural scene image and video frames. The framework is designed to\nsearch query keyword from multiple scripts with the help of on-the-fly\nscript-wise keyword generation for the corresponding script. We have used a\ntwo-stage word spotting approach using Hidden Markov Model (HMM) to detect the\ntranslated keyword in a given text line by identifying the script of the line.\nA novel unsupervised dynamic shape coding based scheme has been used to group\nsimilar shape characters to avoid confusion and to improve text alignment.\nNext, the hypotheses locations are verified to improve retrieval performance.\nTo evaluate the proposed system for searching keyword from natural scene image\nand video frames, we have considered two popular Indic scripts such as Bangla\n(Bengali) and Devanagari along with English. Inspired by the zone-wise\nrecognition approach in Indic scripts[1], zone-wise text information has been\nused to improve the traditional word spotting performance in Indic scripts. For\nour experiment, a dataset consisting of images of different scenes and video\nframes of English, Bangla and Devanagari scripts were considered. The results\nobtained showed the effectiveness of our proposed word spotting approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Retrieval of text information from natural scene images and video frames is a\nchallenging task due to its inherent problems like complex character shapes,\nlow resolution, background noise, etc. Available OCR systems often fail to\nretrieve such information in scene/video frames. Keyword spotting, an\nalternative way to retrieve information, performs efficient text searching in\nsuch scenarios. However, current word spotting techniques in scene/video images\nare script-specific and they are mainly developed for Latin script. This paper\npresents a novel word spotting framework using dynamic shape coding for text\nretrieval in natural scene image and video frames. The framework is designed to\nsearch query keyword from multiple scripts with the help of on-the-fly\nscript-wise keyword generation for the corresponding script. We have used a\ntwo-stage word spotting approach using Hidden Markov Model (HMM) to detect the\ntranslated keyword in a given text line by identifying the script of the line.\nA novel unsupervised dynamic shape coding based scheme has been used to group\nsimilar shape characters to avoid confusion and to improve text alignment.\nNext, the hypotheses locations are verified to improve retrieval performance.\nTo evaluate the proposed system for searching keyword from natural scene image\nand video frames, we have considered two popular Indic scripts such as Bangla\n(Bengali) and Devanagari along with English. Inspired by the zone-wise\nrecognition approach in Indic scripts[1], zone-wise text information has been\nused to improve the traditional word spotting performance in Indic scripts. For\nour experiment, a dataset consisting of images of different scenes and video\nframes of English, Bangla and Devanagari scripts were considered. The results\nobtained showed the effectiveness of our proposed word spotting approach."}, "authors": ["Partha Pratim Roy", "Ayan Kumar Bhunia", "Avirup Bhattacharyya", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "arxiv_comment": "Multimedia Tools and Applications, Springer", "links": [{"href": "http://arxiv.org/abs/1708.05529v6", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1708.05529v6", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1708.05529v6", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1708.05529v6", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1410.4013v1", "guidislink": true, "updated": "2014-10-15T11:19:33Z", "updated_parsed": [2014, 10, 15, 11, 19, 33, 2, 288, 0], "published": "2014-10-15T11:19:33Z", "published_parsed": [2014, 10, 15, 11, 19, 33, 2, 288, 0], "title": "A two-pass fuzzy-geno approach to pattern classification", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A two-pass fuzzy-geno approach to pattern classification"}, "summary": "The work presents an extension of the fuzzy approach to 2-D shape recognition\n[1] through refinement of initial or coarse classification decisions under a\ntwo pass approach. In this approach, an unknown pattern is classified by\nrefining possible classification decisions obtained through coarse\nclassification of the same. To build a fuzzy model of a pattern class\nhorizontal and vertical fuzzy partitions on the sample images of the class are\noptimized using genetic algorithm. To make coarse classification decisions\nabout an unknown pattern, the fuzzy representation of the pattern is compared\nwith models of all pattern classes through a specially designed similarity\nmeasure. Coarse classification decisions are refined in the second pass to\nobtain the final classification decision of the unknown pattern. To do so,\noptimized horizontal and vertical fuzzy partitions are again created on certain\nregions of the image frame, specific to each group of similar type of pattern\nclasses. It is observed through experiments that the technique improves the\noverall recognition rate from 86.2%, in the first pass, to 90.4% after the\nsecond pass, with 500 training samples of handwritten digits.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presents an extension of the fuzzy approach to 2-D shape recognition\n[1] through refinement of initial or coarse classification decisions under a\ntwo pass approach. In this approach, an unknown pattern is classified by\nrefining possible classification decisions obtained through coarse\nclassification of the same. To build a fuzzy model of a pattern class\nhorizontal and vertical fuzzy partitions on the sample images of the class are\noptimized using genetic algorithm. To make coarse classification decisions\nabout an unknown pattern, the fuzzy representation of the pattern is compared\nwith models of all pattern classes through a specially designed similarity\nmeasure. Coarse classification decisions are refined in the second pass to\nobtain the final classification decision of the unknown pattern. To do so,\noptimized horizontal and vertical fuzzy partitions are again created on certain\nregions of the image frame, specific to each group of similar type of pattern\nclasses. It is observed through experiments that the technique improves the\noverall recognition rate from 86.2%, in the first pass, to 90.4% after the\nsecond pass, with 500 training samples of handwritten digits."}, "authors": ["Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1410.4013v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.4013v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.4013v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.4013v1", "arxiv_comment": null, "journal_reference": "Proc. of International Conference on Computer Processing of\n  Bangla, pp. 130-134, Feb-2006, Dhaka", "doi": null}
{"id": "http://arxiv.org/abs/1009.4979v1", "guidislink": true, "updated": "2010-09-25T06:27:49Z", "updated_parsed": [2010, 9, 25, 6, 27, 49, 5, 268, 0], "published": "2010-09-25T06:27:49Z", "published_parsed": [2010, 9, 25, 6, 27, 49, 5, 268, 0], "title": "Smart Bengali Cell Phone Keypad Layout", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Smart Bengali Cell Phone Keypad Layout"}, "summary": "Nowadays cell phone is the most common communicating used by mass people. SMS\nbased communication is a cheap and popular communication method. It is human\ntendency to have the opportunity to write SMS in their mother language. Text\ninput in mother language is more flexible when the alphabets of that language\nare printed on the keypad. Bangla mobile keypad based on phonetics has been\nproposed earlier. But the keypad is not scientific from frequency and\nflexibility point of view. Since it is not a feasible solution in this paper we\nhave proposed an efficient Bengali keypad for cell phone and other cellular\ndevice. The proposed keypad is based on the frequency of the alphabets in\nBengali language and also with the view of structure of human finger movements.\nWe took the two points in count to provide a flexible and fast cell phone\nkeypad.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Nowadays cell phone is the most common communicating used by mass people. SMS\nbased communication is a cheap and popular communication method. It is human\ntendency to have the opportunity to write SMS in their mother language. Text\ninput in mother language is more flexible when the alphabets of that language\nare printed on the keypad. Bangla mobile keypad based on phonetics has been\nproposed earlier. But the keypad is not scientific from frequency and\nflexibility point of view. Since it is not a feasible solution in this paper we\nhave proposed an efficient Bengali keypad for cell phone and other cellular\ndevice. The proposed keypad is based on the frequency of the alphabets in\nBengali language and also with the view of structure of human finger movements.\nWe took the two points in count to provide a flexible and fast cell phone\nkeypad."}, "authors": ["Md. Abul Kalam Azad", "Rezwana Sharmeen", "Shabbir Ahmad", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "4 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4979v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4979v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4979v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4979v1", "journal_reference": "Proc. 8th International Conference on Computer and Information\n  Technology (ICCIT 2005), Dhaka, Bangladesh, pp. 1208-1211, Dec. 2005", "doi": null}
{"id": "http://arxiv.org/abs/1707.08385v1", "guidislink": true, "updated": "2017-07-26T11:40:13Z", "updated_parsed": [2017, 7, 26, 11, 40, 13, 2, 207, 0], "published": "2017-07-26T11:40:13Z", "published_parsed": [2017, 7, 26, 11, 40, 13, 2, 207, 0], "title": "A Novel Transfer Learning Approach upon Hindi, Arabic, and Bangla\n  Numerals using Convolutional Neural Networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Novel Transfer Learning Approach upon Hindi, Arabic, and Bangla\n  Numerals using Convolutional Neural Networks"}, "summary": "Increased accuracy in predictive models for handwritten character recognition\nwill open up new frontiers for optical character recognition. Major drawbacks\nof predictive machine learning models are headed by the elongated training time\ntaken by some models, and the requirement that training and test data be in the\nsame feature space and consist of the same distribution. In this study, these\nobstacles are minimized by presenting a model for transferring knowledge from\none task to another. This model is presented for the recognition of handwritten\nnumerals in Indic languages. The model utilizes convolutional neural networks\nwith backpropagation for error reduction and dropout for data overfitting. The\noutput performance of the proposed neural network is shown to have closely\nmatched other state-of-the-art methods using only a fraction of time used by\nthe state-of-the-arts.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Increased accuracy in predictive models for handwritten character recognition\nwill open up new frontiers for optical character recognition. Major drawbacks\nof predictive machine learning models are headed by the elongated training time\ntaken by some models, and the requirement that training and test data be in the\nsame feature space and consist of the same distribution. In this study, these\nobstacles are minimized by presenting a model for transferring knowledge from\none task to another. This model is presented for the recognition of handwritten\nnumerals in Indic languages. The model utilizes convolutional neural networks\nwith backpropagation for error reduction and dropout for data overfitting. The\noutput performance of the proposed neural network is shown to have closely\nmatched other state-of-the-art methods using only a fraction of time used by\nthe state-of-the-arts."}, "authors": ["Abdul Kawsar Tushar", "Akm Ashiquzzaman", "Afia Afrin", "Md. Rashedul Islam"], "author_detail": {"name": "Md. Rashedul Islam"}, "author": "Md. Rashedul Islam", "arxiv_comment": "10 pages; 2 figures, 4 tables; conference - International Conference\n  On Computational Vision and Bio Inspired Computing 2017 (http://iccvbic.com/)\n  (accepted)", "links": [{"href": "http://arxiv.org/abs/1707.08385v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1707.08385v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1707.08385v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1707.08385v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1804.04475v1", "guidislink": true, "updated": "2018-04-12T12:46:08Z", "updated_parsed": [2018, 4, 12, 12, 46, 8, 3, 102, 0], "published": "2018-04-12T12:46:08Z", "published_parsed": [2018, 4, 12, 12, 46, 8, 3, 102, 0], "title": "Learning Multilingual Embeddings for Cross-Lingual Information Retrieval\n  in the Presence of Topically Aligned Corpora", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Learning Multilingual Embeddings for Cross-Lingual Information Retrieval\n  in the Presence of Topically Aligned Corpora"}, "summary": "Cross-lingual information retrieval is a challenging task in the absence of\naligned parallel corpora. In this paper, we address this problem by considering\ntopically aligned corpora designed for evaluating an IR setup. To emphasize, we\nneither use any sentence-aligned corpora or document-aligned corpora, nor do we\nuse any language specific resources such as dictionary, thesaurus, or grammar\nrules. Instead, we use an embedding into a common space and learn word\ncorrespondences directly from there. We test our proposed approach for\nbilingual IR on standard FIRE datasets for Bangla, Hindi and English. The\nproposed method is superior to the state-of-the-art method not only for IR\nevaluation measures but also in terms of time requirements. We extend our\nmethod successfully to the trilingual setting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Cross-lingual information retrieval is a challenging task in the absence of\naligned parallel corpora. In this paper, we address this problem by considering\ntopically aligned corpora designed for evaluating an IR setup. To emphasize, we\nneither use any sentence-aligned corpora or document-aligned corpora, nor do we\nuse any language specific resources such as dictionary, thesaurus, or grammar\nrules. Instead, we use an embedding into a common space and learn word\ncorrespondences directly from there. We test our proposed approach for\nbilingual IR on standard FIRE datasets for Bangla, Hindi and English. The\nproposed method is superior to the state-of-the-art method not only for IR\nevaluation measures but also in terms of time requirements. We extend our\nmethod successfully to the trilingual setting."}, "authors": ["Mitodru Niyogi", "Kripabandhu Ghosh", "Arnab Bhattacharya"], "author_detail": {"name": "Arnab Bhattacharya"}, "author": "Arnab Bhattacharya", "links": [{"href": "http://arxiv.org/abs/1804.04475v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1804.04475v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1804.04475v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1804.04475v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1902.11133v1", "guidislink": true, "updated": "2019-02-25T13:52:53Z", "updated_parsed": [2019, 2, 25, 13, 52, 53, 0, 56, 0], "published": "2019-02-25T13:52:53Z", "published_parsed": [2019, 2, 25, 13, 52, 53, 0, 56, 0], "title": "Bengali Handwritten Character Classification using Transfer Learning on\n  Deep Convolutional Neural Network", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bengali Handwritten Character Classification using Transfer Learning on\n  Deep Convolutional Neural Network"}, "summary": "In this paper, we propose a solution which uses state-of-the-art techniques\nin Deep Learning to tackle the problem of Bengali Handwritten Character\nRecognition ( HCR ). Our method uses lesser iterations to train than most other\ncomparable methods. We employ Transfer Learning on ResNet 50, a\nstate-of-the-art deep Convolutional Neural Network Model, pretrained on\nImageNet dataset. We also use other techniques like a modified version of One\nCycle Policy, varying the input image sizes etc. to ensure that our training\noccurs fast. We use the BanglaLekha-Isolated Dataset for evaluation of our\ntechnique which consists of 84 classes (50 Basic, 10 Numerals and 24 Compound\nCharacters). We are able to achieve 96.12% accuracy in just 47 epochs on\nBanglaLekha-Isolated dataset. When comparing our method with that of other\nresearchers, considering number of classes and without using Ensemble Learning,\nthe proposed solution achieves state of the art result for Handwritten Bengali\nCharacter Recognition. Code and weight files are available at\nhttps://github.com/swagato-c/bangla-hwcr-present.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we propose a solution which uses state-of-the-art techniques\nin Deep Learning to tackle the problem of Bengali Handwritten Character\nRecognition ( HCR ). Our method uses lesser iterations to train than most other\ncomparable methods. We employ Transfer Learning on ResNet 50, a\nstate-of-the-art deep Convolutional Neural Network Model, pretrained on\nImageNet dataset. We also use other techniques like a modified version of One\nCycle Policy, varying the input image sizes etc. to ensure that our training\noccurs fast. We use the BanglaLekha-Isolated Dataset for evaluation of our\ntechnique which consists of 84 classes (50 Basic, 10 Numerals and 24 Compound\nCharacters). We are able to achieve 96.12% accuracy in just 47 epochs on\nBanglaLekha-Isolated dataset. When comparing our method with that of other\nresearchers, considering number of classes and without using Ensemble Learning,\nthe proposed solution achieves state of the art result for Handwritten Bengali\nCharacter Recognition. Code and weight files are available at\nhttps://github.com/swagato-c/bangla-hwcr-present."}, "authors": ["Swagato Chatterjee", "Rwik Kumar Dutta", "Debayan Ganguly", "Kingshuk Chatterjee", "Sudipta Roy"], "author_detail": {"name": "Sudipta Roy"}, "author": "Sudipta Roy", "links": [{"href": "http://arxiv.org/abs/1902.11133v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1902.11133v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1902.11133v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1902.11133v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1912.12405v2", "guidislink": true, "updated": "2020-03-16T17:06:44Z", "updated_parsed": [2020, 3, 16, 17, 6, 44, 0, 76, 0], "published": "2019-12-28T05:37:28Z", "published_parsed": [2019, 12, 28, 5, 37, 28, 5, 362, 0], "title": "A Genetic Algorithm based Kernel-size Selection Approach for a\n  Multi-column Convolutional Neural Network", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Genetic Algorithm based Kernel-size Selection Approach for a\n  Multi-column Convolutional Neural Network"}, "summary": "Deep neural network-based architectures give promising results in various\ndomains including pattern recognition. Finding the optimal combination of the\nhyper-parameters of such a large-sized architecture is tedious and requires a\nlarge number of laboratory experiments. But, identifying the optimal\ncombination of a hyper-parameter or appropriate kernel size for a given\narchitecture of deep learning is always a challenging and tedious task. Here,\nwe introduced a genetic algorithm-based technique to reduce the efforts of\nfinding the optimal combination of a hyper-parameter (kernel size) of a\nconvolutional neural network-based architecture. The method is evaluated on\nthree popular datasets of different handwritten Bangla characters and digits.\nThe implementation of the proposed methodology can be found in the following\nlink: https://github.com/DeepQn/GA-Based-Kernel-Size.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Deep neural network-based architectures give promising results in various\ndomains including pattern recognition. Finding the optimal combination of the\nhyper-parameters of such a large-sized architecture is tedious and requires a\nlarge number of laboratory experiments. But, identifying the optimal\ncombination of a hyper-parameter or appropriate kernel size for a given\narchitecture of deep learning is always a challenging and tedious task. Here,\nwe introduced a genetic algorithm-based technique to reduce the efforts of\nfinding the optimal combination of a hyper-parameter (kernel size) of a\nconvolutional neural network-based architecture. The method is evaluated on\nthree popular datasets of different handwritten Bangla characters and digits.\nThe implementation of the proposed methodology can be found in the following\nlink: https://github.com/DeepQn/GA-Based-Kernel-Size."}, "authors": ["Animesh Singh", "Sandip Saha", "Ritesh Sarkhel", "Mahantapas Kundu", "Mita Nasipuri", "Nibaran Das"], "author_detail": {"name": "Nibaran Das"}, "author": "Nibaran Das", "links": [{"href": "http://arxiv.org/abs/1912.12405v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1912.12405v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1912.12405v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1912.12405v2", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2003.07428v1", "guidislink": true, "updated": "2020-03-16T20:19:21Z", "updated_parsed": [2020, 3, 16, 20, 19, 21, 0, 76, 0], "published": "2020-03-16T20:19:21Z", "published_parsed": [2020, 3, 16, 20, 19, 21, 0, 76, 0], "title": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression"}, "summary": "In this paper, we discuss the development of a multilingual annotated corpus\nof misogyny and aggression in Indian English, Hindi, and Indian Bangla as part\nof a project on studying and automatically identifying misogyny and communalism\non social media (the ComMA Project). The dataset is collected from comments on\nYouTube videos and currently contains a total of over 20,000 comments. The\ncomments are annotated at two levels - aggression (overtly aggressive, covertly\naggressive, and non-aggressive) and misogyny (gendered and non-gendered). We\ndescribe the process of data collection, the tagset used for annotation, and\nissues and challenges faced during the process of annotation. Finally, we\ndiscuss the results of the baseline experiments conducted to develop a\nclassifier for misogyny in the three languages.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we discuss the development of a multilingual annotated corpus\nof misogyny and aggression in Indian English, Hindi, and Indian Bangla as part\nof a project on studying and automatically identifying misogyny and communalism\non social media (the ComMA Project). The dataset is collected from comments on\nYouTube videos and currently contains a total of over 20,000 comments. The\ncomments are annotated at two levels - aggression (overtly aggressive, covertly\naggressive, and non-aggressive) and misogyny (gendered and non-gendered). We\ndescribe the process of data collection, the tagset used for annotation, and\nissues and challenges faced during the process of annotation. Finally, we\ndiscuss the results of the baseline experiments conducted to develop a\nclassifier for misogyny in the three languages."}, "authors": ["Shiladitya Bhattacharya", "Siddharth Singh", "Ritesh Kumar", "Akanksha Bansal", "Akash Bhagat", "Yogesh Dawer", "Bornini Lahiri", "Atul Kr. Ojha"], "author_detail": {"name": "Atul Kr. Ojha"}, "author": "Atul Kr. Ojha", "arxiv_comment": "Submitted for review to Second Workshop on Trolling, Aggression and\n  Cyberbullying (TRAC 2020)", "links": [{"href": "http://arxiv.org/abs/2003.07428v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2003.07428v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2003.07428v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2003.07428v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2003.08384v5", "guidislink": true, "updated": "2021-01-05T18:11:50Z", "updated_parsed": [2021, 1, 5, 18, 11, 50, 1, 5, 0], "published": "2020-03-18T17:58:05Z", "published_parsed": [2020, 3, 18, 17, 58, 5, 2, 78, 0], "title": "Confronting the Constraints for Optical Character Segmentation from\n  Printed Bangla Text Image", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Confronting the Constraints for Optical Character Segmentation from\n  Printed Bangla Text Image"}, "summary": "In a world of digitization, optical character recognition holds the\nautomation to written history. Optical character recognition system basically\nconverts printed images into editable texts for better storage and usability.\nTo be completely functional, the system needs to go through some crucial\nmethods such as pre-processing and segmentation. Pre-processing helps printed\ndata to be noise free and gets rid of skewness efficiently whereas segmentation\nhelps the image fragment into line, word and character precisely for better\nconversion. These steps hold the door to better accuracy and consistent results\nfor a printed image to be ready for conversion. Our proposed algorithm is able\nto segment characters both from ideal and non-ideal cases of scanned or\ncaptured images giving a sustainable outcome. The implementation of our work is\nprovided here: https://cutt.ly/rgdfBIa", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In a world of digitization, optical character recognition holds the\nautomation to written history. Optical character recognition system basically\nconverts printed images into editable texts for better storage and usability.\nTo be completely functional, the system needs to go through some crucial\nmethods such as pre-processing and segmentation. Pre-processing helps printed\ndata to be noise free and gets rid of skewness efficiently whereas segmentation\nhelps the image fragment into line, word and character precisely for better\nconversion. These steps hold the door to better accuracy and consistent results\nfor a printed image to be ready for conversion. Our proposed algorithm is able\nto segment characters both from ideal and non-ideal cases of scanned or\ncaptured images giving a sustainable outcome. The implementation of our work is\nprovided here: https://cutt.ly/rgdfBIa"}, "authors": ["Abu Saleh Md. Abir", "Sanjana Rahman", "Samia Ellin", "Maisha Farzana", "Md Hridoy Manik", "Chowdhury Rafeed Rahman"], "author_detail": {"name": "Chowdhury Rafeed Rahman"}, "author": "Chowdhury Rafeed Rahman", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1145/3428363.3428367", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/2003.08384v5", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2003.08384v5", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2003.08384v5", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2003.08384v5", "arxiv_comment": null, "journal_reference": null, "doi": "10.1145/3428363.3428367"}
{"id": "http://arxiv.org/abs/2004.01551v1", "guidislink": true, "updated": "2020-04-03T13:20:12Z", "updated_parsed": [2020, 4, 3, 13, 20, 12, 4, 94, 0], "published": "2020-04-03T13:20:12Z", "published_parsed": [2020, 4, 3, 13, 20, 12, 4, 94, 0], "title": "Sparse Concept Coded Tetrolet Transform for Unconstrained Odia Character\n  Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sparse Concept Coded Tetrolet Transform for Unconstrained Odia Character\n  Recognition"}, "summary": "Feature representation in the form of spatio-spectral decomposition is one of\nthe robust techniques adopted in automatic handwritten character recognition\nsystems. In this regard, we propose a new image representation approach for\nunconstrained handwritten alphanumeric characters using sparse concept coded\nTetrolets. Tetrolets, which does not use fixed dyadic square blocks for\nspectral decomposition like conventional wavelets, preserve the localized\nvariations in handwritings by adopting tetrominoes those capture the shape\ngeometry. The sparse concept coding of low entropy Tetrolet representation is\nfound to extract the important hidden information (concept) for superior\npattern discrimination. Large scale experimentation using ten databases in six\ndifferent scripts (Bangla, Devanagari, Odia, English, Arabic and Telugu) has\nbeen performed. The proposed feature representation along with standard\nclassifiers such as random forest, support vector machine (SVM), nearest\nneighbor and modified quadratic discriminant function (MQDF) is found to\nachieve state-of-the-art recognition performance in all the databases, viz.\n99.40% (MNIST); 98.72% and 93.24% (IITBBS); 99.38% and 99.22% (ISI Kolkata).\nThe proposed OCR system is shown to perform better than other sparse based\ntechniques such as PCA, SparsePCA and SparseLDA, as well as better than\nexisting transforms (Wavelet, Slantlet and Stockwell).", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Feature representation in the form of spatio-spectral decomposition is one of\nthe robust techniques adopted in automatic handwritten character recognition\nsystems. In this regard, we propose a new image representation approach for\nunconstrained handwritten alphanumeric characters using sparse concept coded\nTetrolets. Tetrolets, which does not use fixed dyadic square blocks for\nspectral decomposition like conventional wavelets, preserve the localized\nvariations in handwritings by adopting tetrominoes those capture the shape\ngeometry. The sparse concept coding of low entropy Tetrolet representation is\nfound to extract the important hidden information (concept) for superior\npattern discrimination. Large scale experimentation using ten databases in six\ndifferent scripts (Bangla, Devanagari, Odia, English, Arabic and Telugu) has\nbeen performed. The proposed feature representation along with standard\nclassifiers such as random forest, support vector machine (SVM), nearest\nneighbor and modified quadratic discriminant function (MQDF) is found to\nachieve state-of-the-art recognition performance in all the databases, viz.\n99.40% (MNIST); 98.72% and 93.24% (IITBBS); 99.38% and 99.22% (ISI Kolkata).\nThe proposed OCR system is shown to perform better than other sparse based\ntechniques such as PCA, SparsePCA and SparseLDA, as well as better than\nexisting transforms (Wavelet, Slantlet and Stockwell)."}, "authors": ["Kalyan S Dash", "N B Puhan", "G Panda"], "author_detail": {"name": "G Panda"}, "author": "G Panda", "links": [{"href": "http://arxiv.org/abs/2004.01551v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.01551v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "eess.IV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.01551v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.01551v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2009.07435v1", "guidislink": true, "updated": "2020-09-16T02:50:03Z", "updated_parsed": [2020, 9, 16, 2, 50, 3, 2, 260, 0], "published": "2020-09-16T02:50:03Z", "published_parsed": [2020, 9, 16, 2, 50, 3, 2, 260, 0], "title": "A New Approach for Texture based Script Identification At Block Level\n  using Quad Tree Decomposition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A New Approach for Texture based Script Identification At Block Level\n  using Quad Tree Decomposition"}, "summary": "A considerable amount of success has been achieved in developing monolingual\nOCR systems for Indic scripts. But in a country like India, where multi-script\nscenario is prevalent, identifying scripts beforehand becomes obligatory. In\nthis paper, we present the significance of Gabor wavelets filters in extracting\ndirectional energy and entropy distributions for 11 official handwritten\nscripts namely, Bangla, Devanagari, Gujarati, Gurumukhi, Kannada, Malayalam,\nOriya, Tamil, Telugu, Urdu and Roman. The experimentation is conducted at block\nlevel based on a quad-tree decomposition approach and evaluated using six\ndifferent well-known classifiers. Finally, the best identification accuracy of\n96.86% has been achieved by Multi Layer Perceptron (MLP) classifier for 3-fold\ncross validation at level-2 decomposition. The results serve to establish the\nefficacy of the present approach to the classification of handwritten Indic\nscripts", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A considerable amount of success has been achieved in developing monolingual\nOCR systems for Indic scripts. But in a country like India, where multi-script\nscenario is prevalent, identifying scripts beforehand becomes obligatory. In\nthis paper, we present the significance of Gabor wavelets filters in extracting\ndirectional energy and entropy distributions for 11 official handwritten\nscripts namely, Bangla, Devanagari, Gujarati, Gurumukhi, Kannada, Malayalam,\nOriya, Tamil, Telugu, Urdu and Roman. The experimentation is conducted at block\nlevel based on a quad-tree decomposition approach and evaluated using six\ndifferent well-known classifiers. Finally, the best identification accuracy of\n96.86% has been achieved by Multi Layer Perceptron (MLP) classifier for 3-fold\ncross validation at level-2 decomposition. The results serve to establish the\nefficacy of the present approach to the classification of handwritten Indic\nscripts"}, "authors": ["Pawan Kumar Singh", "Supratim Das", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "13 pages, 5 figures, conference", "links": [{"href": "http://arxiv.org/abs/2009.07435v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2009.07435v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2009.07435v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2009.07435v1", "journal_reference": "7th International Conference on Advances in Communication, Network\n  and Computing (CNC), pp. 247-259, 2016", "doi": null}
{"id": "http://arxiv.org/abs/2010.03065v1", "guidislink": true, "updated": "2020-10-06T22:33:58Z", "updated_parsed": [2020, 10, 6, 22, 33, 58, 1, 280, 0], "published": "2020-10-06T22:33:58Z", "published_parsed": [2020, 10, 6, 22, 33, 58, 1, 280, 0], "title": "Anubhuti -- An annotated dataset for emotional analysis of Bengali short\n  stories", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Anubhuti -- An annotated dataset for emotional analysis of Bengali short\n  stories"}, "summary": "Thousands of short stories and articles are being written in many different\nlanguages all around the world today. Bengali, or Bangla, is the second highest\nspoken language in India after Hindi and is the national language of the\ncountry of Bangladesh. This work reports in detail the creation of Anubhuti --\nthe first and largest text corpus for analyzing emotions expressed by writers\nof Bengali short stories. We explain the data collection methods, the manual\nannotation process and the resulting high inter-annotator agreement of the\ndataset due to the linguistic expertise of the annotators and the clear\nmethodology of labelling followed. We also address some of the challenges faced\nin the collection of raw data and annotation process of a low resource language\nlike Bengali. We have verified the performance of our dataset with baseline\nMachine Learning as well as a Deep Learning model for emotion classification\nand have found that these standard models have a high accuracy and relevant\nfeature selection on Anubhuti. In addition, we also explain how this dataset\ncan be of interest to linguists and data analysts to study the flow of emotions\nas expressed by writers of Bengali literature.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Thousands of short stories and articles are being written in many different\nlanguages all around the world today. Bengali, or Bangla, is the second highest\nspoken language in India after Hindi and is the national language of the\ncountry of Bangladesh. This work reports in detail the creation of Anubhuti --\nthe first and largest text corpus for analyzing emotions expressed by writers\nof Bengali short stories. We explain the data collection methods, the manual\nannotation process and the resulting high inter-annotator agreement of the\ndataset due to the linguistic expertise of the annotators and the clear\nmethodology of labelling followed. We also address some of the challenges faced\nin the collection of raw data and annotation process of a low resource language\nlike Bengali. We have verified the performance of our dataset with baseline\nMachine Learning as well as a Deep Learning model for emotion classification\nand have found that these standard models have a high accuracy and relevant\nfeature selection on Anubhuti. In addition, we also explain how this dataset\ncan be of interest to linguists and data analysts to study the flow of emotions\nas expressed by writers of Bengali literature."}, "authors": ["Aditya Pal", "Bhaskar Karn"], "author_detail": {"name": "Bhaskar Karn"}, "author": "Bhaskar Karn", "arxiv_comment": "4 pages, 6 figures", "links": [{"href": "http://arxiv.org/abs/2010.03065v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.03065v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.03065v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.03065v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2010.08066v1", "guidislink": true, "updated": "2020-10-15T23:24:15Z", "updated_parsed": [2020, 10, 15, 23, 24, 15, 3, 289, 0], "published": "2020-10-15T23:24:15Z", "published_parsed": [2020, 10, 15, 23, 24, 15, 3, 289, 0], "title": "TextMage: The Automated Bangla Caption Generator Based On Deep Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "TextMage: The Automated Bangla Caption Generator Based On Deep Learning"}, "summary": "Neural Networks and Deep Learning have seen an upsurge of research in the\npast decade due to the improved results. Generates text from the given image is\na crucial task that requires the combination of both sectors which are computer\nvision and natural language processing in order to understand an image and\nrepresent it using a natural language. However existing works have all been\ndone on a particular lingual domain and on the same set of data. This leads to\nthe systems being developed to perform poorly on images that belong to specific\nlocales' geographical context. TextMage is a system that is capable of\nunderstanding visual scenes that belong to the Bangladeshi geographical context\nand use its knowledge to represent what it understands in Bengali. Hence, we\nhave trained a model on our previously developed and published dataset named\nBanglaLekhaImageCaptions. This dataset contains 9,154 images along with two\nannotations for each image. In order to access performance, the proposed model\nhas been implemented and evaluated.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Neural Networks and Deep Learning have seen an upsurge of research in the\npast decade due to the improved results. Generates text from the given image is\na crucial task that requires the combination of both sectors which are computer\nvision and natural language processing in order to understand an image and\nrepresent it using a natural language. However existing works have all been\ndone on a particular lingual domain and on the same set of data. This leads to\nthe systems being developed to perform poorly on images that belong to specific\nlocales' geographical context. TextMage is a system that is capable of\nunderstanding visual scenes that belong to the Bangladeshi geographical context\nand use its knowledge to represent what it understands in Bengali. Hence, we\nhave trained a model on our previously developed and published dataset named\nBanglaLekhaImageCaptions. This dataset contains 9,154 images along with two\nannotations for each image. In order to access performance, the proposed model\nhas been implemented and evaluated."}, "authors": ["Abrar Hasin Kamal", "Md. Asifuzzaman Jishan", "Nafees Mansoor"], "author_detail": {"name": "Nafees Mansoor"}, "author": "Nafees Mansoor", "arxiv_comment": "5 pages", "links": [{"href": "http://arxiv.org/abs/2010.08066v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.08066v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.08066v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.08066v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.06908v2", "guidislink": true, "updated": "2018-01-28T15:10:48Z", "updated_parsed": [2018, 1, 28, 15, 10, 48, 6, 28, 0], "published": "2017-12-19T13:12:29Z", "published_parsed": [2017, 12, 19, 13, 12, 29, 1, 353, 0], "title": "Cross-language Framework for Word Recognition and Spotting of Indic\n  Scripts", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Cross-language Framework for Word Recognition and Spotting of Indic\n  Scripts"}, "summary": "Handwritten word recognition and spotting of low-resource scripts are\ndifficult as sufficient training data is not available and it is often\nexpensive for collecting data of such scripts. This paper presents a novel\ncross language platform for handwritten word recognition and spotting for such\nlow-resource scripts where training is performed with a sufficiently large\ndataset of an available script (considered as source script) and testing is\ndone on other scripts (considered as target script). Training with one source\nscript and testing with another script to have a reasonable result is not easy\nin handwriting domain due to the complex nature of handwriting variability\namong scripts. Also it is difficult in mapping between source and target\ncharacters when they appear in cursive word images. The proposed Indic cross\nlanguage framework exploits a large resource of dataset for training and uses\nit for recognizing and spotting text of other target scripts where sufficient\namount of training data is not available. Since, Indic scripts are mostly\nwritten in 3 zones, namely, upper, middle and lower, we employ zone-wise\ncharacter (or component) mapping for efficient learning purpose. The\nperformance of our cross-language framework depends on the extent of similarity\nbetween the source and target scripts. Hence, we devise an entropy based script\nsimilarity score using source to target character mapping that will provide a\nfeasibility of cross language transcription. We have tested our approach in\nthree Indic scripts, namely, Bangla, Devanagari and Gurumukhi, and the\ncorresponding results are reported.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten word recognition and spotting of low-resource scripts are\ndifficult as sufficient training data is not available and it is often\nexpensive for collecting data of such scripts. This paper presents a novel\ncross language platform for handwritten word recognition and spotting for such\nlow-resource scripts where training is performed with a sufficiently large\ndataset of an available script (considered as source script) and testing is\ndone on other scripts (considered as target script). Training with one source\nscript and testing with another script to have a reasonable result is not easy\nin handwriting domain due to the complex nature of handwriting variability\namong scripts. Also it is difficult in mapping between source and target\ncharacters when they appear in cursive word images. The proposed Indic cross\nlanguage framework exploits a large resource of dataset for training and uses\nit for recognizing and spotting text of other target scripts where sufficient\namount of training data is not available. Since, Indic scripts are mostly\nwritten in 3 zones, namely, upper, middle and lower, we employ zone-wise\ncharacter (or component) mapping for efficient learning purpose. The\nperformance of our cross-language framework depends on the extent of similarity\nbetween the source and target scripts. Hence, we devise an entropy based script\nsimilarity score using source to target character mapping that will provide a\nfeasibility of cross language transcription. We have tested our approach in\nthree Indic scripts, namely, Bangla, Devanagari and Gurumukhi, and the\ncorresponding results are reported."}, "authors": ["Ayan Kumar Bhunia", "Partha Pratim Roy", "Akash Mohta", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patcog.2018.01.034", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1712.06908v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.06908v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Accepted in Pattern Recognition, Elsevier(2018)", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.06908v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.06908v2", "journal_reference": null, "doi": "10.1016/j.patcog.2018.01.034"}
{"id": "http://arxiv.org/abs/1804.06254v1", "guidislink": true, "updated": "2018-04-17T13:52:59Z", "updated_parsed": [2018, 4, 17, 13, 52, 59, 1, 107, 0], "published": "2018-04-17T13:52:59Z", "published_parsed": [2018, 4, 17, 13, 52, 59, 1, 107, 0], "title": "Synthetic data generation for Indic handwritten text recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Synthetic data generation for Indic handwritten text recognition"}, "summary": "This paper presents a novel approach to generate synthetic dataset for\nhandwritten word recognition systems. It is difficult to recognize handwritten\nscripts for which sufficient training data is not readily available or it may\nbe expensive to collect such data. Hence, it becomes hard to train recognition\nsystems owing to lack of proper dataset. To overcome such problems, synthetic\ndata could be used to create or expand the existing training dataset to improve\nrecognition performance. Any available digital data from online newspaper and\nsuch sources can be used to generate synthetic data. In this paper, we propose\nto add distortion/deformation to digital data in such a way that the underlying\npattern is preserved, so that the image so produced bears a close similarity to\nactual handwritten samples. The images thus produced can be used independently\nto train the system or be combined with natural handwritten data to augment the\noriginal dataset and improve the recognition system. We experimented using\nsynthetic data to improve the recognition accuracy of isolated characters and\nwords. The framework is tested on 2 Indic scripts - Devanagari (Hindi) and\nBengali (Bangla), for numeral, character and word recognition. We have obtained\nencouraging results from the experiment. Finally, the experiment with Latin\ntext verifies the utility of the approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents a novel approach to generate synthetic dataset for\nhandwritten word recognition systems. It is difficult to recognize handwritten\nscripts for which sufficient training data is not readily available or it may\nbe expensive to collect such data. Hence, it becomes hard to train recognition\nsystems owing to lack of proper dataset. To overcome such problems, synthetic\ndata could be used to create or expand the existing training dataset to improve\nrecognition performance. Any available digital data from online newspaper and\nsuch sources can be used to generate synthetic data. In this paper, we propose\nto add distortion/deformation to digital data in such a way that the underlying\npattern is preserved, so that the image so produced bears a close similarity to\nactual handwritten samples. The images thus produced can be used independently\nto train the system or be combined with natural handwritten data to augment the\noriginal dataset and improve the recognition system. We experimented using\nsynthetic data to improve the recognition accuracy of isolated characters and\nwords. The framework is tested on 2 Indic scripts - Devanagari (Hindi) and\nBengali (Bangla), for numeral, character and word recognition. We have obtained\nencouraging results from the experiment. Finally, the experiment with Latin\ntext verifies the utility of the approach."}, "authors": ["Partha Pratim Roy", "Akash Mohta", "Bidyut B. Chaudhuri"], "author_detail": {"name": "Bidyut B. Chaudhuri"}, "author": "Bidyut B. Chaudhuri", "links": [{"href": "http://arxiv.org/abs/1804.06254v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1804.06254v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1804.06254v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1804.06254v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1807.06772v1", "guidislink": true, "updated": "2018-07-18T04:29:20Z", "updated_parsed": [2018, 7, 18, 4, 29, 20, 2, 199, 0], "published": "2018-07-18T04:29:20Z", "published_parsed": [2018, 7, 18, 4, 29, 20, 2, 199, 0], "title": "Bag-of-Visual-Words for Signature-Based Multi-Script Document Retrieval", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bag-of-Visual-Words for Signature-Based Multi-Script Document Retrieval"}, "summary": "An end-to-end architecture for multi-script document retrieval using\nhandwritten signatures is proposed in this paper. The user supplies a query\nsignature sample and the system exclusively returns a set of documents that\ncontain the query signature. In the first stage, a component-wise\nclassification technique separates the potential signature components from all\nother components. A bag-of-visual-words powered by SIFT descriptors in a\npatch-based framework is proposed to compute the features and a Support Vector\nMachine (SVM)-based classifier was used to separate signatures from the\ndocuments. In the second stage, features from the foreground (i.e. signature\nstrokes) and the background spatial information (i.e. background loops,\nreservoirs etc.) were combined to characterize the signature object to match\nwith the query signature. Finally, three distance measures were used to match a\nquery signature with the signature present in target documents for retrieval.\nThe `Tobacco' document database and an Indian script database containing 560\ndocuments of Devanagari (Hindi) and Bangla scripts were used for the\nperformance evaluation. The proposed system was also tested on noisy documents\nand promising results were obtained. A comparative study shows that the\nproposed method outperforms the state-of-the-art approaches.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An end-to-end architecture for multi-script document retrieval using\nhandwritten signatures is proposed in this paper. The user supplies a query\nsignature sample and the system exclusively returns a set of documents that\ncontain the query signature. In the first stage, a component-wise\nclassification technique separates the potential signature components from all\nother components. A bag-of-visual-words powered by SIFT descriptors in a\npatch-based framework is proposed to compute the features and a Support Vector\nMachine (SVM)-based classifier was used to separate signatures from the\ndocuments. In the second stage, features from the foreground (i.e. signature\nstrokes) and the background spatial information (i.e. background loops,\nreservoirs etc.) were combined to characterize the signature object to match\nwith the query signature. Finally, three distance measures were used to match a\nquery signature with the signature present in target documents for retrieval.\nThe `Tobacco' document database and an Indian script database containing 560\ndocuments of Devanagari (Hindi) and Bangla scripts were used for the\nperformance evaluation. The proposed system was also tested on noisy documents\nand promising results were obtained. A comparative study shows that the\nproposed method outperforms the state-of-the-art approaches."}, "authors": ["Ranju Mandal", "Partha Pratim Roy", "Umapada Pal", "Michael Blumenstein"], "author_detail": {"name": "Michael Blumenstein"}, "author": "Michael Blumenstein", "links": [{"href": "http://arxiv.org/abs/1807.06772v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1807.06772v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1807.06772v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1807.06772v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1811.08816v2", "guidislink": true, "updated": "2019-07-22T11:02:06Z", "updated_parsed": [2019, 7, 22, 11, 2, 6, 0, 203, 0], "published": "2018-11-21T16:36:08Z", "published_parsed": [2018, 11, 21, 16, 36, 8, 2, 325, 0], "title": "Learning cross-lingual phonological and orthagraphic adaptations: a case\n  study in improving neural machine translation between low-resource languages", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Learning cross-lingual phonological and orthagraphic adaptations: a case\n  study in improving neural machine translation between low-resource languages"}, "summary": "Out-of-vocabulary (OOV) words can pose serious challenges for machine\ntranslation (MT) tasks, and in particular, for low-resource language (LRL)\npairs, i.e., language pairs for which few or no parallel corpora exist. Our\nwork adapts variants of seq2seq models to perform transduction of such words\nfrom Hindi to Bhojpuri (an LRL instance), learning from a set of cognate pairs\nbuilt from a bilingual dictionary of Hindi--Bhojpuri words. We demonstrate that\nour models can be effectively used for language pairs that have limited\nparallel corpora; our models work at the character level to grasp phonetic and\northographic similarities across multiple types of word adaptations, whether\nsynchronic or diachronic, loan words or cognates. We describe the training\naspects of several character level NMT systems that we adapted to this task and\ncharacterize their typical errors. Our method improves BLEU score by 6.3 on the\nHindi-to-Bhojpuri translation task. Further, we show that such transductions\ncan generalize well to other languages by applying it successfully to Hindi --\nBangla cognate pairs. Our work can be seen as an important step in the process\nof: (i) resolving the OOV words problem arising in MT tasks, (ii) creating\neffective parallel corpora for resource-constrained languages, and (iii)\nleveraging the enhanced semantic knowledge captured by word-level embeddings to\nperform character-level tasks.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Out-of-vocabulary (OOV) words can pose serious challenges for machine\ntranslation (MT) tasks, and in particular, for low-resource language (LRL)\npairs, i.e., language pairs for which few or no parallel corpora exist. Our\nwork adapts variants of seq2seq models to perform transduction of such words\nfrom Hindi to Bhojpuri (an LRL instance), learning from a set of cognate pairs\nbuilt from a bilingual dictionary of Hindi--Bhojpuri words. We demonstrate that\nour models can be effectively used for language pairs that have limited\nparallel corpora; our models work at the character level to grasp phonetic and\northographic similarities across multiple types of word adaptations, whether\nsynchronic or diachronic, loan words or cognates. We describe the training\naspects of several character level NMT systems that we adapted to this task and\ncharacterize their typical errors. Our method improves BLEU score by 6.3 on the\nHindi-to-Bhojpuri translation task. Further, we show that such transductions\ncan generalize well to other languages by applying it successfully to Hindi --\nBangla cognate pairs. Our work can be seen as an important step in the process\nof: (i) resolving the OOV words problem arising in MT tasks, (ii) creating\neffective parallel corpora for resource-constrained languages, and (iii)\nleveraging the enhanced semantic knowledge captured by word-level embeddings to\nperform character-level tasks."}, "authors": ["Saurav Jha", "Akhilesh Sudhakar", "Anil Kumar Singh"], "author_detail": {"name": "Anil Kumar Singh"}, "author": "Anil Kumar Singh", "arxiv_comment": "47 pages, 4 figures, 21 tables (including Appendices)", "links": [{"href": "http://arxiv.org/abs/1811.08816v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1811.08816v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1811.08816v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1811.08816v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2012.14353v1", "guidislink": true, "updated": "2020-12-28T16:46:03Z", "updated_parsed": [2020, 12, 28, 16, 46, 3, 0, 363, 0], "published": "2020-12-28T16:46:03Z", "published_parsed": [2020, 12, 28, 16, 46, 3, 0, 363, 0], "title": "DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced\n  Bengali Language", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced\n  Bengali Language"}, "summary": "Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices, but also\nenables people to express anti-social behavior like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behavior analysis, by predicting the\ncontexts mostly for highly-resourced languages like English. However, some\nlanguages such as Bengali are under-resourced that lack of computational\nresources for natural language processing(NLP). In this paper, we propose an\nexplainable approach for hate speech detection from under-resourced Bengali\nlanguage, which we called DeepHateExplainer. In our approach, Bengali texts are\nfirst comprehensively preprocessed, before classifying them into political,\npersonal, geopolitical, and religious hates, by employing neural ensemble of\ndifferent transformer-based neural architectures(i.e., monolingual Bangla\nBERT-base, multilingual BERT-cased and uncased, and XLM-RoBERTa), followed by\nidentifying important terms with sensitivity analysis and layer-wise relevance\npropagation(LRP) to provide human-interpretable explanations. Evaluations\nagainst several machine learning~(linear and tree-based models) and deep neural\nnetworks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines\nyield F1 scores of 84%, 90%, 88%, and 88%, for political, personal,\ngeopolitical, and religious hates, respectively, during 3-fold cross-validation\ntests.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices, but also\nenables people to express anti-social behavior like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behavior analysis, by predicting the\ncontexts mostly for highly-resourced languages like English. However, some\nlanguages such as Bengali are under-resourced that lack of computational\nresources for natural language processing(NLP). In this paper, we propose an\nexplainable approach for hate speech detection from under-resourced Bengali\nlanguage, which we called DeepHateExplainer. In our approach, Bengali texts are\nfirst comprehensively preprocessed, before classifying them into political,\npersonal, geopolitical, and religious hates, by employing neural ensemble of\ndifferent transformer-based neural architectures(i.e., monolingual Bangla\nBERT-base, multilingual BERT-cased and uncased, and XLM-RoBERTa), followed by\nidentifying important terms with sensitivity analysis and layer-wise relevance\npropagation(LRP) to provide human-interpretable explanations. Evaluations\nagainst several machine learning~(linear and tree-based models) and deep neural\nnetworks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines\nyield F1 scores of 84%, 90%, 88%, and 88%, for political, personal,\ngeopolitical, and religious hates, respectively, during 3-fold cross-validation\ntests."}, "authors": ["Md. Rezaul Karim", "Sumon Kanti Dey", "Bharathi Raja Chakravarthi"], "author_detail": {"name": "Bharathi Raja Chakravarthi"}, "author": "Bharathi Raja Chakravarthi", "arxiv_comment": "Extended version of this paper is currently under review in the IEEE\n  Access journal", "links": [{"href": "http://arxiv.org/abs/2012.14353v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2012.14353v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2012.14353v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2012.14353v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1204.1198v1", "guidislink": true, "updated": "2012-04-05T12:28:11Z", "updated_parsed": [2012, 4, 5, 12, 28, 11, 3, 96, 0], "published": "2012-04-05T12:28:11Z", "published_parsed": [2012, 4, 5, 12, 28, 11, 3, 96, 0], "title": "A Complete Workflow for Development of Bangla OCR", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Complete Workflow for Development of Bangla OCR"}, "summary": "Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required."}, "authors": ["Farjana Yeasmin Omee", "Shiam Shabbir Himel", "Md. Abu Naser Bikas"], "author_detail": {"name": "Md. Abu Naser Bikas"}, "author": "Md. Abu Naser Bikas", "links": [{"href": "http://arxiv.org/abs/1204.1198v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1204.1198v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1204.1198v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1204.1198v1", "arxiv_comment": null, "journal_reference": "International Journal of Computer Applications, Volume 21, No.9,\n  May 2011", "doi": null}
{"id": "http://arxiv.org/abs/1009.4586v1", "guidislink": true, "updated": "2010-09-23T11:42:41Z", "updated_parsed": [2010, 9, 23, 11, 42, 41, 3, 266, 0], "published": "2010-09-23T11:42:41Z", "published_parsed": [2010, 9, 23, 11, 42, 41, 3, 266, 0], "title": "Optimal Bangla Keyboard Layout using Association Rule of Data Mining", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Optimal Bangla Keyboard Layout using Association Rule of Data Mining"}, "summary": "In this paper we present an optimal Bangla Keyboard Layout, which distributes\nthe load equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Finally, we propose a Bangla Keyboard Layout. Experimental results on\nseveral keyboard layout shows the effectiveness of the proposed approach with\nbetter performance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper we present an optimal Bangla Keyboard Layout, which distributes\nthe load equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Finally, we propose a Bangla Keyboard Layout. Experimental results on\nseveral keyboard layout shows the effectiveness of the proposed approach with\nbetter performance."}, "authors": ["Md. Hijbul Alam", "Abdul Kadar Muhammad Masum", "Mohammad Mahadi Hassan", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "3 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4586v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4586v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4586v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4586v1", "journal_reference": "Proc. 7th International Conference on Computer and Information\n  Technology (ICCIT 2004), Dhaka, Bangladesh, pp. 679-681, Dec. 2004", "doi": null}
{"id": "http://arxiv.org/abs/1703.10661v1", "guidislink": true, "updated": "2017-02-22T07:57:14Z", "updated_parsed": [2017, 2, 22, 7, 57, 14, 2, 53, 0], "published": "2017-02-22T07:57:14Z", "published_parsed": [2017, 2, 22, 7, 57, 14, 2, 53, 0], "title": "BanglaLekha-Isolated: A Comprehensive Bangla Handwritten Character\n  Dataset", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaLekha-Isolated: A Comprehensive Bangla Handwritten Character\n  Dataset"}, "summary": "Bangla handwriting recognition is becoming a very important issue nowadays.\nIt is potentially a very important task specially for Bangla speaking\npopulation of Bangladesh and West Bengal. By keeping that in our mind we are\nintroducing a comprehensive Bangla handwritten character dataset named\nBanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic\ncharacters and compound characters. This dataset was collected from multiple\ngeographical location within Bangladesh and includes sample collected from a\nvariety of aged groups. This dataset can also be used for other classification\nproblems i.e: gender, age, district. This is the largest dataset on Bangla\nhandwritten characters yet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla handwriting recognition is becoming a very important issue nowadays.\nIt is potentially a very important task specially for Bangla speaking\npopulation of Bangladesh and West Bengal. By keeping that in our mind we are\nintroducing a comprehensive Bangla handwritten character dataset named\nBanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic\ncharacters and compound characters. This dataset was collected from multiple\ngeographical location within Bangladesh and includes sample collected from a\nvariety of aged groups. This dataset can also be used for other classification\nproblems i.e: gender, age, district. This is the largest dataset on Bangla\nhandwritten characters yet."}, "authors": ["Mithun Biswas", "Rafiqul Islam", "Gautam Kumar Shom", "Md Shopon", "Nabeel Mohammed", "Sifat Momen", "Md Anowarul Abedin"], "author_detail": {"name": "Md Anowarul Abedin"}, "author": "Md Anowarul Abedin", "arxiv_comment": "Bangla Handwriting Dataset, OCR", "links": [{"href": "http://arxiv.org/abs/1703.10661v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1703.10661v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1703.10661v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1703.10661v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.07955v1", "guidislink": true, "updated": "2017-01-27T06:30:21Z", "updated_parsed": [2017, 1, 27, 6, 30, 21, 4, 27, 0], "published": "2017-01-27T06:30:21Z", "published_parsed": [2017, 1, 27, 6, 30, 21, 4, 27, 0], "title": "Statistical Analysis on Bangla Newspaper Data to Extract Trending Topic\n  and Visualize Its Change Over Time", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Statistical Analysis on Bangla Newspaper Data to Extract Trending Topic\n  and Visualize Its Change Over Time"}, "summary": "Trending topic of newspapers is an indicator to understand the situation of a\ncountry and also a way to evaluate the particular newspaper. This paper\nrepresents a model describing few techniques to select trending topics from\nBangla Newspaper. Topics that are discussed more frequently than other in\nBangla newspaper will be marked and how a very famous topic loses its\nimportance with the change of time and another topic takes its place will be\ndemonstrated. Data from two popular Bangla Newspaper with date and time were\ncollected. Statistical analysis was performed after on these data after\npreprocessing. Popular and most used keywords were extracted from the stream of\nBangla keyword with this analysis. This model can also cluster category wise\nnews trend or a list of news trend in daily or weekly basis with enough data. A\npattern can be found on their news trend too. Comparison among past news trend\nof Bangla newspapers will give a visualization of the situation of Bangladesh.\nThis visualization will be helpful to predict future trending topics of Bangla\nNewspaper.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Trending topic of newspapers is an indicator to understand the situation of a\ncountry and also a way to evaluate the particular newspaper. This paper\nrepresents a model describing few techniques to select trending topics from\nBangla Newspaper. Topics that are discussed more frequently than other in\nBangla newspaper will be marked and how a very famous topic loses its\nimportance with the change of time and another topic takes its place will be\ndemonstrated. Data from two popular Bangla Newspaper with date and time were\ncollected. Statistical analysis was performed after on these data after\npreprocessing. Popular and most used keywords were extracted from the stream of\nBangla keyword with this analysis. This model can also cluster category wise\nnews trend or a list of news trend in daily or weekly basis with enough data. A\npattern can be found on their news trend too. Comparison among past news trend\nof Bangla newspapers will give a visualization of the situation of Bangladesh.\nThis visualization will be helpful to predict future trending topics of Bangla\nNewspaper."}, "authors": ["Syed Mehedi Hasan Nirob", "Md. Kazi Nayeem", "Md. Saiful Islam"], "author_detail": {"name": "Md. Saiful Islam"}, "author": "Md. Saiful Islam", "arxiv_comment": "8 pages", "links": [{"href": "http://arxiv.org/abs/1701.07955v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.07955v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.07955v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.07955v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2005.02155v2", "guidislink": true, "updated": "2020-05-06T07:59:45Z", "updated_parsed": [2020, 5, 6, 7, 59, 45, 2, 127, 0], "published": "2020-04-29T06:38:12Z", "published_parsed": [2020, 4, 29, 6, 38, 12, 2, 120, 0], "title": "MatriVasha: A Multipurpose Comprehensive Database for Bangla Handwritten\n  Compound Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "MatriVasha: A Multipurpose Comprehensive Database for Bangla Handwritten\n  Compound Characters"}, "summary": "At present, recognition of the Bangla handwriting compound character has been\nan essential issue for many years. In recent years there have been\napplication-based researches in machine learning, and deep learning, which is\ngained interest, and most notably is handwriting recognition because it has a\ntremendous application such as Bangla OCR. MatrriVasha, the project which can\nrecognize Bangla, handwritten several compound characters. Currently, compound\ncharacter recognition is an important topic due to its variant application, and\nhelps to create old forms, and information digitization with reliability. But\nunfortunately, there is a lack of a comprehensive dataset that can categorize\nall types of Bangla compound characters. MatrriVasha is an attempt to align\ncompound character, and it's challenging because each person has a unique style\nof writing shapes. After all, MatrriVasha has proposed a dataset that intends\nto recognize Bangla 120(one hundred twenty) compound characters that consist of\n2552(two thousand five hundred fifty-two) isolated handwritten characters\nwritten unique writers which were collected from within Bangladesh. This\ndataset faced problems in terms of the district, age, and gender-based written\nrelated research because the samples were collected that includes a verity of\nthe district, age group, and the equal number of males, and females. As of now,\nour proposed dataset is so far the most extensive dataset for Bangla compound\ncharacters. It is intended to frame the acknowledgment technique for\nhandwritten Bangla compound character. In the future, this dataset will be made\npublicly available to help to widen the research.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "At present, recognition of the Bangla handwriting compound character has been\nan essential issue for many years. In recent years there have been\napplication-based researches in machine learning, and deep learning, which is\ngained interest, and most notably is handwriting recognition because it has a\ntremendous application such as Bangla OCR. MatrriVasha, the project which can\nrecognize Bangla, handwritten several compound characters. Currently, compound\ncharacter recognition is an important topic due to its variant application, and\nhelps to create old forms, and information digitization with reliability. But\nunfortunately, there is a lack of a comprehensive dataset that can categorize\nall types of Bangla compound characters. MatrriVasha is an attempt to align\ncompound character, and it's challenging because each person has a unique style\nof writing shapes. After all, MatrriVasha has proposed a dataset that intends\nto recognize Bangla 120(one hundred twenty) compound characters that consist of\n2552(two thousand five hundred fifty-two) isolated handwritten characters\nwritten unique writers which were collected from within Bangladesh. This\ndataset faced problems in terms of the district, age, and gender-based written\nrelated research because the samples were collected that includes a verity of\nthe district, age group, and the equal number of males, and females. As of now,\nour proposed dataset is so far the most extensive dataset for Bangla compound\ncharacters. It is intended to frame the acknowledgment technique for\nhandwritten Bangla compound character. In the future, this dataset will be made\npublicly available to help to widen the research."}, "authors": ["Jannatul Ferdous", "Suvrajit Karmaker", "A K M Shahariar Azad Rabby", "Syed Akhter Hossain"], "author_detail": {"name": "Syed Akhter Hossain"}, "author": "Syed Akhter Hossain", "arxiv_comment": "19 fig, 2 table", "links": [{"href": "http://arxiv.org/abs/2005.02155v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2005.02155v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2005.02155v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2005.02155v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1201.2010v1", "guidislink": true, "updated": "2012-01-10T10:33:18Z", "updated_parsed": [2012, 1, 10, 10, 33, 18, 1, 10, 0], "published": "2012-01-10T10:33:18Z", "published_parsed": [2012, 1, 10, 10, 33, 18, 1, 10, 0], "title": "Recognizing Bangla Grammar using Predictive Parser", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recognizing Bangla Grammar using Predictive Parser"}, "summary": "We describe a Context Free Grammar (CFG) for Bangla language and hence we\npropose a Bangla parser based on the grammar. Our approach is very much general\nto apply in Bangla Sentences and the method is well accepted for parsing a\nlanguage of a grammar. The proposed parser is a predictive parser and we\nconstruct the parse table for recognizing Bangla grammar. Using the parse table\nwe recognize syntactical mistakes of Bangla sentences when there is no entry\nfor a terminal in the parse table. If a natural language can be successfully\nparsed then grammar checking from this language becomes possible. The proposed\nscheme is based on Top down parsing method and we have avoided the left\nrecursion of the CFG using the idea of left factoring.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "We describe a Context Free Grammar (CFG) for Bangla language and hence we\npropose a Bangla parser based on the grammar. Our approach is very much general\nto apply in Bangla Sentences and the method is well accepted for parsing a\nlanguage of a grammar. The proposed parser is a predictive parser and we\nconstruct the parse table for recognizing Bangla grammar. Using the parse table\nwe recognize syntactical mistakes of Bangla sentences when there is no entry\nfor a terminal in the parse table. If a natural language can be successfully\nparsed then grammar checking from this language becomes possible. The proposed\nscheme is based on Top down parsing method and we have avoided the left\nrecursion of the CFG using the idea of left factoring."}, "authors": ["K. M. Azharul Hasan", "Al-Mahmud", "Amit Mondal", "Amit Saha"], "author_detail": {"name": "Amit Saha"}, "author": "Amit Saha", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijcsit.2011.3605", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1201.2010v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1201.2010v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "13 pages, 13 figures", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1201.2010v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1201.2010v1", "journal_reference": null, "doi": "10.5121/ijcsit.2011.3605"}
{"id": "http://arxiv.org/abs/1203.0876v1", "guidislink": true, "updated": "2012-03-05T12:06:54Z", "updated_parsed": [2012, 3, 5, 12, 6, 54, 0, 65, 0], "published": "2012-03-05T12:06:54Z", "published_parsed": [2012, 3, 5, 12, 6, 54, 0, 65, 0], "title": "An MLP based Approach for Recognition of Handwritten `Bangla' Numerals", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An MLP based Approach for Recognition of Handwritten `Bangla' Numerals"}, "summary": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased pattern classifier for recognition of handwritten Bangla digits using a\n76 element feature vector. Bangla is the second most popular script and\nlanguage in the Indian subcontinent and the fifth most popular language in the\nworld. The feature set developed for representing handwritten Bangla numerals\nhere includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. On experimentation with a database of 6000 samples, the technique\nyields an average recognition rate of 96.67% evaluated after three-fold cross\nvalidation of results. It is useful for applications related to OCR of\nhandwritten Bangla Digit and can also be extended to include OCR of handwritten\ncharacters of Bangla alphabet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased pattern classifier for recognition of handwritten Bangla digits using a\n76 element feature vector. Bangla is the second most popular script and\nlanguage in the Indian subcontinent and the fifth most popular language in the\nworld. The feature set developed for representing handwritten Bangla numerals\nhere includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. On experimentation with a database of 6000 samples, the technique\nyields an average recognition rate of 96.67% evaluated after three-fold cross\nvalidation of results. It is useful for applications related to OCR of\nhandwritten Bangla Digit and can also be extended to include OCR of handwritten\ncharacters of Bangla alphabet."}, "authors": ["Subhadip Basu", "Nibaran Das", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1203.0876v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.0876v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.0876v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.0876v1", "arxiv_comment": null, "journal_reference": "Proc. 2nd Indian International Conference on Artificial\n  Intelligence, pp. 407-417, Dec. 2005, Pune", "doi": null}
{"id": "http://arxiv.org/abs/1203.0882v1", "guidislink": true, "updated": "2012-03-05T12:22:23Z", "updated_parsed": [2012, 3, 5, 12, 22, 23, 0, 65, 0], "published": "2012-03-05T12:22:23Z", "published_parsed": [2012, 3, 5, 12, 22, 23, 0, 65, 0], "title": "Handwritten Bangla Alphabet Recognition using an MLP Based Classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Alphabet Recognition using an MLP Based Classifier"}, "summary": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased classifier for recognition of handwritten Bangla alphabet using a 76\nelement feature set Bangla is the second most popular script and language in\nthe Indian subcontinent and the fifth most popular language in the world. The\nfeature set developed for representing handwritten characters of Bangla\nalphabet includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. Recognition performances of the MLP designed to work with this\nfeature set are experimentally observed as 86.46% and 75.05% on the samples of\nthe training and the test sets respectively. The work has useful application in\nthe development of a complete OCR system for handwritten Bangla text.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased classifier for recognition of handwritten Bangla alphabet using a 76\nelement feature set Bangla is the second most popular script and language in\nthe Indian subcontinent and the fifth most popular language in the world. The\nfeature set developed for representing handwritten characters of Bangla\nalphabet includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. Recognition performances of the MLP designed to work with this\nfeature set are experimentally observed as 86.46% and 75.05% on the samples of\nthe training and the test sets respectively. The work has useful application in\nthe development of a complete OCR system for handwritten Bangla text."}, "authors": ["Subhadip Basu", "Nibaran Das", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1203.0882v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.0882v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.0882v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.0882v1", "arxiv_comment": null, "journal_reference": "Proc. of the 2nd National Conf. on Computer Processing of Bangla,\n  pp. 285-291, Feb-2005, Dhaka", "doi": null}
{"id": "http://arxiv.org/abs/1410.2045v1", "guidislink": true, "updated": "2014-10-08T10:01:47Z", "updated_parsed": [2014, 10, 8, 10, 1, 47, 2, 281, 0], "published": "2014-10-08T10:01:47Z", "published_parsed": [2014, 10, 8, 10, 1, 47, 2, 281, 0], "title": "Supervised learning Methods for Bangla Web Document Categorization", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Supervised learning Methods for Bangla Web Document Categorization"}, "summary": "This paper explores the use of machine learning approaches, or more\nspecifically, four supervised learning Methods, namely Decision Tree(C 4.5),\nK-Nearest Neighbour (KNN), Na\\\"ive Bays (NB), and Support Vector Machine (SVM)\nfor categorization of Bangla web documents. This is a task of automatically\nsorting a set of documents into categories from a predefined set. Whereas a\nwide range of methods have been applied to English text categorization,\nrelatively few studies have been conducted on Bangla language text\ncategorization. Hence, we attempt to analyze the efficiency of those four\nmethods for categorization of Bangla documents. In order to validate, Bangla\ncorpus from various websites has been developed and used as examples for the\nexperiment. For Bangla, empirical results support that all four methods produce\nsatisfactory performance with SVM attaining good result in terms of high\ndimensional and relatively noisy document feature vectors.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper explores the use of machine learning approaches, or more\nspecifically, four supervised learning Methods, namely Decision Tree(C 4.5),\nK-Nearest Neighbour (KNN), Na\\\"ive Bays (NB), and Support Vector Machine (SVM)\nfor categorization of Bangla web documents. This is a task of automatically\nsorting a set of documents into categories from a predefined set. Whereas a\nwide range of methods have been applied to English text categorization,\nrelatively few studies have been conducted on Bangla language text\ncategorization. Hence, we attempt to analyze the efficiency of those four\nmethods for categorization of Bangla documents. In order to validate, Bangla\ncorpus from various websites has been developed and used as examples for the\nexperiment. For Bangla, empirical results support that all four methods produce\nsatisfactory performance with SVM attaining good result in terms of high\ndimensional and relatively noisy document feature vectors."}, "authors": ["Ashis Kumar Mandal", "Rikta Sen"], "author_detail": {"name": "Rikta Sen"}, "author": "Rikta Sen", "arxiv_comment": "13 pages, International Journal of Artificial Intelligence &\n  Applications (IJAIA), Vol. 5, No. 5, September 2014", "links": [{"href": "http://arxiv.org/abs/1410.2045v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.2045v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.2045v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.2045v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1009.4982v1", "guidislink": true, "updated": "2010-09-25T06:55:27Z", "updated_parsed": [2010, 9, 25, 6, 55, 27, 5, 268, 0], "published": "2010-09-25T06:55:27Z", "published_parsed": [2010, 9, 25, 6, 55, 27, 5, 268, 0], "title": "Optimal Bangla Keyboard Layout using Data Mining Technique", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Optimal Bangla Keyboard Layout using Data Mining Technique"}, "summary": "This paper presents an optimal Bangla Keyboard Layout, which distributes the\nload equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Experimental results on several data show the effectiveness of the\nproposed approach with better performance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents an optimal Bangla Keyboard Layout, which distributes the\nload equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Experimental results on several data show the effectiveness of the\nproposed approach with better performance."}, "authors": ["S. M. Kamruzzaman", "Md. Hijbul Alam", "Abdul Kadar Muhammad Masum", "Md. Mahadi Hassan"], "author_detail": {"name": "Md. Mahadi Hassan"}, "author": "Md. Mahadi Hassan", "arxiv_comment": "9 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4982v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4982v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4982v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4982v1", "journal_reference": "Proc. International Conference on Information and Communication\n  Technology in Management (ICTM 2005), Multimedia University, Malaysia, May\n  2005", "doi": null}
{"id": "http://arxiv.org/abs/1009.5048v1", "guidislink": true, "updated": "2010-09-26T02:09:41Z", "updated_parsed": [2010, 9, 26, 2, 9, 41, 6, 269, 0], "published": "2010-09-26T02:09:41Z", "published_parsed": [2010, 9, 26, 2, 9, 41, 6, 269, 0], "title": "The Most Advantageous Bangla Keyboard Layout Using Data Mining Technique", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The Most Advantageous Bangla Keyboard Layout Using Data Mining Technique"}, "summary": "Bangla alphabet has a large number of letters, for this it is complicated to\ntype faster using Bangla keyboard. The proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Association rule\nof data mining to distribute the Bangla characters in the keyboard is used\nhere. The frequencies of data consisting of monograph, digraph and trigraph are\nanalyzed, which are derived from data wire-house, and then used association\nrule of data mining to distribute the Bangla characters in the layout.\nExperimental results on several data show the effectiveness of the proposed\napproach with better performance. This paper presents an optimal Bangla\nKeyboard Layout, which distributes the load equally on both hands so that\nmaximizing the ease and minimizing the effort.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla alphabet has a large number of letters, for this it is complicated to\ntype faster using Bangla keyboard. The proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Association rule\nof data mining to distribute the Bangla characters in the keyboard is used\nhere. The frequencies of data consisting of monograph, digraph and trigraph are\nanalyzed, which are derived from data wire-house, and then used association\nrule of data mining to distribute the Bangla characters in the layout.\nExperimental results on several data show the effectiveness of the proposed\napproach with better performance. This paper presents an optimal Bangla\nKeyboard Layout, which distributes the load equally on both hands so that\nmaximizing the ease and minimizing the effort."}, "authors": ["Abdul Kadar Muhammad Masum", "Mohammad Mahadi Hassan", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "10 Pages, International Journal", "links": [{"href": "http://arxiv.org/abs/1009.5048v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.5048v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.5048v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.5048v1", "journal_reference": "Journal of Computer Science, IBAIS University, Dkhaka, Bangladesh,\n  Vol. 1, No. 2, Dec. 2007", "doi": null}
{"id": "http://arxiv.org/abs/1002.4040v2", "guidislink": true, "updated": "2010-02-23T06:44:32Z", "updated_parsed": [2010, 2, 23, 6, 44, 32, 1, 54, 0], "published": "2010-02-22T02:58:49Z", "published_parsed": [2010, 2, 22, 2, 58, 49, 0, 53, 0], "title": "Handwritten Bangla Basic and Compound character recognition using MLP\n  and SVM classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Basic and Compound character recognition using MLP\n  and SVM classifier"}, "summary": "A novel approach for recognition of handwritten compound Bangla characters,\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\nto English like Roman script, one of the major stumbling blocks in Optical\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\ncharacter classes, there are nearly 160 complex shaped compound character\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\ncharacters with a suitably designed feature set is a challenging problem.\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\na large varieties of complex shaped characters, some of which have close\nresemblance, makes the problem of OCR of handwritten Bangla characters more\ndifficult. Considering the complexity of the problem, the present approach\nmakes an attempt to identify compound character classes from most frequently to\nless frequently occurred ones, i.e., in order of importance. This is to develop\na frame work for incrementally increasing the number of learned classes of\ncompound characters from more frequently occurred ones to less frequently\noccurred ones along with Basic characters. On experimentation, the technique is\nobserved produce an average recognition rate of 79.25 after three fold cross\nvalidation of data with future scope of improvement and extension.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A novel approach for recognition of handwritten compound Bangla characters,\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\nto English like Roman script, one of the major stumbling blocks in Optical\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\ncharacter classes, there are nearly 160 complex shaped compound character\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\ncharacters with a suitably designed feature set is a challenging problem.\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\na large varieties of complex shaped characters, some of which have close\nresemblance, makes the problem of OCR of handwritten Bangla characters more\ndifficult. Considering the complexity of the problem, the present approach\nmakes an attempt to identify compound character classes from most frequently to\nless frequently occurred ones, i.e., in order of importance. This is to develop\na frame work for incrementally increasing the number of learned classes of\ncompound characters from more frequently occurred ones to less frequently\noccurred ones along with Basic characters. On experimentation, the technique is\nobserved produce an average recognition rate of 79.25 after three fold cross\nvalidation of data with future scope of improvement and extension."}, "authors": ["Nibaran Das", "Bindaban Das", "Ram Sarkar", "Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/1002.4040v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.4040v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.4040v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1002.4040v2", "arxiv_comment": null, "journal_reference": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null}
{"id": "http://arxiv.org/abs/1410.0478v1", "guidislink": true, "updated": "2014-10-02T08:26:38Z", "updated_parsed": [2014, 10, 2, 8, 26, 38, 3, 275, 0], "published": "2014-10-02T08:26:38Z", "published_parsed": [2014, 10, 2, 8, 26, 38, 3, 275, 0], "title": "Recognition of Handwritten Bangla Basic Characters and Digits using\n  Convex Hull based Feature Set", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recognition of Handwritten Bangla Basic Characters and Digits using\n  Convex Hull based Feature Set"}, "summary": "In dealing with the problem of recognition of handwritten character patterns\nof varying shapes and sizes, selection of a proper feature set is important to\nachieve high recognition performance. The current research aims to evaluate the\nperformance of the convex hull based feature set, i.e. 125 features in all\ncomputed over different bays attributes of the convex hull of a pattern, for\neffective recognition of isolated handwritten Bangla basic characters and\ndigits. On experimentation with a database of 10000 samples, the maximum\nrecognition rate of 76.86% is observed for handwritten Bangla characters. For\nBangla numerals the maximum success rate of 99.45%. is achieved on a database\nof 12000 sample. The current work validates the usefulness of a new kind of\nfeature set for recognition of handwritten Bangla basic characters and\nnumerals.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In dealing with the problem of recognition of handwritten character patterns\nof varying shapes and sizes, selection of a proper feature set is important to\nachieve high recognition performance. The current research aims to evaluate the\nperformance of the convex hull based feature set, i.e. 125 features in all\ncomputed over different bays attributes of the convex hull of a pattern, for\neffective recognition of isolated handwritten Bangla basic characters and\ndigits. On experimentation with a database of 10000 samples, the maximum\nrecognition rate of 76.86% is observed for handwritten Bangla characters. For\nBangla numerals the maximum success rate of 99.45%. is achieved on a database\nof 12000 sample. The current work validates the usefulness of a new kind of\nfeature set for recognition of handwritten Bangla basic characters and\nnumerals."}, "authors": ["Nibaran Das", "Sandip Pramanik", "Subhadip Basu", "Punam Kumar Saha", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"title": "doi", "href": "http://dx.doi.org/10.13140/2.1.3689.4089", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1410.0478v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.0478v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.0478v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.0478v1", "arxiv_comment": null, "journal_reference": "2009 International Conference on Artificial Intelligence and\n  Pattern Recognition, At Orlando, Florida pp. 380-386", "doi": "10.13140/2.1.3689.4089"}
{"id": "http://arxiv.org/abs/1701.08702v1", "guidislink": true, "updated": "2017-01-27T18:43:31Z", "updated_parsed": [2017, 1, 27, 18, 43, 31, 4, 27, 0], "published": "2017-01-27T18:43:31Z", "published_parsed": [2017, 1, 27, 18, 43, 31, 4, 27, 0], "title": "Bangla Word Clustering Based on Tri-gram, 4-gram and 5-gram Language\n  Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Word Clustering Based on Tri-gram, 4-gram and 5-gram Language\n  Model"}, "summary": "In this paper, we describe a research method that generates Bangla word\nclusters on the basis of relating to meaning in language and contextual\nsimilarity. The importance of word clustering is in parts of speech (POS)\ntagging, word sense disambiguation, text classification, recommender system,\nspell checker, grammar checker, knowledge discover and for many others Natural\nLanguage Processing (NLP) applications. In the history of word clustering,\nEnglish and some other languages have already implemented some methods on word\nclustering efficiently. But due to lack of the resources, word clustering in\nBangla has not been still implemented efficiently. Presently, its\nimplementation is in the beginning stage. In some research of word clustering\nin English based on preceding and next five words of a key word they found an\nefficient result. Now, we are trying to implement the tri-gram, 4-gram and\n5-gram model of word clustering for Bangla to observe which one is the best\namong them. We have started our research with quite a large corpus of\napproximate 1 lakh Bangla words. We are using a machine learning technique in\nthis research. We will generate word clusters and analyze the clusters by\ntesting some different threshold values.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we describe a research method that generates Bangla word\nclusters on the basis of relating to meaning in language and contextual\nsimilarity. The importance of word clustering is in parts of speech (POS)\ntagging, word sense disambiguation, text classification, recommender system,\nspell checker, grammar checker, knowledge discover and for many others Natural\nLanguage Processing (NLP) applications. In the history of word clustering,\nEnglish and some other languages have already implemented some methods on word\nclustering efficiently. But due to lack of the resources, word clustering in\nBangla has not been still implemented efficiently. Presently, its\nimplementation is in the beginning stage. In some research of word clustering\nin English based on preceding and next five words of a key word they found an\nefficient result. Now, we are trying to implement the tri-gram, 4-gram and\n5-gram model of word clustering for Bangla to observe which one is the best\namong them. We have started our research with quite a large corpus of\napproximate 1 lakh Bangla words. We are using a machine learning technique in\nthis research. We will generate word clusters and analyze the clusters by\ntesting some different threshold values."}, "authors": ["Dipaloke Saha", "Md Saddam Hossain", "MD. Saiful Islam", "Sabir Ismail"], "author_detail": {"name": "Sabir Ismail"}, "author": "Sabir Ismail", "arxiv_comment": "6 pages", "links": [{"href": "http://arxiv.org/abs/1701.08702v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08702v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08702v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08702v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1809.00339v1", "guidislink": true, "updated": "2018-09-02T14:03:30Z", "updated_parsed": [2018, 9, 2, 14, 3, 30, 6, 245, 0], "published": "2018-09-02T14:03:30Z", "published_parsed": [2018, 9, 2, 14, 3, 30, 6, 245, 0], "title": "Chittron: An Automatic Bangla Image Captioning System", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Chittron: An Automatic Bangla Image Captioning System"}, "summary": "Automatic image caption generation aims to produce an accurate description of\nan image in natural language automatically. However, Bangla, the fifth most\nwidely spoken language in the world, is lagging considerably in the research\nand development of such domain. Besides, while there are many established data\nsets to related to image annotation in English, no such resource exists for\nBangla yet. Hence, this paper outlines the development of \"Chittron\", an\nautomatic image captioning system in Bangla. Moreover, to address the data set\navailability issue, a collection of 16,000 Bangladeshi contextual images has\nbeen accumulated and manually annotated in Bangla. This data set is then used\nto train a model which integrates a pre-trained VGG16 image embedding model\nwith stacked LSTM layers. The model is trained to predict the caption when the\ninput is an image, one word at a time. The results show that the model has\nsuccessfully been able to learn a working language model and to generate\ncaptions of images quite accurately in many cases. The results are evaluated\nmainly qualitatively. However, BLEU scores are also reported. It is expected\nthat a better result can be obtained with a bigger and more varied data set.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic image caption generation aims to produce an accurate description of\nan image in natural language automatically. However, Bangla, the fifth most\nwidely spoken language in the world, is lagging considerably in the research\nand development of such domain. Besides, while there are many established data\nsets to related to image annotation in English, no such resource exists for\nBangla yet. Hence, this paper outlines the development of \"Chittron\", an\nautomatic image captioning system in Bangla. Moreover, to address the data set\navailability issue, a collection of 16,000 Bangladeshi contextual images has\nbeen accumulated and manually annotated in Bangla. This data set is then used\nto train a model which integrates a pre-trained VGG16 image embedding model\nwith stacked LSTM layers. The model is trained to predict the caption when the\ninput is an image, one word at a time. The results show that the model has\nsuccessfully been able to learn a working language model and to generate\ncaptions of images quite accurately in many cases. The results are evaluated\nmainly qualitatively. However, BLEU scores are also reported. It is expected\nthat a better result can be obtained with a bigger and more varied data set."}, "authors": ["Motiur Rahman", "Nabeel Mohammed", "Nafees Mansoor", "Sifat Momen"], "author_detail": {"name": "Sifat Momen"}, "author": "Sifat Momen", "links": [{"href": "http://arxiv.org/abs/1809.00339v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1809.00339v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1809.00339v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1809.00339v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1401.1190v1", "guidislink": true, "updated": "2014-01-06T20:25:26Z", "updated_parsed": [2014, 1, 6, 20, 25, 26, 0, 6, 0], "published": "2014-01-06T20:25:26Z", "published_parsed": [2014, 1, 6, 20, 25, 26, 0, 6, 0], "title": "Bangla Text Recognition from Video Sequence: A New Focus", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Text Recognition from Video Sequence: A New Focus"}, "summary": "Extraction and recognition of Bangla text from video frame images is\nchallenging due to complex color background, low-resolution etc. In this paper,\nwe propose an algorithm for extraction and recognition of Bangla text form such\nvideo frames with complex background. Here, a two-step approach has been\nproposed. First, the text line is segmented into words using information based\non line contours. First order gradient value of the text blocks are used to\nfind the word gap. Next, a local binarization technique is applied on each word\nand text line is reconstructed using those words. Secondly, this binarized text\nblock is sent to OCR for recognition purpose.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Extraction and recognition of Bangla text from video frame images is\nchallenging due to complex color background, low-resolution etc. In this paper,\nwe propose an algorithm for extraction and recognition of Bangla text form such\nvideo frames with complex background. Here, a two-step approach has been\nproposed. First, the text line is segmented into words using information based\non line contours. First order gradient value of the text blocks are used to\nfind the word gap. Next, a local binarization technique is applied on each word\nand text line is reconstructed using those words. Secondly, this binarized text\nblock is sent to OCR for recognition purpose."}, "authors": ["Souvik Bhowmick", "Purnendu Banerjee"], "author_detail": {"name": "Purnendu Banerjee"}, "author": "Purnendu Banerjee", "links": [{"href": "http://arxiv.org/abs/1401.1190v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1401.1190v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1401.1190v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1401.1190v1", "arxiv_comment": null, "journal_reference": "NATIONAL CONFERENCE ON COMPUTING AND SYSTEMS (NaCCS), pp.\n  62-67,2012", "doi": null}
{"id": "http://arxiv.org/abs/1610.00369v2", "guidislink": true, "updated": "2016-11-24T02:13:05Z", "updated_parsed": [2016, 11, 24, 2, 13, 5, 3, 329, 0], "published": "2016-10-02T23:45:23Z", "published_parsed": [2016, 10, 2, 23, 45, 23, 6, 276, 0], "title": "Sentiment Analysis on Bangla and Romanized Bangla Text (BRBT) using Deep\n  Recurrent models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Analysis on Bangla and Romanized Bangla Text (BRBT) using Deep\n  Recurrent models"}, "summary": "Sentiment Analysis (SA) is an action research area in the digital age. With\nrapid and constant growth of online social media sites and services, and the\nincreasing amount of textual data such as - statuses, comments, reviews etc.\navailable in them, application of automatic SA is on the rise. However, most of\nthe research works on SA in natural language processing (NLP) are based on\nEnglish language. Despite being the sixth most widely spoken language in the\nworld, Bangla still does not have a large and standard dataset. Because of\nthis, recent research works in Bangla have failed to produce results that can\nbe both comparable to works done by others and reusable as stepping stones for\nfuture researchers to progress in this field. Therefore, we first tried to\nprovide a textual dataset - that includes not just Bangla, but Romanized Bangla\ntexts as well, is substantial, post-processed and multiple validated, ready to\nbe used in SA experiments. We tested this dataset in Deep Recurrent model,\nspecifically, Long Short Term Memory (LSTM), using two types of loss functions\n- binary crossentropy and categorical crossentropy, and also did some\nexperimental pre-training by using data from one validation to pre-train the\nother and vice versa. Lastly, we documented the results along with some\nanalysis on them, which were promising.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Analysis (SA) is an action research area in the digital age. With\nrapid and constant growth of online social media sites and services, and the\nincreasing amount of textual data such as - statuses, comments, reviews etc.\navailable in them, application of automatic SA is on the rise. However, most of\nthe research works on SA in natural language processing (NLP) are based on\nEnglish language. Despite being the sixth most widely spoken language in the\nworld, Bangla still does not have a large and standard dataset. Because of\nthis, recent research works in Bangla have failed to produce results that can\nbe both comparable to works done by others and reusable as stepping stones for\nfuture researchers to progress in this field. Therefore, we first tried to\nprovide a textual dataset - that includes not just Bangla, but Romanized Bangla\ntexts as well, is substantial, post-processed and multiple validated, ready to\nbe used in SA experiments. We tested this dataset in Deep Recurrent model,\nspecifically, Long Short Term Memory (LSTM), using two types of loss functions\n- binary crossentropy and categorical crossentropy, and also did some\nexperimental pre-training by using data from one validation to pre-train the\nother and vice versa. Lastly, we documented the results along with some\nanalysis on them, which were promising."}, "authors": ["A. Hassan", "M. R. Amin", "N. Mohammed", "A. K. A. Azad"], "author_detail": {"name": "A. K. A. Azad"}, "author": "A. K. A. Azad", "links": [{"href": "http://arxiv.org/abs/1610.00369v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1610.00369v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1610.00369v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1610.00369v2", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1705.02680v1", "guidislink": true, "updated": "2017-05-07T18:49:27Z", "updated_parsed": [2017, 5, 7, 18, 49, 27, 6, 127, 0], "published": "2017-05-07T18:49:27Z", "published_parsed": [2017, 5, 7, 18, 49, 27, 6, 127, 0], "title": "Handwritten Bangla Digit Recognition Using Deep Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Digit Recognition Using Deep Learning"}, "summary": "In spite of the advances in pattern recognition technology, Handwritten\nBangla Character Recognition (HBCR) (such as alpha-numeric and special\ncharacters) remains largely unsolved due to the presence of many perplexing\ncharacters and excessive cursive in Bangla handwriting. Even the best existing\nrecognizers do not lead to satisfactory performance for practical applications.\nTo improve the performance of Handwritten Bangla Digit Recognition (HBDR), we\nherein present a new approach based on deep neural networks which have recently\nshown excellent performance in many pattern recognition and machine learning\napplications, but has not been throughly attempted for HBDR. We introduce\nBangla digit recognition techniques based on Deep Belief Network (DBN),\nConvolutional Neural Networks (CNN), CNN with dropout, CNN with dropout and\nGaussian filters, and CNN with dropout and Gabor filters. These networks have\nthe advantage of extracting and using feature information, improving the\nrecognition of two dimensional shapes with a high degree of invariance to\ntranslation, scaling and other pattern distortions. We systematically evaluated\nthe performance of our method on publicly available Bangla numeral image\ndatabase named CMATERdb 3.1.1. From experiments, we achieved 98.78% recognition\nrate using the proposed method: CNN with Gabor features and dropout, which\noutperforms the state-of-the-art algorithms for HDBR.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In spite of the advances in pattern recognition technology, Handwritten\nBangla Character Recognition (HBCR) (such as alpha-numeric and special\ncharacters) remains largely unsolved due to the presence of many perplexing\ncharacters and excessive cursive in Bangla handwriting. Even the best existing\nrecognizers do not lead to satisfactory performance for practical applications.\nTo improve the performance of Handwritten Bangla Digit Recognition (HBDR), we\nherein present a new approach based on deep neural networks which have recently\nshown excellent performance in many pattern recognition and machine learning\napplications, but has not been throughly attempted for HBDR. We introduce\nBangla digit recognition techniques based on Deep Belief Network (DBN),\nConvolutional Neural Networks (CNN), CNN with dropout, CNN with dropout and\nGaussian filters, and CNN with dropout and Gabor filters. These networks have\nthe advantage of extracting and using feature information, improving the\nrecognition of two dimensional shapes with a high degree of invariance to\ntranslation, scaling and other pattern distortions. We systematically evaluated\nthe performance of our method on publicly available Bangla numeral image\ndatabase named CMATERdb 3.1.1. From experiments, we achieved 98.78% recognition\nrate using the proposed method: CNN with Gabor features and dropout, which\noutperforms the state-of-the-art algorithms for HDBR."}, "authors": ["Md Zahangir Alom", "Paheding Sidike", "Tarek M. Taha", "Vijayan K. Asari"], "author_detail": {"name": "Vijayan K. Asari"}, "author": "Vijayan K. Asari", "arxiv_comment": "12 pages, 10 figures, 3 tables", "links": [{"href": "http://arxiv.org/abs/1705.02680v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1705.02680v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1705.02680v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1705.02680v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1208.0995v1", "guidislink": true, "updated": "2012-08-05T09:22:06Z", "updated_parsed": [2012, 8, 5, 9, 22, 6, 6, 218, 0], "published": "2012-08-05T09:22:06Z", "published_parsed": [2012, 8, 5, 9, 22, 6, 6, 218, 0], "title": "Design and implementation of a digital clock showing digits in Bangla\n  font using microcontroller AT89C4051", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Design and implementation of a digital clock showing digits in Bangla\n  font using microcontroller AT89C4051"}, "summary": "In this paper, a digital clock is designed where the microcontroller is used\nfor timing controller and the font of the Bangla digits are designed, and\nprogrammed within the microcontroller. The design is cost effective, simple and\neasy for maintenance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, a digital clock is designed where the microcontroller is used\nfor timing controller and the font of the Bangla digits are designed, and\nprogrammed within the microcontroller. The design is cost effective, simple and\neasy for maintenance."}, "authors": ["Nasif Muslim", "Md. Tanvir Adnan", "Mohammad Zahidul Kabir", "Md. Humayun Kabir", "Sheikh Mominul Islam"], "author_detail": {"name": "Sheikh Mominul Islam"}, "author": "Sheikh Mominul Islam", "links": [{"href": "http://arxiv.org/abs/1208.0995v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1208.0995v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1208.0995v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1208.0995v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1308.3785v1", "guidislink": true, "updated": "2013-08-17T14:04:00Z", "updated_parsed": [2013, 8, 17, 14, 4, 0, 5, 229, 0], "published": "2013-08-17T14:04:00Z", "published_parsed": [2013, 8, 17, 14, 4, 0, 5, 229, 0], "title": "Implementation Of Back-Propagation Neural Network For Isolated Bangla\n  Speech Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Implementation Of Back-Propagation Neural Network For Isolated Bangla\n  Speech Recognition"}, "summary": "This paper is concerned with the development of Back-propagation Neural\nNetwork for Bangla Speech Recognition. In this paper, ten bangla digits were\nrecorded from ten speakers and have been recognized. The features of these\nspeech digits were extracted by the method of Mel Frequency Cepstral\nCoefficient (MFCC) analysis. The mfcc features of five speakers were used to\ntrain the network with Back propagation algorithm. The mfcc features of ten\nbangla digit speeches, from 0 to 9, of another five speakers were used to test\nthe system. All the methods and algorithms used in this research were\nimplemented using the features of Turbo C and C++ languages. From our\ninvestigation it is seen that the developed system can successfully encode and\nanalyze the mfcc features of the speech signal to recognition. The developed\nsystem achieved recognition rate about 96.332% for known speakers (i.e.,\nspeaker dependent) and 92% for unknown speakers (i.e., speaker independent).", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper is concerned with the development of Back-propagation Neural\nNetwork for Bangla Speech Recognition. In this paper, ten bangla digits were\nrecorded from ten speakers and have been recognized. The features of these\nspeech digits were extracted by the method of Mel Frequency Cepstral\nCoefficient (MFCC) analysis. The mfcc features of five speakers were used to\ntrain the network with Back propagation algorithm. The mfcc features of ten\nbangla digit speeches, from 0 to 9, of another five speakers were used to test\nthe system. All the methods and algorithms used in this research were\nimplemented using the features of Turbo C and C++ languages. From our\ninvestigation it is seen that the developed system can successfully encode and\nanalyze the mfcc features of the speech signal to recognition. The developed\nsystem achieved recognition rate about 96.332% for known speakers (i.e.,\nspeaker dependent) and 92% for unknown speakers (i.e., speaker independent)."}, "authors": ["Md. Ali Hossain", "Md. Mijanur Rahman", "Uzzal Kumar Prodhan", "Md. Farukuzzaman Khan"], "author_detail": {"name": "Md. Farukuzzaman Khan"}, "author": "Md. Farukuzzaman Khan", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijist.2013.3401", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1308.3785v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1308.3785v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "9 pages, 3 figures, 1 table", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1308.3785v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1308.3785v1", "journal_reference": "International Journal of Information Sciences and Techniques\n  (IJIST) Vol.3, No.4, July 2013", "doi": "10.5121/ijist.2013.3401"}
{"id": "http://arxiv.org/abs/1003.5897v1", "guidislink": true, "updated": "2010-03-30T18:54:57Z", "updated_parsed": [2010, 3, 30, 18, 54, 57, 1, 89, 0], "published": "2010-03-30T18:54:57Z", "published_parsed": [2010, 3, 30, 18, 54, 57, 1, 89, 0], "title": "Development of a Multi-User Recognition Engine for Handwritten Bangla\n  Basic Characters and Digits", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Development of a Multi-User Recognition Engine for Handwritten Bangla\n  Basic Characters and Digits"}, "summary": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset."}, "authors": ["Sandip Rakshit", "Debkumar Ghosal", "Tanmoy Das", "Subhrajit Dutta", "Subhadip Basu"], "author_detail": {"name": "Subhadip Basu"}, "author": "Subhadip Basu", "arxiv_comment": "Proc. (CD) Int. Conf. on Information Technology and Business\n  Intelligence (2009)", "links": [{"href": "http://arxiv.org/abs/1003.5897v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1003.5897v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1003.5897v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1003.5897v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1602.07803v1", "guidislink": true, "updated": "2016-02-25T05:35:16Z", "updated_parsed": [2016, 2, 25, 5, 35, 16, 3, 56, 0], "published": "2016-02-25T05:35:16Z", "published_parsed": [2016, 2, 25, 5, 35, 16, 3, 56, 0], "title": "Automated Word Prediction in Bangla Language Using Stochastic Language\n  Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automated Word Prediction in Bangla Language Using Stochastic Language\n  Models"}, "summary": "Word completion and word prediction are two important phenomena in typing\nthat benefit users who type using keyboard or other similar devices. They can\nhave profound impact on the typing of disable people. Our work is based on word\nprediction on Bangla sentence by using stochastic, i.e. N-gram language model\nsuch as unigram, bigram, trigram, deleted Interpolation and backoff models for\nauto completing a sentence by predicting a correct word in a sentence which\nsaves time and keystrokes of typing and also reduces misspelling. We use large\ndata corpus of Bangla language of different word types to predict correct word\nwith the accuracy as much as possible. We have found promising results. We hope\nthat our work will impact on the baseline for automated Bangla typing.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word completion and word prediction are two important phenomena in typing\nthat benefit users who type using keyboard or other similar devices. They can\nhave profound impact on the typing of disable people. Our work is based on word\nprediction on Bangla sentence by using stochastic, i.e. N-gram language model\nsuch as unigram, bigram, trigram, deleted Interpolation and backoff models for\nauto completing a sentence by predicting a correct word in a sentence which\nsaves time and keystrokes of typing and also reduces misspelling. We use large\ndata corpus of Bangla language of different word types to predict correct word\nwith the accuracy as much as possible. We have found promising results. We hope\nthat our work will impact on the baseline for automated Bangla typing."}, "authors": ["Md. Masudul Haque", "Md. Tarek Habib", "Md. Mokhlesur Rahman"], "author_detail": {"name": "Md. Mokhlesur Rahman"}, "author": "Md. Mokhlesur Rahman", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijfcst.2015.5607", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1602.07803v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1602.07803v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "in International Journal in Foundations of Computer Science &\n  Technology (IJFCST) Vol.5, No.6, November 2015", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1602.07803v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1602.07803v1", "journal_reference": null, "doi": "10.5121/ijfcst.2015.5607"}
{"id": "http://arxiv.org/abs/1310.1590v1", "guidislink": true, "updated": "2013-10-06T14:37:05Z", "updated_parsed": [2013, 10, 6, 14, 37, 5, 6, 279, 0], "published": "2013-10-06T14:37:05Z", "published_parsed": [2013, 10, 6, 14, 37, 5, 6, 279, 0], "title": "Evolution of the Modern Phase of Written Bangla: A Statistical Study", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Evolution of the Modern Phase of Written Bangla: A Statistical Study"}, "summary": "Active languages such as Bangla (or Bengali) evolve over time due to a\nvariety of social, cultural, economic, and political issues. In this paper, we\nanalyze the change in the written form of the modern phase of Bangla\nquantitatively in terms of character-level, syllable-level, morpheme-level and\nword-level features. We collect three different types of corpora---classical,\nnewspapers and blogs---and test whether the differences in their features are\nstatistically significant. Results suggest that there are significant changes\nin the length of a word when measured in terms of characters, but there is not\nmuch difference in usage of different characters, syllables and morphemes in a\nword or of different words in a sentence. To the best of our knowledge, this is\nthe first work on Bangla of this kind.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Active languages such as Bangla (or Bengali) evolve over time due to a\nvariety of social, cultural, economic, and political issues. In this paper, we\nanalyze the change in the written form of the modern phase of Bangla\nquantitatively in terms of character-level, syllable-level, morpheme-level and\nword-level features. We collect three different types of corpora---classical,\nnewspapers and blogs---and test whether the differences in their features are\nstatistically significant. Results suggest that there are significant changes\nin the length of a word when measured in terms of characters, but there is not\nmuch difference in usage of different characters, syllables and morphemes in a\nword or of different words in a sentence. To the best of our knowledge, this is\nthe first work on Bangla of this kind."}, "authors": ["Paheli Bhattacharya", "Arnab Bhattacharya"], "author_detail": {"name": "Arnab Bhattacharya"}, "author": "Arnab Bhattacharya", "arxiv_comment": "LCC 2013", "links": [{"href": "http://arxiv.org/abs/1310.1590v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1310.1590v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1310.1590v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1310.1590v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1809.00905v1", "guidislink": true, "updated": "2018-09-04T11:55:34Z", "updated_parsed": [2018, 9, 4, 11, 55, 34, 1, 247, 0], "published": "2018-09-04T11:55:34Z", "published_parsed": [2018, 9, 4, 11, 55, 34, 1, 247, 0], "title": "Bangla License Plate Recognition Using Convolutional Neural Networks\n  (CNN)", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla License Plate Recognition Using Convolutional Neural Networks\n  (CNN)"}, "summary": "In the last few years, the deep learning technique in particular\nConvolutional Neural Networks (CNNs) is using massively in the field of\ncomputer vision and machine learning. This deep learning technique provides\nstate-of-the-art accuracy in different classification, segmentation, and\ndetection tasks on different benchmarks such as MNIST, CIFAR-10, CIFAR-100,\nMicrosoft COCO, and ImageNet. However, there are a lot of research has been\nconducted for Bangla License plate recognition with traditional machine\nlearning approaches in last decade. None of them are used to deploy a physical\nsystem for Bangla License Plate Recognition System (BLPRS) due to their poor\nrecognition accuracy. In this paper, we have implemented CNNs based Bangla\nlicense plate recognition system with better accuracy that can be applied for\ndifferent purposes including roadside assistance, automatic parking lot\nmanagement system, vehicle license status detection and so on. Along with that,\nwe have also created and released a very first and standard database for BLPRS.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In the last few years, the deep learning technique in particular\nConvolutional Neural Networks (CNNs) is using massively in the field of\ncomputer vision and machine learning. This deep learning technique provides\nstate-of-the-art accuracy in different classification, segmentation, and\ndetection tasks on different benchmarks such as MNIST, CIFAR-10, CIFAR-100,\nMicrosoft COCO, and ImageNet. However, there are a lot of research has been\nconducted for Bangla License plate recognition with traditional machine\nlearning approaches in last decade. None of them are used to deploy a physical\nsystem for Bangla License Plate Recognition System (BLPRS) due to their poor\nrecognition accuracy. In this paper, we have implemented CNNs based Bangla\nlicense plate recognition system with better accuracy that can be applied for\ndifferent purposes including roadside assistance, automatic parking lot\nmanagement system, vehicle license status detection and so on. Along with that,\nwe have also created and released a very first and standard database for BLPRS."}, "authors": ["M M Shaifur Rahman", "Mst Shamima Nasrin", "Moin Mostakim", "Md Zahangir Alom"], "author_detail": {"name": "Md Zahangir Alom"}, "author": "Md Zahangir Alom", "arxiv_comment": "6 pages,10 figures", "links": [{"href": "http://arxiv.org/abs/1809.00905v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1809.00905v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1809.00905v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1809.00905v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1911.07613v1", "guidislink": true, "updated": "2019-11-15T08:22:33Z", "updated_parsed": [2019, 11, 15, 8, 22, 33, 4, 319, 0], "published": "2019-11-15T08:22:33Z", "published_parsed": [2019, 11, 15, 8, 22, 33, 4, 319, 0], "title": "A Subword Level Language Model for Bangla Language", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Subword Level Language Model for Bangla Language"}, "summary": "Language models are at the core of natural language processing. The ability\nto represent natural language gives rise to its applications in numerous NLP\ntasks including text classification, summarization, and translation. Research\nin this area is very limited in Bangla due to the scarcity of resources, except\nfor some count-based models and very recent neural language models being\nproposed, which are all based on words and limited in practical tasks due to\ntheir high perplexity. This paper attempts to approach this issue of perplexity\nand proposes a subword level neural language model with the AWD-LSTM\narchitecture and various other techniques suitable for training in Bangla\nlanguage. The model is trained on a corpus of Bangla newspaper articles of an\nappreciable size consisting of more than 28.5 million word tokens. The\nperformance comparison with various other models depicts the significant\nreduction in perplexity the proposed model provides, reaching as low as 39.84,\nin just 20 epochs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Language models are at the core of natural language processing. The ability\nto represent natural language gives rise to its applications in numerous NLP\ntasks including text classification, summarization, and translation. Research\nin this area is very limited in Bangla due to the scarcity of resources, except\nfor some count-based models and very recent neural language models being\nproposed, which are all based on words and limited in practical tasks due to\ntheir high perplexity. This paper attempts to approach this issue of perplexity\nand proposes a subword level neural language model with the AWD-LSTM\narchitecture and various other techniques suitable for training in Bangla\nlanguage. The model is trained on a corpus of Bangla newspaper articles of an\nappreciable size consisting of more than 28.5 million word tokens. The\nperformance comparison with various other models depicts the significant\nreduction in perplexity the proposed model provides, reaching as low as 39.84,\nin just 20 epochs."}, "authors": ["Aisha Khatun", "Anisur Rahman", "Hemayet Ahmed Chowdhury", "Md. Saiful Islam", "Ayesha Tasnim"], "author_detail": {"name": "Ayesha Tasnim"}, "author": "Ayesha Tasnim", "arxiv_comment": "12 pages, Conference Paper", "links": [{"href": "http://arxiv.org/abs/1911.07613v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1911.07613v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1911.07613v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1911.07613v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2005.14627v1", "guidislink": true, "updated": "2020-05-29T15:38:54Z", "updated_parsed": [2020, 5, 29, 15, 38, 54, 4, 150, 0], "published": "2020-05-29T15:38:54Z", "published_parsed": [2020, 5, 29, 15, 38, 54, 4, 150, 0], "title": "Detection of Bangla Fake News using MNB and SVM Classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Detection of Bangla Fake News using MNB and SVM Classifier"}, "summary": "Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%."}, "authors": ["Md Gulzar Hussain", "Md Rashidul Hasan", "Mahmuda Rahman", "Joy Protim", "Sakib Al Hasan"], "author_detail": {"name": "Sakib Al Hasan"}, "author": "Sakib Al Hasan", "links": [{"href": "http://arxiv.org/abs/2005.14627v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2005.14627v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2005.14627v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2005.14627v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.09872v3", "guidislink": true, "updated": "2018-02-10T18:40:54Z", "updated_parsed": [2018, 2, 10, 18, 40, 54, 5, 41, 0], "published": "2017-12-28T14:31:56Z", "published_parsed": [2017, 12, 28, 14, 31, 56, 3, 362, 0], "title": "Handwritten Bangla Character Recognition Using The State-of-Art Deep\n  Convolutional Neural Networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Character Recognition Using The State-of-Art Deep\n  Convolutional Neural Networks"}, "summary": "In spite of advances in object recognition technology, Handwritten Bangla\nCharacter Recognition (HBCR) remains largely unsolved due to the presence of\nmany ambiguous handwritten characters and excessively cursive Bangla\nhandwritings. Even the best existing recognizers do not lead to satisfactory\nperformance for practical applications related to Bangla character recognition\nand have much lower performance than those developed for English alpha-numeric\ncharacters. To improve the performance of HBCR, we herein present the\napplication of the state-of-the-art Deep Convolutional Neural Networks (DCNN)\nincluding VGG Network, All Convolution Network (All-Conv Net), Network in\nNetwork (NiN), Residual Network, FractalNet, and DenseNet for HBCR. The deep\nlearning approaches have the advantage of extracting and using feature\ninformation, improving the recognition of 2D shapes with a high degree of\ninvariance to translation, scaling and other distortions. We systematically\nevaluated the performance of DCNN models on publicly available Bangla\nhandwritten character dataset called CMATERdb and achieved the superior\nrecognition accuracy when using DCNN models. This improvement would help in\nbuilding an automatic HBCR system for practical applications.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In spite of advances in object recognition technology, Handwritten Bangla\nCharacter Recognition (HBCR) remains largely unsolved due to the presence of\nmany ambiguous handwritten characters and excessively cursive Bangla\nhandwritings. Even the best existing recognizers do not lead to satisfactory\nperformance for practical applications related to Bangla character recognition\nand have much lower performance than those developed for English alpha-numeric\ncharacters. To improve the performance of HBCR, we herein present the\napplication of the state-of-the-art Deep Convolutional Neural Networks (DCNN)\nincluding VGG Network, All Convolution Network (All-Conv Net), Network in\nNetwork (NiN), Residual Network, FractalNet, and DenseNet for HBCR. The deep\nlearning approaches have the advantage of extracting and using feature\ninformation, improving the recognition of 2D shapes with a high degree of\ninvariance to translation, scaling and other distortions. We systematically\nevaluated the performance of DCNN models on publicly available Bangla\nhandwritten character dataset called CMATERdb and achieved the superior\nrecognition accuracy when using DCNN models. This improvement would help in\nbuilding an automatic HBCR system for practical applications."}, "authors": ["Md Zahangir Alom", "Peheding Sidike", "Mahmudul Hasan", "Tark M. Taha", "Vijayan K. Asari"], "author_detail": {"name": "Vijayan K. Asari"}, "author": "Vijayan K. Asari", "arxiv_comment": "12 pages,22 figures, 5 tables. arXiv admin note: text overlap with\n  arXiv:1705.02680", "links": [{"href": "http://arxiv.org/abs/1712.09872v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.09872v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.09872v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.09872v3", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2101.00204v1", "guidislink": true, "updated": "2021-01-01T09:28:45Z", "updated_parsed": [2021, 1, 1, 9, 28, 45, 4, 1, 0], "published": "2021-01-01T09:28:45Z", "published_parsed": [2021, 1, 1, 9, 28, 45, 4, 1, 0], "title": "BanglaBERT: Combating Embedding Barrier for Low-Resource Language\n  Understanding", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaBERT: Combating Embedding Barrier for Low-Resource Language\n  Understanding"}, "summary": "Pre-training language models on large volume of data with self-supervised\nobjectives has become a standard practice in natural language processing.\nHowever, most such state-of-the-art models are available in only English and\nother resource-rich languages. Even in multilingual models, which are trained\non hundreds of languages, low-resource ones still remain underrepresented.\nBangla, the seventh most widely spoken language in the world, is still low in\nterms of resources. Few downstream task datasets for language understanding in\nBangla are publicly available, and there is a clear shortage of good quality\ndata for pre-training. In this work, we build a Bangla natural language\nunderstanding model pre-trained on 18.6 GB data we crawled from top Bangla\nsites on the internet. We introduce a new downstream task dataset and benchmark\non four tasks on sentence classification, document classification, natural\nlanguage understanding, and sequence tagging. Our model outperforms\nmultilingual baselines and previous state-of-the-art results by 1-6%. In the\nprocess, we identify a major shortcoming of multilingual models that hurt\nperformance for low-resource languages that don't share writing scripts with\nany high resource one, which we name the `Embedding Barrier'. We perform\nextensive experiments to study this barrier. We release all our datasets and\npre-trained models to aid future NLP research on Bangla and other low-resource\nlanguages. Our code and data are available at\nhttps://github.com/csebuetnlp/banglabert.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Pre-training language models on large volume of data with self-supervised\nobjectives has become a standard practice in natural language processing.\nHowever, most such state-of-the-art models are available in only English and\nother resource-rich languages. Even in multilingual models, which are trained\non hundreds of languages, low-resource ones still remain underrepresented.\nBangla, the seventh most widely spoken language in the world, is still low in\nterms of resources. Few downstream task datasets for language understanding in\nBangla are publicly available, and there is a clear shortage of good quality\ndata for pre-training. In this work, we build a Bangla natural language\nunderstanding model pre-trained on 18.6 GB data we crawled from top Bangla\nsites on the internet. We introduce a new downstream task dataset and benchmark\non four tasks on sentence classification, document classification, natural\nlanguage understanding, and sequence tagging. Our model outperforms\nmultilingual baselines and previous state-of-the-art results by 1-6%. In the\nprocess, we identify a major shortcoming of multilingual models that hurt\nperformance for low-resource languages that don't share writing scripts with\nany high resource one, which we name the `Embedding Barrier'. We perform\nextensive experiments to study this barrier. We release all our datasets and\npre-trained models to aid future NLP research on Bangla and other low-resource\nlanguages. Our code and data are available at\nhttps://github.com/csebuetnlp/banglabert."}, "authors": ["Abhik Bhattacharjee", "Tahmid Hasan", "Kazi Samin", "M. Sohel Rahman", "Anindya Iqbal", "Rifat Shahriyar"], "author_detail": {"name": "Rifat Shahriyar"}, "author": "Rifat Shahriyar", "links": [{"href": "http://arxiv.org/abs/2101.00204v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2101.00204v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2101.00204v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2101.00204v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.10106v1", "guidislink": true, "updated": "2020-11-19T21:06:28Z", "updated_parsed": [2020, 11, 19, 21, 6, 28, 3, 324, 0], "published": "2020-11-19T21:06:28Z", "published_parsed": [2020, 11, 19, 21, 6, 28, 3, 324, 0], "title": "Sentiment Classification in Bangla Textual Content: A Comparative Study", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Classification in Bangla Textual Content: A Comparative Study"}, "summary": "Sentiment analysis has been widely used to understand our views on social and\npolitical agendas or user experiences over a product. It is one of the cores\nand well-researched areas in NLP. However, for low-resource languages, like\nBangla, one of the prominent challenge is the lack of resources. Another\nimportant limitation, in the current literature for Bangla, is the absence of\ncomparable results due to the lack of a well-defined train/test split. In this\nstudy, we explore several publicly available sentiment labeled datasets and\ndesigned classifiers using both classical and deep learning algorithms. In our\nstudy, the classical algorithms include SVM and Random Forest, and deep\nlearning algorithms include CNN, FastText, and transformer-based models. We\ncompare these models in terms of model performance and time-resource\ncomplexity. Our finding suggests transformer-based models, which have not been\nexplored earlier for Bangla, outperform all other models. Furthermore, we\ncreated a weighted list of lexicon content based on the valence score per\nclass. We then analyzed the content for high significance entries per class, in\nthe datasets. For reproducibility, we make publicly available data splits and\nthe ranked lexicon list. The presented results can be used for future studies\nas a benchmark.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment analysis has been widely used to understand our views on social and\npolitical agendas or user experiences over a product. It is one of the cores\nand well-researched areas in NLP. However, for low-resource languages, like\nBangla, one of the prominent challenge is the lack of resources. Another\nimportant limitation, in the current literature for Bangla, is the absence of\ncomparable results due to the lack of a well-defined train/test split. In this\nstudy, we explore several publicly available sentiment labeled datasets and\ndesigned classifiers using both classical and deep learning algorithms. In our\nstudy, the classical algorithms include SVM and Random Forest, and deep\nlearning algorithms include CNN, FastText, and transformer-based models. We\ncompare these models in terms of model performance and time-resource\ncomplexity. Our finding suggests transformer-based models, which have not been\nexplored earlier for Bangla, outperform all other models. Furthermore, we\ncreated a weighted list of lexicon content based on the valence score per\nclass. We then analyzed the content for high significance entries per class, in\nthe datasets. For reproducibility, we make publicly available data splits and\nthe ranked lexicon list. The presented results can be used for future studies\nas a benchmark."}, "authors": ["Md. Arid Hasan", "Jannatul Tajrin", "Shammur Absar Chowdhury", "Firoj Alam"], "author_detail": {"name": "Firoj Alam"}, "author": "Firoj Alam", "arxiv_comment": "Accepted at ICCIT-2020", "links": [{"href": "http://arxiv.org/abs/2011.10106v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.10106v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T50", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.10106v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.10106v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1002.4007v1", "guidislink": true, "updated": "2010-02-21T19:48:16Z", "updated_parsed": [2010, 2, 21, 19, 48, 16, 6, 52, 0], "published": "2010-02-21T19:48:16Z", "published_parsed": [2010, 2, 21, 19, 48, 16, 6, 52, 0], "title": "Word level Script Identification from Bangla and Devanagri Handwritten\n  Texts mixed with Roman Script", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word level Script Identification from Bangla and Devanagri Handwritten\n  Texts mixed with Roman Script"}, "summary": "India is a multi-lingual country where Roman script is often used alongside\ndifferent Indic scripts in a text document. To develop a script specific\nhandwritten Optical Character Recognition (OCR) system, it is therefore\nnecessary to identify the scripts of handwritten text correctly. In this paper,\nwe present a system, which automatically separates the scripts of handwritten\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\nIn this script separation technique, we first, extract the text lines and words\nfrom document pages using a script independent Neighboring Component Analysis\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\nclassifier for script separation, trained with 8 different wordlevel holistic\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\nOn respective independent text samples, word-level script identification\naccuracies of 99.29% and 98.43% are achieved.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "India is a multi-lingual country where Roman script is often used alongside\ndifferent Indic scripts in a text document. To develop a script specific\nhandwritten Optical Character Recognition (OCR) system, it is therefore\nnecessary to identify the scripts of handwritten text correctly. In this paper,\nwe present a system, which automatically separates the scripts of handwritten\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\nIn this script separation technique, we first, extract the text lines and words\nfrom document pages using a script independent Neighboring Component Analysis\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\nclassifier for script separation, trained with 8 different wordlevel holistic\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\nOn respective independent text samples, word-level script identification\naccuracies of 99.29% and 98.43% are achieved."}, "authors": ["Ram Sarkar", "Nibaran Das", "Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1002.4007v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.4007v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.4007v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1002.4007v1", "arxiv_comment": null, "journal_reference": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null}
{"id": "http://arxiv.org/abs/1206.0381v1", "guidislink": true, "updated": "2012-06-02T13:23:18Z", "updated_parsed": [2012, 6, 2, 13, 23, 18, 5, 154, 0], "published": "2012-06-02T13:23:18Z", "published_parsed": [2012, 6, 2, 13, 23, 18, 5, 154, 0], "title": "UNL Based Bangla Natural Text Conversion - Predicate Preserving Parser\n  Approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "UNL Based Bangla Natural Text Conversion - Predicate Preserving Parser\n  Approach"}, "summary": "Universal Networking Language (UNL) is a declarative formal language that is\nused to represent semantic data extracted from natural language texts. This\npaper presents a novel approach to converting Bangla natural language text into\nUNL using a method known as Predicate Preserving Parser (PPP) technique. PPP\nperforms morphological, syntactic and semantic, and lexical analysis of text\nsynchronously. This analysis produces a semantic-net like structure represented\nusing UNL. We demonstrate how Bangla texts are analyzed following the PPP\ntechnique to produce UNL documents which can then be translated into any other\nsuitable natural language facilitating the opportunity to develop a universal\nlanguage translation method via UNL.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Universal Networking Language (UNL) is a declarative formal language that is\nused to represent semantic data extracted from natural language texts. This\npaper presents a novel approach to converting Bangla natural language text into\nUNL using a method known as Predicate Preserving Parser (PPP) technique. PPP\nperforms morphological, syntactic and semantic, and lexical analysis of text\nsynchronously. This analysis produces a semantic-net like structure represented\nusing UNL. We demonstrate how Bangla texts are analyzed following the PPP\ntechnique to produce UNL documents which can then be translated into any other\nsuitable natural language facilitating the opportunity to develop a universal\nlanguage translation method via UNL."}, "authors": ["Md. Nawab Yousuf Ali", "Shamim Ripon", "Shaikh Muhammad Allayear"], "author_detail": {"name": "Shaikh Muhammad Allayear"}, "author": "Shaikh Muhammad Allayear", "arxiv_comment": "7 pages, International Journal of Computer Science Issues (IJCSI),\n  Volume 9, Issue 3 May 2012", "links": [{"href": "http://arxiv.org/abs/1206.0381v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1206.0381v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1206.0381v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1206.0381v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1310.1426v1", "guidislink": true, "updated": "2013-10-05T00:39:02Z", "updated_parsed": [2013, 10, 5, 0, 39, 2, 5, 278, 0], "published": "2013-10-05T00:39:02Z", "published_parsed": [2013, 10, 5, 0, 39, 2, 5, 278, 0], "title": "Local Feature or Mel Frequency Cepstral Coefficients - Which One is\n  Better for MLN-Based Bangla Speech Recognition?", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Local Feature or Mel Frequency Cepstral Coefficients - Which One is\n  Better for MLN-Based Bangla Speech Recognition?"}, "summary": "This paper discusses the dominancy of local features (LFs), as input to the\nmultilayer neural network (MLN), extracted from a Bangla input speech over mel\nfrequency cepstral coefficients (MFCCs). Here, LF-based method comprises three\nstages: (i) LF extraction from input speech, (ii) phoneme probabilities\nextraction using MLN from LF and (iii) the hidden Markov model (HMM) based\nclassifier to obtain more accurate phoneme strings. In the experiments on\nBangla speech corpus prepared by us, it is observed that the LFbased automatic\nspeech recognition (ASR) system provides higher phoneme correct rate than the\nMFCC-based system. Moreover, the proposed system requires fewer mixture\ncomponents in the HMMs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper discusses the dominancy of local features (LFs), as input to the\nmultilayer neural network (MLN), extracted from a Bangla input speech over mel\nfrequency cepstral coefficients (MFCCs). Here, LF-based method comprises three\nstages: (i) LF extraction from input speech, (ii) phoneme probabilities\nextraction using MLN from LF and (iii) the hidden Markov model (HMM) based\nclassifier to obtain more accurate phoneme strings. In the experiments on\nBangla speech corpus prepared by us, it is observed that the LFbased automatic\nspeech recognition (ASR) system provides higher phoneme correct rate than the\nMFCC-based system. Moreover, the proposed system requires fewer mixture\ncomponents in the HMMs."}, "authors": ["Foyzul Hassan", "Mohammed Rokibul Alam Kotwal", "Md. Mostafizur Rahman", "Mohammad Nasiruddin", "Md. Abdul Latif", "Mohammad Nurul Huda"], "author_detail": {"name": "Mohammad Nurul Huda"}, "author": "Mohammad Nurul Huda", "arxiv_comment": "9 pages Advances in Computing and Communications (ACC) 2011", "links": [{"href": "http://arxiv.org/abs/1310.1426v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1310.1426v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T50", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1310.1426v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1310.1426v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1911.11062v1", "guidislink": true, "updated": "2019-11-19T20:37:03Z", "updated_parsed": [2019, 11, 19, 20, 37, 3, 1, 323, 0], "published": "2019-11-19T20:37:03Z", "published_parsed": [2019, 11, 19, 20, 37, 3, 1, 323, 0], "title": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model"}, "summary": "Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%."}, "authors": ["Arnab Sen Sharma", "Maruf Ahmed Mridul", "Md Saiful Islam"], "author_detail": {"name": "Md Saiful Islam"}, "author": "Md Saiful Islam", "arxiv_comment": "5 pages, Conference paper", "links": [{"href": "http://arxiv.org/abs/1911.11062v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1911.11062v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1911.11062v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1911.11062v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2001.05316v1", "guidislink": true, "updated": "2020-01-11T14:54:04Z", "updated_parsed": [2020, 1, 11, 14, 54, 4, 5, 11, 0], "published": "2020-01-11T14:54:04Z", "published_parsed": [2020, 1, 11, 14, 54, 4, 5, 11, 0], "title": "Authorship Attribution in Bangla literature using Character-level CNN", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Authorship Attribution in Bangla literature using Character-level CNN"}, "summary": "Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results."}, "authors": ["Aisha Khatun", "Anisur Rahman", "Md. Saiful Islam", "Marium-E-Jannat"], "author_detail": {"name": "Marium-E-Jannat"}, "author": "Marium-E-Jannat", "arxiv_comment": "5 pages", "links": [{"href": "http://arxiv.org/abs/2001.05316v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2001.05316v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2001.05316v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2001.05316v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2004.08789v1", "guidislink": true, "updated": "2020-04-19T07:42:22Z", "updated_parsed": [2020, 4, 19, 7, 42, 22, 6, 110, 0], "published": "2020-04-19T07:42:22Z", "published_parsed": [2020, 4, 19, 7, 42, 22, 6, 110, 0], "title": "BanFakeNews: A Dataset for Detecting Fake News in Bangla", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanFakeNews: A Dataset for Detecting Fake News in Bangla"}, "summary": "Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages."}, "authors": ["Md Zobaer Hossain", "Md Ashraful Rahman", "Md Saiful Islam", "Sudipta Kar"], "author_detail": {"name": "Sudipta Kar"}, "author": "Sudipta Kar", "arxiv_comment": "LREC 2020", "links": [{"href": "http://arxiv.org/abs/2004.08789v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.08789v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.08789v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.08789v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2010.13404v2", "guidislink": true, "updated": "2021-01-12T13:51:27Z", "updated_parsed": [2021, 1, 12, 13, 51, 27, 1, 12, 0], "published": "2020-10-26T08:00:48Z", "published_parsed": [2020, 10, 26, 8, 0, 48, 0, 300, 0], "title": "Robust and Consistent Estimation of Word Embedding for Bangla Language\n  by fine-tuning Word2Vec Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Robust and Consistent Estimation of Word Embedding for Bangla Language\n  by fine-tuning Word2Vec Model"}, "summary": "In recent times, data is growing rapidly in every domain such as news, social\nmedia, banking, education, etc. Due to the excessiveness of data, there is a\nneed for an automatic keyword extractor that can help to summarize the data.\nKeyword extraction is a text analysis technique that consists of automatically\nextracting the most important words and expressions in a text. It helps\nsummarize the content of a text and recognize the main topics which are being\ndiscussed. Earlier works regarding this topic have been done but no significant\nwork was done for the Bangla language. So, we tried to achieve the same things\nwhich could be done with other languages in the Bangla language.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In recent times, data is growing rapidly in every domain such as news, social\nmedia, banking, education, etc. Due to the excessiveness of data, there is a\nneed for an automatic keyword extractor that can help to summarize the data.\nKeyword extraction is a text analysis technique that consists of automatically\nextracting the most important words and expressions in a text. It helps\nsummarize the content of a text and recognize the main topics which are being\ndiscussed. Earlier works regarding this topic have been done but no significant\nwork was done for the Bangla language. So, we tried to achieve the same things\nwhich could be done with other languages in the Bangla language."}, "authors": ["Rifat Rahman"], "author_detail": {"name": "Rifat Rahman"}, "author": "Rifat Rahman", "arxiv_comment": "I have implemented some approaches that are wrong. Now I am fixing\n  these issues. The methodology used my previous script may be harmful for\n  relevant researchers", "links": [{"href": "http://arxiv.org/abs/2010.13404v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.13404v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.13404v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.13404v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.04446v1", "guidislink": true, "updated": "2020-11-09T14:12:07Z", "updated_parsed": [2020, 11, 9, 14, 12, 7, 0, 314, 0], "published": "2020-11-09T14:12:07Z", "published_parsed": [2020, 11, 9, 14, 12, 7, 0, 314, 0], "title": "Bangla Text Classification using Transformers", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Text Classification using Transformers"}, "summary": "Text classification has been one of the earliest problems in NLP. Over time\nthe scope of application areas has broadened and the difficulty of dealing with\nnew areas (e.g., noisy social media content) has increased. The problem-solving\nstrategy switched from classical machine learning to deep learning algorithms.\nOne of the recent deep neural network architecture is the Transformer. Models\ndesigned with this type of network and its variants recently showed their\nsuccess in many downstream natural language processing tasks, especially for\nresource-rich languages, e.g., English. However, these models have not been\nexplored fully for Bangla text classification tasks. In this work, we fine-tune\nmultilingual transformer models for Bangla text classification tasks in\ndifferent domains, including sentiment analysis, emotion detection, news\ncategorization, and authorship attribution. We obtain the state of the art\nresults on six benchmark datasets, improving upon the previous results by 5-29%\naccuracy across different tasks.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Text classification has been one of the earliest problems in NLP. Over time\nthe scope of application areas has broadened and the difficulty of dealing with\nnew areas (e.g., noisy social media content) has increased. The problem-solving\nstrategy switched from classical machine learning to deep learning algorithms.\nOne of the recent deep neural network architecture is the Transformer. Models\ndesigned with this type of network and its variants recently showed their\nsuccess in many downstream natural language processing tasks, especially for\nresource-rich languages, e.g., English. However, these models have not been\nexplored fully for Bangla text classification tasks. In this work, we fine-tune\nmultilingual transformer models for Bangla text classification tasks in\ndifferent domains, including sentiment analysis, emotion detection, news\ncategorization, and authorship attribution. We obtain the state of the art\nresults on six benchmark datasets, improving upon the previous results by 5-29%\naccuracy across different tasks."}, "authors": ["Tanvirul Alam", "Akib Khan", "Firoj Alam"], "author_detail": {"name": "Firoj Alam"}, "author": "Firoj Alam", "links": [{"href": "http://arxiv.org/abs/2011.04446v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.04446v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.04446v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.04446v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.07499v2", "guidislink": true, "updated": "2020-12-08T09:30:02Z", "updated_parsed": [2020, 12, 8, 9, 30, 2, 1, 343, 0], "published": "2020-11-15T11:08:53Z", "published_parsed": [2020, 11, 15, 11, 8, 53, 6, 320, 0], "title": "BanglaWriting: A multi-purpose offline Bangla handwriting dataset", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaWriting: A multi-purpose offline Bangla handwriting dataset"}, "summary": "This article presents a Bangla handwriting dataset named BanglaWriting that\ncontains single-page handwritings of 260 individuals of different personalities\nand ages. Each page includes bounding-boxes that bounds each word, along with\nthe unicode representation of the writing. This dataset contains 21,234 words\nand 32,787 characters in total. Moreover, this dataset includes 5,470 unique\nwords of Bangla vocabulary. Apart from the usual words, the dataset comprises\n261 comprehensible overwriting and 450 handwritten strikes and mistakes. All of\nthe bounding-boxes and word labels are manually-generated. The dataset can be\nused for complex optical character/word recognition, writer identification,\nhandwritten word segmentation, and word generation. Furthermore, this dataset\nis suitable for extracting age-based and gender-based variation of handwriting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This article presents a Bangla handwriting dataset named BanglaWriting that\ncontains single-page handwritings of 260 individuals of different personalities\nand ages. Each page includes bounding-boxes that bounds each word, along with\nthe unicode representation of the writing. This dataset contains 21,234 words\nand 32,787 characters in total. Moreover, this dataset includes 5,470 unique\nwords of Bangla vocabulary. Apart from the usual words, the dataset comprises\n261 comprehensible overwriting and 450 handwritten strikes and mistakes. All of\nthe bounding-boxes and word labels are manually-generated. The dataset can be\nused for complex optical character/word recognition, writer identification,\nhandwritten word segmentation, and word generation. Furthermore, this dataset\nis suitable for extracting age-based and gender-based variation of handwriting."}, "authors": ["M. F. Mridha", "Abu Quwsar Ohi", "M. Ameer Ali", "Mazedul Islam Emon", "Muhammad Mohsin Kabir"], "author_detail": {"name": "Muhammad Mohsin Kabir"}, "author": "Muhammad Mohsin Kabir", "arxiv_comment": "Accepted in journal Data in Brief. The dataset is available on\n  https://data.mendeley.com/datasets/r43wkvdk4w/", "links": [{"href": "http://arxiv.org/abs/2011.07499v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.07499v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.07499v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.07499v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1901.05613v1", "guidislink": true, "updated": "2019-01-17T04:27:34Z", "updated_parsed": [2019, 1, 17, 4, 27, 34, 3, 17, 0], "published": "2019-01-17T04:27:34Z", "published_parsed": [2019, 1, 17, 4, 27, 34, 3, 17, 0], "title": "Hand Sign to Bangla Speech: A Deep Learning in Vision based system for\n  Recognizing Hand Sign Digits and Generating Bangla Speech", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Hand Sign to Bangla Speech: A Deep Learning in Vision based system for\n  Recognizing Hand Sign Digits and Generating Bangla Speech"}, "summary": "Recent advancements in the field of computer vision with the help of deep\nneural networks have led us to explore and develop many existing challenges\nthat were once unattended due to the lack of necessary technologies. Hand\nSign/Gesture Recognition is one of the significant areas where the deep neural\nnetwork is making a substantial impact. In the last few years, a large number\nof researches has been conducted to recognize hand signs and hand gestures,\nwhich we aim to extend to our mother-tongue, Bangla (also known as Bengali).\nThe primary goal of our work is to make an automated tool to aid the people who\nare unable to speak. We developed a system that automatically detects hand sign\nbased digits and speaks out the result in Bangla language. According to the\nreport of the World Health Organization (WHO), 15% of people in the world live\nwith some kind of disabilities. Among them, individuals with communication\nimpairment such as speech disabilities experience substantial barrier in social\ninteraction. The proposed system can be invaluable to mitigate such a barrier.\nThe core of the system is built with a deep learning model which is based on\nconvolutional neural networks (CNN). The model classifies hand sign based\ndigits with 92% accuracy over validation data which ensures it a highly\ntrustworthy system. Upon classification of the digits, the resulting output is\nfed to the text to speech engine and the translator unit eventually which\ngenerates audio output in Bangla language. A web application to demonstrate our\ntool is available at http://bit.ly/signdigits2banglaspeech.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recent advancements in the field of computer vision with the help of deep\nneural networks have led us to explore and develop many existing challenges\nthat were once unattended due to the lack of necessary technologies. Hand\nSign/Gesture Recognition is one of the significant areas where the deep neural\nnetwork is making a substantial impact. In the last few years, a large number\nof researches has been conducted to recognize hand signs and hand gestures,\nwhich we aim to extend to our mother-tongue, Bangla (also known as Bengali).\nThe primary goal of our work is to make an automated tool to aid the people who\nare unable to speak. We developed a system that automatically detects hand sign\nbased digits and speaks out the result in Bangla language. According to the\nreport of the World Health Organization (WHO), 15% of people in the world live\nwith some kind of disabilities. Among them, individuals with communication\nimpairment such as speech disabilities experience substantial barrier in social\ninteraction. The proposed system can be invaluable to mitigate such a barrier.\nThe core of the system is built with a deep learning model which is based on\nconvolutional neural networks (CNN). The model classifies hand sign based\ndigits with 92% accuracy over validation data which ensures it a highly\ntrustworthy system. Upon classification of the digits, the resulting output is\nfed to the text to speech engine and the translator unit eventually which\ngenerates audio output in Bangla language. A web application to demonstrate our\ntool is available at http://bit.ly/signdigits2banglaspeech."}, "authors": ["Shahjalal Ahmed", "Md. Rafiqul Islam", "Jahid Hassan", "Minhaz Uddin Ahmed", "Bilkis Jamal Ferdosi", "Sanjay Saha", "Md. Shopon"], "author_detail": {"name": "Md. Shopon"}, "author": "Md. Shopon", "links": [{"href": "http://arxiv.org/abs/1901.05613v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1901.05613v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1901.05613v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1901.05613v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.08706v1", "guidislink": true, "updated": "2017-01-27T12:54:52Z", "updated_parsed": [2017, 1, 27, 12, 54, 52, 4, 27, 0], "published": "2017-01-27T12:54:52Z", "published_parsed": [2017, 1, 27, 12, 54, 52, 4, 27, 0], "title": "Document Decomposition of Bangla Printed Text", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Document Decomposition of Bangla Printed Text"}, "summary": "Today all kind of information is getting digitized and along with all this\ndigitization, the huge archive of various kinds of documents is being digitized\ntoo. We know that, Optical Character Recognition is the method through which,\nnewspapers and other paper documents convert into digital resources. But, it is\na fact that this method works on texts only. As a result, if we try to process\nany document which contains non-textual zones, then we will get garbage texts\nas output. That is why; in order to digitize documents properly they should be\nprepossessed carefully. And while preprocessing, segmenting document in\ndifferent regions according to the category properly is most important. But,\nthe Optical Character Recognition processes available for Bangla language have\nno such algorithm that can categorize a newspaper/book page fully. So we worked\nto decompose a document into its several parts like headlines, sub headlines,\ncolumns, images etc. And if the input is skewed and rotated, then the input was\nalso deskewed and de-rotated. To decompose any Bangla document we found out the\nedges of the input image. Then we find out the horizontal and vertical area of\nevery pixel where it lies in. Later on the input image was cut according to\nthese areas. Then we pick each and every sub image and found out their\nheight-width ratio, line height. Then according to these values the sub images\nwere categorized. To deskew the image we found out the skew angle and de skewed\nthe image according to this angle. To de-rotate the image we used the line\nheight, matra line, pixel ratio of matra line.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Today all kind of information is getting digitized and along with all this\ndigitization, the huge archive of various kinds of documents is being digitized\ntoo. We know that, Optical Character Recognition is the method through which,\nnewspapers and other paper documents convert into digital resources. But, it is\na fact that this method works on texts only. As a result, if we try to process\nany document which contains non-textual zones, then we will get garbage texts\nas output. That is why; in order to digitize documents properly they should be\nprepossessed carefully. And while preprocessing, segmenting document in\ndifferent regions according to the category properly is most important. But,\nthe Optical Character Recognition processes available for Bangla language have\nno such algorithm that can categorize a newspaper/book page fully. So we worked\nto decompose a document into its several parts like headlines, sub headlines,\ncolumns, images etc. And if the input is skewed and rotated, then the input was\nalso deskewed and de-rotated. To decompose any Bangla document we found out the\nedges of the input image. Then we find out the horizontal and vertical area of\nevery pixel where it lies in. Later on the input image was cut according to\nthese areas. Then we pick each and every sub image and found out their\nheight-width ratio, line height. Then according to these values the sub images\nwere categorized. To deskew the image we found out the skew angle and de skewed\nthe image according to this angle. To de-rotate the image we used the line\nheight, matra line, pixel ratio of matra line."}, "authors": ["Md. Fahad Hasan", "Tasmin Afroz", "Sabir Ismail", "Md. Saiful Islam"], "author_detail": {"name": "Md. Saiful Islam"}, "author": "Md. Saiful Islam", "arxiv_comment": "6 pages", "links": [{"href": "http://arxiv.org/abs/1701.08706v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08706v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08706v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08706v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1707.08398v1", "guidislink": true, "updated": "2017-07-26T12:03:39Z", "updated_parsed": [2017, 7, 26, 12, 3, 39, 2, 207, 0], "published": "2017-07-26T12:03:39Z", "published_parsed": [2017, 7, 26, 12, 3, 39, 2, 207, 0], "title": "A Harmony Search Based Wrapper Feature Selection Method for Holistic\n  Bangla word Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Harmony Search Based Wrapper Feature Selection Method for Holistic\n  Bangla word Recognition"}, "summary": "A lot of search approaches have been explored for the selection of features\nin pattern classification domain in order to discover significant subset of the\nfeatures which produces better accuracy. In this paper, we introduced a Harmony\nSearch (HS) algorithm based feature selection method for feature dimensionality\nreduction in handwritten Bangla word recognition problem. This algorithm has\nbeen implemented to reduce the feature dimensionality of a technique described\nin one of our previous papers by S. Bhowmik et al.[1]. In the said paper, a set\nof 65 elliptical features were computed for handwritten Bangla word recognition\npurpose and a recognition accuracy of 81.37% was achieved using Multi Layer\nPerceptron (MLP) classifier. In the present work, a subset containing 48\nfeatures (approximately 75% of said feature vector) has been selected by HS\nbased wrapper feature selection method which produces an accuracy rate of\n90.29%. Reasonable outcomes also validates that the introduced algorithm\nutilizes optimal number of features while showing higher classification\naccuracies when compared to two standard evolutionary algorithms like Genetic\nAlgorithm (GA), Particle Swarm Optimization (PSO) and statistical feature\ndimensionality reduction technique like Principal Component Analysis (PCA).\nThis confirms the suitability of HS algorithm to the holistic handwritten word\nrecognition problem.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A lot of search approaches have been explored for the selection of features\nin pattern classification domain in order to discover significant subset of the\nfeatures which produces better accuracy. In this paper, we introduced a Harmony\nSearch (HS) algorithm based feature selection method for feature dimensionality\nreduction in handwritten Bangla word recognition problem. This algorithm has\nbeen implemented to reduce the feature dimensionality of a technique described\nin one of our previous papers by S. Bhowmik et al.[1]. In the said paper, a set\nof 65 elliptical features were computed for handwritten Bangla word recognition\npurpose and a recognition accuracy of 81.37% was achieved using Multi Layer\nPerceptron (MLP) classifier. In the present work, a subset containing 48\nfeatures (approximately 75% of said feature vector) has been selected by HS\nbased wrapper feature selection method which produces an accuracy rate of\n90.29%. Reasonable outcomes also validates that the introduced algorithm\nutilizes optimal number of features while showing higher classification\naccuracies when compared to two standard evolutionary algorithms like Genetic\nAlgorithm (GA), Particle Swarm Optimization (PSO) and statistical feature\ndimensionality reduction technique like Principal Component Analysis (PCA).\nThis confirms the suitability of HS algorithm to the holistic handwritten word\nrecognition problem."}, "authors": ["Supratim Das", "Pawan Kumar Singh", "Showmik Bhowmik", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/1707.08398v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1707.08398v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T10", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1707.08398v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1707.08398v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1501.05497v1", "guidislink": true, "updated": "2015-01-22T13:50:25Z", "updated_parsed": [2015, 1, 22, 13, 50, 25, 3, 22, 0], "published": "2015-01-22T13:50:25Z", "published_parsed": [2015, 1, 22, 13, 50, 25, 3, 22, 0], "title": "An Improved Feature Descriptor for Recognition of Handwritten Bangla\n  Alphabet", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An Improved Feature Descriptor for Recognition of Handwritten Bangla\n  Alphabet"}, "summary": "Appropriate feature set for representation of pattern classes is one of the\nmost important aspects of handwritten character recognition. The effectiveness\nof features depends on the discriminating power of the features chosen to\nrepresent patterns of different classes. However, discriminatory features are\nnot easily measurable. Investigative experimentation is necessary for\nidentifying discriminatory features. In the present work we have identified a\nnew variation of feature set which significantly outperforms on handwritten\nBangla alphabet from the previously used feature set. 132 number of features in\nall viz. modified shadow features, octant and centroid features, distance based\nfeatures, quad tree based longest run features are used here. Using this\nfeature set the recognition performance increases sharply from the 75.05%\nobserved in our previous work [7], to 85.40% on 50 character classes with MLP\nbased classifier on the same dataset.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Appropriate feature set for representation of pattern classes is one of the\nmost important aspects of handwritten character recognition. The effectiveness\nof features depends on the discriminating power of the features chosen to\nrepresent patterns of different classes. However, discriminatory features are\nnot easily measurable. Investigative experimentation is necessary for\nidentifying discriminatory features. In the present work we have identified a\nnew variation of feature set which significantly outperforms on handwritten\nBangla alphabet from the previously used feature set. 132 number of features in\nall viz. modified shadow features, octant and centroid features, distance based\nfeatures, quad tree based longest run features are used here. Using this\nfeature set the recognition performance increases sharply from the 75.05%\nobserved in our previous work [7], to 85.40% on 50 character classes with MLP\nbased classifier on the same dataset."}, "authors": ["Nibaran Das", "Subhadip Basu", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak kumar Basu"], "author_detail": {"name": "Dipak kumar Basu"}, "author": "Dipak kumar Basu", "arxiv_comment": "In proceedings of ICSIP 2009, pp. 451 to 454, August 2009, Mysore,\n  India. arXiv admin note: substantial text overlap with arXiv:1203.0882,\n  arXiv:1002.4040, arXiv:1410.0478", "links": [{"href": "http://arxiv.org/abs/1501.05497v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1501.05497v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1501.05497v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1501.05497v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.01434v1", "guidislink": true, "updated": "2017-12-05T01:12:25Z", "updated_parsed": [2017, 12, 5, 1, 12, 25, 1, 339, 0], "published": "2017-12-05T01:12:25Z", "published_parsed": [2017, 12, 5, 1, 12, 25, 1, 339, 0], "title": "Zone-based Keyword Spotting in Bangla and Devanagari Documents", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Zone-based Keyword Spotting in Bangla and Devanagari Documents"}, "summary": "In this paper we present a word spotting system in text lines for offline\nIndic scripts such as Bangla (Bengali) and Devanagari. Recently, it was shown\nthat zone-wise recognition method improves the word recognition performance\nthan conventional full word recognition system in Indic scripts. Inspired with\nthis idea we consider the zone segmentation approach and use middle zone\ninformation to improve the traditional word spotting performance. To avoid the\nproblem of zone segmentation using heuristic approach, we propose here an HMM\nbased approach to segment the upper and lower zone components from the text\nline images. The candidate keywords are searched from a line without segmenting\ncharacters or words. Also, we propose a novel feature combining foreground and\nbackground information of text line images for keyword-spotting by character\nfiller models. A significant improvement in performance is noted by using both\nforeground and background information than their individual one. Pyramid\nHistogram of Oriented Gradient (PHOG) feature has been used in our word\nspotting framework. From the experiment, it has been noted that the proposed\nzone-segmentation based system outperforms traditional approaches of word\nspotting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper we present a word spotting system in text lines for offline\nIndic scripts such as Bangla (Bengali) and Devanagari. Recently, it was shown\nthat zone-wise recognition method improves the word recognition performance\nthan conventional full word recognition system in Indic scripts. Inspired with\nthis idea we consider the zone segmentation approach and use middle zone\ninformation to improve the traditional word spotting performance. To avoid the\nproblem of zone segmentation using heuristic approach, we propose here an HMM\nbased approach to segment the upper and lower zone components from the text\nline images. The candidate keywords are searched from a line without segmenting\ncharacters or words. Also, we propose a novel feature combining foreground and\nbackground information of text line images for keyword-spotting by character\nfiller models. A significant improvement in performance is noted by using both\nforeground and background information than their individual one. Pyramid\nHistogram of Oriented Gradient (PHOG) feature has been used in our word\nspotting framework. From the experiment, it has been noted that the proposed\nzone-segmentation based system outperforms traditional approaches of word\nspotting."}, "authors": ["Ayan Kumar Bhunia", "Partha Pratim Roy", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "arxiv_comment": "Preprint Submitted", "links": [{"href": "http://arxiv.org/abs/1712.01434v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.01434v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.01434v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.01434v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1802.00671v1", "guidislink": true, "updated": "2018-02-02T13:06:43Z", "updated_parsed": [2018, 2, 2, 13, 6, 43, 4, 33, 0], "published": "2018-02-02T13:06:43Z", "published_parsed": [2018, 2, 2, 13, 6, 43, 4, 33, 0], "title": "Handwritten Isolated Bangla Compound Character Recognition: a new\n  benchmark using a novel deep learning approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Isolated Bangla Compound Character Recognition: a new\n  benchmark using a novel deep learning approach"}, "summary": "In this work, a novel deep learning technique for the recognition of\nhandwritten Bangla isolated compound character is presented and a new benchmark\nof recognition accuracy on the CMATERdb 3.1.3.3 dataset is reported. Greedy\nlayer wise training of Deep Neural Network has helped to make significant\nstrides in various pattern recognition problems. We employ layerwise training\nto Deep Convolutional Neural Networks (DCNN) in a supervised fashion and\naugment the training process with the RMSProp algorithm to achieve faster\nconvergence. We compare results with those obtained from standard shallow\nlearning methods with predefined features, as well as standard DCNNs.\nSupervised layerwise trained DCNNs are found to outperform standard shallow\nlearning models such as Support Vector Machines as well as regular DCNNs of\nsimilar architecture by achieving error rate of 9.67% thereby setting a new\nbenchmark on the CMATERdb 3.1.3.3 with recognition accuracy of 90.33%,\nrepresenting an improvement of nearly 10%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this work, a novel deep learning technique for the recognition of\nhandwritten Bangla isolated compound character is presented and a new benchmark\nof recognition accuracy on the CMATERdb 3.1.3.3 dataset is reported. Greedy\nlayer wise training of Deep Neural Network has helped to make significant\nstrides in various pattern recognition problems. We employ layerwise training\nto Deep Convolutional Neural Networks (DCNN) in a supervised fashion and\naugment the training process with the RMSProp algorithm to achieve faster\nconvergence. We compare results with those obtained from standard shallow\nlearning methods with predefined features, as well as standard DCNNs.\nSupervised layerwise trained DCNNs are found to outperform standard shallow\nlearning models such as Support Vector Machines as well as regular DCNNs of\nsimilar architecture by achieving error rate of 9.67% thereby setting a new\nbenchmark on the CMATERdb 3.1.3.3 with recognition accuracy of 90.33%,\nrepresenting an improvement of nearly 10%."}, "authors": ["Saikat Roy", "Nibaran Das", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patrec.2017.03.004", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1802.00671v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1802.00671v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1802.00671v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1802.00671v1", "arxiv_comment": null, "journal_reference": "Pattern Recognition Letters, Elsevier, Vol. 90, Pages 15-21, 2017", "doi": "10.1016/j.patrec.2017.03.004"}
{"id": "http://arxiv.org/abs/1806.08037v1", "guidislink": true, "updated": "2018-06-21T01:30:30Z", "updated_parsed": [2018, 6, 21, 1, 30, 30, 3, 172, 0], "published": "2018-06-21T01:30:30Z", "published_parsed": [2018, 6, 21, 1, 30, 30, 3, 172, 0], "title": "Pixel-level Reconstruction and Classification for Noisy Handwritten\n  Bangla Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Pixel-level Reconstruction and Classification for Noisy Handwritten\n  Bangla Characters"}, "summary": "Classification techniques for images of handwritten characters are\nsusceptible to noise. Quadtrees can be an efficient representation for learning\nfrom sparse features. In this paper, we improve the effectiveness of\nprobabilistic quadtrees by using a pixel level classifier to extract the\ncharacter pixels and remove noise from handwritten character images. The pixel\nlevel denoiser (a deep belief network) uses the map responses obtained from a\npretrained CNN as features for reconstructing the characters eliminating noise.\nWe experimentally demonstrate the effectiveness of our approach by\nreconstructing and classifying a noisy version of handwritten Bangla Numeral\nand Basic Character datasets.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Classification techniques for images of handwritten characters are\nsusceptible to noise. Quadtrees can be an efficient representation for learning\nfrom sparse features. In this paper, we improve the effectiveness of\nprobabilistic quadtrees by using a pixel level classifier to extract the\ncharacter pixels and remove noise from handwritten character images. The pixel\nlevel denoiser (a deep belief network) uses the map responses obtained from a\npretrained CNN as features for reconstructing the characters eliminating noise.\nWe experimentally demonstrate the effectiveness of our approach by\nreconstructing and classifying a noisy version of handwritten Bangla Numeral\nand Basic Character datasets."}, "authors": ["Manohar Karki", "Qun Liu", "Robert DiBiano", "Saikat Basu", "Supratik Mukhopadhyay"], "author_detail": {"name": "Supratik Mukhopadhyay"}, "author": "Supratik Mukhopadhyay", "arxiv_comment": "Paper was accepted at the 16th International Conference on Frontiers\n  in Handwriting Recognition (ICFHR 2018)", "links": [{"href": "http://arxiv.org/abs/1806.08037v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1806.08037v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1806.08037v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1806.08037v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1907.07826v1", "guidislink": true, "updated": "2019-07-18T01:00:42Z", "updated_parsed": [2019, 7, 18, 1, 0, 42, 3, 199, 0], "published": "2019-07-18T01:00:42Z", "published_parsed": [2019, 7, 18, 1, 0, 42, 3, 199, 0], "title": "Comparison of Classical Machine Learning Approaches on Bangla Textual\n  Emotion Analysis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Comparison of Classical Machine Learning Approaches on Bangla Textual\n  Emotion Analysis"}, "summary": "Detecting emotions from text is an extension of simple sentiment polarity\ndetection. Instead of considering only positive or negative sentiments,\nemotions are conveyed using more tangible manner; thus, they can be expressed\nas many shades of gray. This paper manifests the results of our experimentation\nfor fine-grained emotion analysis on Bangla text. We gathered and annotated a\ntext corpus consisting of user comments from several Facebook groups regarding\nsocio-economic and political issues, and we made efforts to extract the basic\nemotions (sadness, happiness, disgust, surprise, fear, anger) conveyed through\nthese comments. Finally, we compared the results of the five most popular\nclassical machine learning techniques namely Naive Bayes, Decision Tree,\nk-Nearest Neighbor (k-NN), Support Vector Machine (SVM) and K-Means Clustering\nwith several combinations of features. Our best model (SVM with a non-linear\nradial-basis function (RBF) kernel) achieved an overall average accuracy score\nof 52.98% and an F1 score (macro) of 0.3324", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Detecting emotions from text is an extension of simple sentiment polarity\ndetection. Instead of considering only positive or negative sentiments,\nemotions are conveyed using more tangible manner; thus, they can be expressed\nas many shades of gray. This paper manifests the results of our experimentation\nfor fine-grained emotion analysis on Bangla text. We gathered and annotated a\ntext corpus consisting of user comments from several Facebook groups regarding\nsocio-economic and political issues, and we made efforts to extract the basic\nemotions (sadness, happiness, disgust, surprise, fear, anger) conveyed through\nthese comments. Finally, we compared the results of the five most popular\nclassical machine learning techniques namely Naive Bayes, Decision Tree,\nk-Nearest Neighbor (k-NN), Support Vector Machine (SVM) and K-Means Clustering\nwith several combinations of features. Our best model (SVM with a non-linear\nradial-basis function (RBF) kernel) achieved an overall average accuracy score\nof 52.98% and an F1 score (macro) of 0.3324"}, "authors": ["Md. Ataur Rahman", "Md. Hanif Seddiqui"], "author_detail": {"name": "Md. Hanif Seddiqui"}, "author": "Md. Hanif Seddiqui", "links": [{"href": "http://arxiv.org/abs/1907.07826v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1907.07826v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1907.07826v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1907.07826v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1908.08987v1", "guidislink": true, "updated": "2019-08-11T08:01:58Z", "updated_parsed": [2019, 8, 11, 8, 1, 58, 6, 223, 0], "published": "2019-08-11T08:01:58Z", "published_parsed": [2019, 8, 11, 8, 1, 58, 6, 223, 0], "title": "PCGAN-CHAR: Progressively Trained Classifier Generative Adversarial\n  Networks for Classification of Noisy Handwritten Bangla Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "PCGAN-CHAR: Progressively Trained Classifier Generative Adversarial\n  Networks for Classification of Noisy Handwritten Bangla Characters"}, "summary": "Due to the sparsity of features, noise has proven to be a great inhibitor in\nthe classification of handwritten characters. To combat this, most techniques\nperform denoising of the data before classification. In this paper, we\nconsolidate the approach by training an all-in-one model that is able to\nclassify even noisy characters. For classification, we progressively train a\nclassifier generative adversarial network on the characters from low to high\nresolution. We show that by learning the features at each resolution\nindependently a trained model is able to accurately classify characters even in\nthe presence of noise. We experimentally demonstrate the effectiveness of our\napproach by classifying noisy versions of MNIST, handwritten Bangla Numeral,\nand Basic Character datasets.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Due to the sparsity of features, noise has proven to be a great inhibitor in\nthe classification of handwritten characters. To combat this, most techniques\nperform denoising of the data before classification. In this paper, we\nconsolidate the approach by training an all-in-one model that is able to\nclassify even noisy characters. For classification, we progressively train a\nclassifier generative adversarial network on the characters from low to high\nresolution. We show that by learning the features at each resolution\nindependently a trained model is able to accurately classify characters even in\nthe presence of noise. We experimentally demonstrate the effectiveness of our\napproach by classifying noisy versions of MNIST, handwritten Bangla Numeral,\nand Basic Character datasets."}, "authors": ["Qun Liu", "Edward Collier", "Supratik Mukhopadhyay"], "author_detail": {"name": "Supratik Mukhopadhyay"}, "author": "Supratik Mukhopadhyay", "arxiv_comment": "Paper was accepted at the 21st International Conference on\n  Asia-Pacific Digital Libraries (ICADL 2019)", "links": [{"href": "http://arxiv.org/abs/1908.08987v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1908.08987v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1908.08987v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1908.08987v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1912.11612v1", "guidislink": true, "updated": "2019-12-25T07:31:44Z", "updated_parsed": [2019, 12, 25, 7, 31, 44, 2, 359, 0], "published": "2019-12-25T07:31:44Z", "published_parsed": [2019, 12, 25, 7, 31, 44, 2, 359, 0], "title": "N-gram Statistical Stemmer for Bangla Corpus", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "N-gram Statistical Stemmer for Bangla Corpus"}, "summary": "Stemming is a process that can be utilized to trim inflected words to stem or\nroot form. It is useful for enhancing the retrieval effectiveness, especially\nfor text search in order to solve the mismatch problems. Previous research on\nBangla stemming mostly relied on eliminating multiple suffixes from a solitary\nword through a recursive rule based procedure to recover progressively\napplicable relative root. Our proposed system has enhanced the aforementioned\nexploration by actualizing one of the stemming algorithms called N-gram\nstemming. By utilizing an affiliation measure called dice coefficient, related\nsets of words are clustered depending on their character structure. The\nsmallest word in one cluster may be considered as the stem. We additionally\nanalyzed Affinity Propagation clustering algorithms with coefficient similarity\nas well as with median similarity. Our result indicates N-gram stemming\ntechniques to be effective in general which gave us around 87% accurate\nclusters.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Stemming is a process that can be utilized to trim inflected words to stem or\nroot form. It is useful for enhancing the retrieval effectiveness, especially\nfor text search in order to solve the mismatch problems. Previous research on\nBangla stemming mostly relied on eliminating multiple suffixes from a solitary\nword through a recursive rule based procedure to recover progressively\napplicable relative root. Our proposed system has enhanced the aforementioned\nexploration by actualizing one of the stemming algorithms called N-gram\nstemming. By utilizing an affiliation measure called dice coefficient, related\nsets of words are clustered depending on their character structure. The\nsmallest word in one cluster may be considered as the stem. We additionally\nanalyzed Affinity Propagation clustering algorithms with coefficient similarity\nas well as with median similarity. Our result indicates N-gram stemming\ntechniques to be effective in general which gave us around 87% accurate\nclusters."}, "authors": ["Rabeya Sadia", "Md Ataur Rahman", "Md Hanif Seddiqui"], "author_detail": {"name": "Md Hanif Seddiqui"}, "author": "Md Hanif Seddiqui", "links": [{"href": "http://arxiv.org/abs/1912.11612v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1912.11612v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1912.11612v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1912.11612v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2004.12769v1", "guidislink": true, "updated": "2020-04-27T13:18:58Z", "updated_parsed": [2020, 4, 27, 13, 18, 58, 0, 118, 0], "published": "2020-04-27T13:18:58Z", "published_parsed": [2020, 4, 27, 13, 18, 58, 0, 118, 0], "title": "A Skip-connected Multi-column Network for Isolated Handwritten Bangla\n  Character and Digit recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Skip-connected Multi-column Network for Isolated Handwritten Bangla\n  Character and Digit recognition"}, "summary": "Finding local invariant patterns in handwrit-ten characters and/or digits for\noptical character recognition is a difficult task. Variations in writing styles\nfrom one person to another make this task challenging. We have proposed a\nnon-explicit feature extraction method using a multi-scale multi-column skip\nconvolutional neural network in this work. Local and global features extracted\nfrom different layers of the proposed architecture are combined to derive the\nfinal feature descriptor encoding a character or digit image. Our method is\nevaluated on four publicly available datasets of isolated handwritten Bangla\ncharacters and digits. Exhaustive comparative analysis against contemporary\nmethods establishes the efficacy of our proposed approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Finding local invariant patterns in handwrit-ten characters and/or digits for\noptical character recognition is a difficult task. Variations in writing styles\nfrom one person to another make this task challenging. We have proposed a\nnon-explicit feature extraction method using a multi-scale multi-column skip\nconvolutional neural network in this work. Local and global features extracted\nfrom different layers of the proposed architecture are combined to derive the\nfinal feature descriptor encoding a character or digit image. Our method is\nevaluated on four publicly available datasets of isolated handwritten Bangla\ncharacters and digits. Exhaustive comparative analysis against contemporary\nmethods establishes the efficacy of our proposed approach."}, "authors": ["Animesh Singh", "Ritesh Sarkhel", "Nibaran Das", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/2004.12769v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.12769v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.12769v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.12769v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2009.08037v1", "guidislink": true, "updated": "2020-09-17T03:14:27Z", "updated_parsed": [2020, 9, 17, 3, 14, 27, 3, 261, 0], "published": "2020-09-17T03:14:27Z", "published_parsed": [2020, 9, 17, 3, 14, 27, 3, 261, 0], "title": "Word Segmentation from Unconstrained Handwritten Bangla Document Images\n  using Distance Transform", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word Segmentation from Unconstrained Handwritten Bangla Document Images\n  using Distance Transform"}, "summary": "Segmentation of handwritten document images into text lines and words is one\nof the most significant and challenging tasks in the development of a complete\nOptical Character Recognition (OCR) system. This paper addresses the automatic\nsegmentation of text words directly from unconstrained Bangla handwritten\ndocument images. The popular Distance transform (DT) algorithm is applied for\nlocating the outer boundary of the word images. This technique is free from\ngenerating the over-segmented words. A simple post-processing procedure is\napplied to isolate the under-segmented word images, if any. The proposed\ntechnique is tested on 50 random images taken from CMATERdb1.1.1 database.\nSatisfactory result is achieved with a segmentation accuracy of 91.88% which\nconfirms the robustness of the proposed methodology.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Segmentation of handwritten document images into text lines and words is one\nof the most significant and challenging tasks in the development of a complete\nOptical Character Recognition (OCR) system. This paper addresses the automatic\nsegmentation of text words directly from unconstrained Bangla handwritten\ndocument images. The popular Distance transform (DT) algorithm is applied for\nlocating the outer boundary of the word images. This technique is free from\ngenerating the over-segmented words. A simple post-processing procedure is\napplied to isolate the under-segmented word images, if any. The proposed\ntechnique is tested on 50 random images taken from CMATERdb1.1.1 database.\nSatisfactory result is achieved with a segmentation accuracy of 91.88% which\nconfirms the robustness of the proposed methodology."}, "authors": ["Pawan Kumar Singh", "Shubham Sinha", "Sagnik Pal Chowdhury", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "12 pages, 5 figures, conference", "links": [{"href": "http://arxiv.org/abs/2009.08037v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2009.08037v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.MM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68U10, 68U15", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2009.08037v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2009.08037v1", "journal_reference": "7th International Conference on Advances in Communication, Network\n  and Computing (CNC),pp. 271-282, 2016", "doi": null}
{"id": "http://arxiv.org/abs/1206.0238v1", "guidislink": true, "updated": "2012-06-01T16:20:41Z", "updated_parsed": [2012, 6, 1, 16, 20, 41, 4, 153, 0], "published": "2012-06-01T16:20:41Z", "published_parsed": [2012, 6, 1, 16, 20, 41, 4, 153, 0], "title": "Rapid Feature Extraction for Optical Character Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Rapid Feature Extraction for Optical Character Recognition"}, "summary": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection."}, "authors": ["M. Zahid Hossain", "M. Ashraful Amin", "Hong Yan"], "author_detail": {"name": "Hong Yan"}, "author": "Hong Yan", "arxiv_comment": "5 pages, 1 figure", "links": [{"href": "http://arxiv.org/abs/1206.0238v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1206.0238v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.5.2; I.7.5", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1206.0238v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1206.0238v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.08156v2", "guidislink": true, "updated": "2018-04-26T18:17:00Z", "updated_parsed": [2018, 4, 26, 18, 17, 0, 3, 116, 0], "published": "2017-01-27T12:38:47Z", "published_parsed": [2017, 1, 27, 12, 38, 47, 4, 27, 0], "title": "A Comprehensive Survey on Bengali Phoneme Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Comprehensive Survey on Bengali Phoneme Recognition"}, "summary": "Hidden Markov model based various phoneme recognition methods for Bengali\nlanguage is reviewed. Automatic phoneme recognition for Bengali language using\nmultilayer neural network is reviewed. Usefulness of multilayer neural network\nover single layer neural network is discussed. Bangla phonetic feature table\nconstruction and enhancement for Bengali speech recognition is also discussed.\nComparison among these methods is discussed.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Hidden Markov model based various phoneme recognition methods for Bengali\nlanguage is reviewed. Automatic phoneme recognition for Bengali language using\nmultilayer neural network is reviewed. Usefulness of multilayer neural network\nover single layer neural network is discussed. Bangla phonetic feature table\nconstruction and enhancement for Bengali speech recognition is also discussed.\nComparison among these methods is discussed."}, "authors": ["Sadia Tasnim Swarna", "Shamim Ehsan", "Md. Saiful Islam", "Marium E Jannat"], "author_detail": {"name": "Marium E Jannat"}, "author": "Marium E Jannat", "arxiv_comment": "7 pages, reference added in phoneme recognition methods", "links": [{"href": "http://arxiv.org/abs/1701.08156v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08156v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.SD", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SD", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08156v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08156v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2008.07853v1", "guidislink": true, "updated": "2020-08-18T11:02:25Z", "updated_parsed": [2020, 8, 18, 11, 2, 25, 1, 231, 0], "published": "2020-08-18T11:02:25Z", "published_parsed": [2020, 8, 18, 11, 2, 25, 1, 231, 0], "title": "Image Pre-processing on NumtaDB for Bengali Handwritten Digit\n  Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Image Pre-processing on NumtaDB for Bengali Handwritten Digit\n  Recognition"}, "summary": "NumtaDB is by far the largest data-set collection for handwritten digits in\nBengali. This is a diverse dataset containing more than 85000 images. But this\ndiversity also makes this dataset very difficult to work with. The goal of this\npaper is to find the benchmark for pre-processed images which gives good\naccuracy on any machine learning models. The reason being, there are no\navailable pre-processed data for Bengali digit recognition to work with like\nthe English digits for MNIST.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "NumtaDB is by far the largest data-set collection for handwritten digits in\nBengali. This is a diverse dataset containing more than 85000 images. But this\ndiversity also makes this dataset very difficult to work with. The goal of this\npaper is to find the benchmark for pre-processed images which gives good\naccuracy on any machine learning models. The reason being, there are no\navailable pre-processed data for Bengali digit recognition to work with like\nthe English digits for MNIST."}, "authors": ["Ovi Paul"], "author_detail": {"name": "Ovi Paul"}, "author": "Ovi Paul", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ICBSLP.2018.8554910", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/2008.07853v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2008.07853v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "5 pages, 8 figures and 4 tables", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2008.07853v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2008.07853v1", "journal_reference": "2018 International Conference on Bangla Speech and Language\n  Processing (ICBSLP), Sylhet, 2018, pp. 1-6", "doi": "10.1109/ICBSLP.2018.8554910"}
{"id": "http://arxiv.org/abs/1501.05495v1", "guidislink": true, "updated": "2015-01-22T13:46:06Z", "updated_parsed": [2015, 1, 22, 13, 46, 6, 3, 22, 0], "published": "2015-01-22T13:46:06Z", "published_parsed": [2015, 1, 22, 13, 46, 6, 3, 22, 0], "title": "A GA Based approach for selection of local features for recognition of\n  handwritten Bangla numerals", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A GA Based approach for selection of local features for recognition of\n  handwritten Bangla numerals"}, "summary": "Soft computing approaches are mainly designed to address the real world\nill-defined, imprecisely formulated problems, combining different kind of novel\nmodels of computation, such as neural networks, genetic algorithms (GAs.\nHandwritten digit recognition is a typical example of one such problem. In the\ncurrent work we have developed a two-pass approach where the first pass\nclassifier performs a coarse classification, based on some global features of\nthe input pattern by restricting the possibility of classification decisions\nwithin a group of classes, smaller than the number of classes considered\ninitially. In the second pass, the group specific classifiers concentrate on\nthe features extracted from the selected local regions, and refine the earlier\ndecision by combining the local and the global features for selecting the true\nclass of the input pattern from the group of candidate classes selected in the\nfirst pass. To optimize the selection of local regions a GA based approach has\nbeen developed here. The maximum recognition performance on Bangla digit\nsamples as achieved on the test set, during the first pass of the two pass\napproach is 93.35%. After combining the results of the two stage classifiers,\nan overall success rate of 95.25% is achieved.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Soft computing approaches are mainly designed to address the real world\nill-defined, imprecisely formulated problems, combining different kind of novel\nmodels of computation, such as neural networks, genetic algorithms (GAs.\nHandwritten digit recognition is a typical example of one such problem. In the\ncurrent work we have developed a two-pass approach where the first pass\nclassifier performs a coarse classification, based on some global features of\nthe input pattern by restricting the possibility of classification decisions\nwithin a group of classes, smaller than the number of classes considered\ninitially. In the second pass, the group specific classifiers concentrate on\nthe features extracted from the selected local regions, and refine the earlier\ndecision by combining the local and the global features for selecting the true\nclass of the input pattern from the group of candidate classes selected in the\nfirst pass. To optimize the selection of local regions a GA based approach has\nbeen developed here. The maximum recognition performance on Bangla digit\nsamples as achieved on the test set, during the first pass of the two pass\napproach is 93.35%. After combining the results of the two stage classifiers,\nan overall success rate of 95.25% is achieved."}, "authors": ["Nibaran Das", "Subhadip Basu", "Punam Kumar Saha", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "In proceedings of UB NE ASEE 2009 conference, University of\n  Bridgeport, USA", "links": [{"href": "http://arxiv.org/abs/1501.05495v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1501.05495v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1501.05495v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1501.05495v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1605.00420v1", "guidislink": true, "updated": "2016-05-02T10:28:07Z", "updated_parsed": [2016, 5, 2, 10, 28, 7, 0, 123, 0], "published": "2016-05-02T10:28:07Z", "published_parsed": [2016, 5, 2, 10, 28, 7, 0, 123, 0], "title": "An Enhanced Harmony Search Method for Bangla Handwritten Character\n  Recognition Using Region Sampling", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An Enhanced Harmony Search Method for Bangla Handwritten Character\n  Recognition Using Region Sampling"}, "summary": "Identification of minimum number of local regions of a handwritten character\nimage, containing well-defined discriminating features which are sufficient for\na minimal but complete description of the character is a challenging task. A\nnew region selection technique based on the idea of an enhanced Harmony Search\nmethodology has been proposed here. The powerful framework of Harmony Search\nhas been utilized to search the region space and detect only the most\ninformative regions for correctly recognizing the handwritten character. The\nproposed method has been tested on handwritten samples of Bangla Basic,\nCompound and mixed (Basic and Compound characters) characters separately with\nSVM based classifier using a longest run based feature-set obtained from the\nimage subregions formed by a CG based quad-tree partitioning approach. Applying\nthis methodology on the above mentioned three types of datasets, respectively\n43.75%, 12.5% and 37.5% gains have been achieved in terms of region reduction\nand 2.3%, 0.6% and 1.2% gains have been achieved in terms of recognition\naccuracy. The results show a sizeable reduction in the minimal number of\ndescriptive regions as well a significant increase in recognition accuracy for\nall the datasets using the proposed technique. Thus the time and cost related\nto feature extraction is decreased without dampening the corresponding\nrecognition accuracy.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Identification of minimum number of local regions of a handwritten character\nimage, containing well-defined discriminating features which are sufficient for\na minimal but complete description of the character is a challenging task. A\nnew region selection technique based on the idea of an enhanced Harmony Search\nmethodology has been proposed here. The powerful framework of Harmony Search\nhas been utilized to search the region space and detect only the most\ninformative regions for correctly recognizing the handwritten character. The\nproposed method has been tested on handwritten samples of Bangla Basic,\nCompound and mixed (Basic and Compound characters) characters separately with\nSVM based classifier using a longest run based feature-set obtained from the\nimage subregions formed by a CG based quad-tree partitioning approach. Applying\nthis methodology on the above mentioned three types of datasets, respectively\n43.75%, 12.5% and 37.5% gains have been achieved in terms of region reduction\nand 2.3%, 0.6% and 1.2% gains have been achieved in terms of recognition\naccuracy. The results show a sizeable reduction in the minimal number of\ndescriptive regions as well a significant increase in recognition accuracy for\nall the datasets using the proposed technique. Thus the time and cost related\nto feature extraction is decreased without dampening the corresponding\nrecognition accuracy."}, "authors": ["Ritesh Sarkhel", "Amit K Saha", "Nibaran Das"], "author_detail": {"name": "Nibaran Das"}, "author": "Nibaran Das", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ReTIS.2015.7232899", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1605.00420v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1605.00420v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "2nd IEEE International Conference on Recent Trends in Information\n  Systems, 2015", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1605.00420v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1605.00420v1", "journal_reference": null, "doi": "10.1109/ReTIS.2015.7232899"}
{"id": "http://arxiv.org/abs/2101.05081v1", "guidislink": true, "updated": "2020-12-10T15:36:41Z", "updated_parsed": [2020, 12, 10, 15, 36, 41, 3, 345, 0], "published": "2020-12-10T15:36:41Z", "published_parsed": [2020, 12, 10, 15, 36, 41, 3, 345, 0], "title": "Deep Learning Approach Combining Lightweight CNN Architecture with\n  Transfer Learning: An Automatic Approach for the Detection and Recognition of\n  Bangladeshi Banknotes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Deep Learning Approach Combining Lightweight CNN Architecture with\n  Transfer Learning: An Automatic Approach for the Detection and Recognition of\n  Bangladeshi Banknotes"}, "summary": "Automatic detection and recognition of banknotes can be a very useful\ntechnology for people with visual difficulties and also for the banks itself by\nproviding efficient management for handling different paper currencies.\nLightweight models can easily be integrated into any handy IoT based\ngadgets/devices. This article presents our experiments on several\nstate-of-the-art deep learning methods based on Lightweight Convolutional\nNeural Network architectures combining with transfer learning. ResNet152v2,\nMobileNet, and NASNetMobile were used as the base models with two different\ndatasets containing Bangladeshi banknote images. The Bangla Currency dataset\nhas 8000 Bangladeshi banknote images where the Bangla Money dataset consists of\n1970 images. The performances of the models were measured using both the\ndatasets and the combination of the two datasets. In order to achieve maximum\nefficiency, we used various augmentations, hyperparameter tuning, and\noptimizations techniques. We have achieved maximum test accuracy of 98.88\\% on\n8000 images dataset using MobileNet, 100\\% on the 1970 images dataset using\nNASNetMobile, and 97.77\\% on the combined dataset (9970 images) using\nMobileNet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic detection and recognition of banknotes can be a very useful\ntechnology for people with visual difficulties and also for the banks itself by\nproviding efficient management for handling different paper currencies.\nLightweight models can easily be integrated into any handy IoT based\ngadgets/devices. This article presents our experiments on several\nstate-of-the-art deep learning methods based on Lightweight Convolutional\nNeural Network architectures combining with transfer learning. ResNet152v2,\nMobileNet, and NASNetMobile were used as the base models with two different\ndatasets containing Bangladeshi banknote images. The Bangla Currency dataset\nhas 8000 Bangladeshi banknote images where the Bangla Money dataset consists of\n1970 images. The performances of the models were measured using both the\ndatasets and the combination of the two datasets. In order to achieve maximum\nefficiency, we used various augmentations, hyperparameter tuning, and\noptimizations techniques. We have achieved maximum test accuracy of 98.88\\% on\n8000 images dataset using MobileNet, 100\\% on the 1970 images dataset using\nNASNetMobile, and 97.77\\% on the combined dataset (9970 images) using\nMobileNet."}, "authors": ["Ali Hasan Md. Linkon", "Md. Mahir Labib", "Faisal Haque Bappy", "Soumik Sarker", "Marium-E-Jannat", "Md Saiful Islam"], "author_detail": {"name": "Md Saiful Islam"}, "author": "Md Saiful Islam", "arxiv_comment": "4 pages", "links": [{"href": "http://arxiv.org/abs/2101.05081v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2101.05081v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2101.05081v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2101.05081v1", "journal_reference": "2020 11th International Conference on Electrical and Computer\n  Engineering (ICECE)", "doi": null}
{"id": "http://arxiv.org/abs/1708.00227v1", "guidislink": true, "updated": "2017-08-01T09:52:03Z", "updated_parsed": [2017, 8, 1, 9, 52, 3, 1, 213, 0], "published": "2017-08-01T09:52:03Z", "published_parsed": [2017, 8, 1, 9, 52, 3, 1, 213, 0], "title": "HMM-based Indic Handwritten Word Recognition using Zone Segmentation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "HMM-based Indic Handwritten Word Recognition using Zone Segmentation"}, "summary": "This paper presents a novel approach towards Indic handwritten word\nrecognition using zone-wise information. Because of complex nature due to\ncompound characters, modifiers, overlapping and touching, etc., character\nsegmentation and recognition is a tedious job in Indic scripts (e.g.\nDevanagari, Bangla, Gurumukhi, and other similar scripts). To avoid character\nsegmentation in such scripts, HMM-based sequence modeling has been used earlier\nin holistic way. This paper proposes an efficient word recognition framework by\nsegmenting the handwritten word images horizontally into three zones (upper,\nmiddle and lower) and recognize the corresponding zones. The main aim of this\nzone segmentation approach is to reduce the number of distinct component\nclasses compared to the total number of classes in Indic scripts. As a result,\nuse of this zone segmentation approach enhances the recognition performance of\nthe system. The components in middle zone where characters are mostly touching\nare recognized using HMM. After the recognition of middle zone, HMM based\nViterbi forced alignment is applied to mark the left and right boundaries of\nthe characters. Next, the residue components, if any, in upper and lower zones\nin their respective boundary are combined to achieve the final word level\nrecognition. Water reservoir feature has been integrated in this framework to\nimprove the zone segmentation and character alignment defects while\nsegmentation. A novel sliding window-based feature, called Pyramid Histogram of\nOriented Gradient (PHOG) is proposed for middle zone recognition. An exhaustive\nexperiment is performed on two Indic scripts namely, Bangla and Devanagari for\nthe performance evaluation. From the experiment, it has been noted that\nproposed zone-wise recognition improves accuracy with respect to the\ntraditional way of Indic word recognition.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents a novel approach towards Indic handwritten word\nrecognition using zone-wise information. Because of complex nature due to\ncompound characters, modifiers, overlapping and touching, etc., character\nsegmentation and recognition is a tedious job in Indic scripts (e.g.\nDevanagari, Bangla, Gurumukhi, and other similar scripts). To avoid character\nsegmentation in such scripts, HMM-based sequence modeling has been used earlier\nin holistic way. This paper proposes an efficient word recognition framework by\nsegmenting the handwritten word images horizontally into three zones (upper,\nmiddle and lower) and recognize the corresponding zones. The main aim of this\nzone segmentation approach is to reduce the number of distinct component\nclasses compared to the total number of classes in Indic scripts. As a result,\nuse of this zone segmentation approach enhances the recognition performance of\nthe system. The components in middle zone where characters are mostly touching\nare recognized using HMM. After the recognition of middle zone, HMM based\nViterbi forced alignment is applied to mark the left and right boundaries of\nthe characters. Next, the residue components, if any, in upper and lower zones\nin their respective boundary are combined to achieve the final word level\nrecognition. Water reservoir feature has been integrated in this framework to\nimprove the zone segmentation and character alignment defects while\nsegmentation. A novel sliding window-based feature, called Pyramid Histogram of\nOriented Gradient (PHOG) is proposed for middle zone recognition. An exhaustive\nexperiment is performed on two Indic scripts namely, Bangla and Devanagari for\nthe performance evaluation. From the experiment, it has been noted that\nproposed zone-wise recognition improves accuracy with respect to the\ntraditional way of Indic word recognition."}, "authors": ["Partha Pratim Roy", "Ayan Kumar Bhunia", "Ayan Das", "Prasenjit Dey", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patcog.2016.04.012", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1708.00227v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1708.00227v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in Pattern Recognition(2016)", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1708.00227v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1708.00227v1", "journal_reference": "Pattern Recognition, Volume 60, December 2016, Pages 1057-1075", "doi": "10.1016/j.patcog.2016.04.012"}
{"id": "http://arxiv.org/abs/1708.05529v6", "guidislink": true, "updated": "2018-07-30T10:41:30Z", "updated_parsed": [2018, 7, 30, 10, 41, 30, 0, 211, 0], "published": "2017-08-18T07:47:05Z", "published_parsed": [2017, 8, 18, 7, 47, 5, 4, 230, 0], "title": "Word Searching in Scene Image and Video Frame in Multi-Script Scenario\n  using Dynamic Shape Coding", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word Searching in Scene Image and Video Frame in Multi-Script Scenario\n  using Dynamic Shape Coding"}, "summary": "Retrieval of text information from natural scene images and video frames is a\nchallenging task due to its inherent problems like complex character shapes,\nlow resolution, background noise, etc. Available OCR systems often fail to\nretrieve such information in scene/video frames. Keyword spotting, an\nalternative way to retrieve information, performs efficient text searching in\nsuch scenarios. However, current word spotting techniques in scene/video images\nare script-specific and they are mainly developed for Latin script. This paper\npresents a novel word spotting framework using dynamic shape coding for text\nretrieval in natural scene image and video frames. The framework is designed to\nsearch query keyword from multiple scripts with the help of on-the-fly\nscript-wise keyword generation for the corresponding script. We have used a\ntwo-stage word spotting approach using Hidden Markov Model (HMM) to detect the\ntranslated keyword in a given text line by identifying the script of the line.\nA novel unsupervised dynamic shape coding based scheme has been used to group\nsimilar shape characters to avoid confusion and to improve text alignment.\nNext, the hypotheses locations are verified to improve retrieval performance.\nTo evaluate the proposed system for searching keyword from natural scene image\nand video frames, we have considered two popular Indic scripts such as Bangla\n(Bengali) and Devanagari along with English. Inspired by the zone-wise\nrecognition approach in Indic scripts[1], zone-wise text information has been\nused to improve the traditional word spotting performance in Indic scripts. For\nour experiment, a dataset consisting of images of different scenes and video\nframes of English, Bangla and Devanagari scripts were considered. The results\nobtained showed the effectiveness of our proposed word spotting approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Retrieval of text information from natural scene images and video frames is a\nchallenging task due to its inherent problems like complex character shapes,\nlow resolution, background noise, etc. Available OCR systems often fail to\nretrieve such information in scene/video frames. Keyword spotting, an\nalternative way to retrieve information, performs efficient text searching in\nsuch scenarios. However, current word spotting techniques in scene/video images\nare script-specific and they are mainly developed for Latin script. This paper\npresents a novel word spotting framework using dynamic shape coding for text\nretrieval in natural scene image and video frames. The framework is designed to\nsearch query keyword from multiple scripts with the help of on-the-fly\nscript-wise keyword generation for the corresponding script. We have used a\ntwo-stage word spotting approach using Hidden Markov Model (HMM) to detect the\ntranslated keyword in a given text line by identifying the script of the line.\nA novel unsupervised dynamic shape coding based scheme has been used to group\nsimilar shape characters to avoid confusion and to improve text alignment.\nNext, the hypotheses locations are verified to improve retrieval performance.\nTo evaluate the proposed system for searching keyword from natural scene image\nand video frames, we have considered two popular Indic scripts such as Bangla\n(Bengali) and Devanagari along with English. Inspired by the zone-wise\nrecognition approach in Indic scripts[1], zone-wise text information has been\nused to improve the traditional word spotting performance in Indic scripts. For\nour experiment, a dataset consisting of images of different scenes and video\nframes of English, Bangla and Devanagari scripts were considered. The results\nobtained showed the effectiveness of our proposed word spotting approach."}, "authors": ["Partha Pratim Roy", "Ayan Kumar Bhunia", "Avirup Bhattacharyya", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "arxiv_comment": "Multimedia Tools and Applications, Springer", "links": [{"href": "http://arxiv.org/abs/1708.05529v6", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1708.05529v6", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1708.05529v6", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1708.05529v6", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1410.4013v1", "guidislink": true, "updated": "2014-10-15T11:19:33Z", "updated_parsed": [2014, 10, 15, 11, 19, 33, 2, 288, 0], "published": "2014-10-15T11:19:33Z", "published_parsed": [2014, 10, 15, 11, 19, 33, 2, 288, 0], "title": "A two-pass fuzzy-geno approach to pattern classification", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A two-pass fuzzy-geno approach to pattern classification"}, "summary": "The work presents an extension of the fuzzy approach to 2-D shape recognition\n[1] through refinement of initial or coarse classification decisions under a\ntwo pass approach. In this approach, an unknown pattern is classified by\nrefining possible classification decisions obtained through coarse\nclassification of the same. To build a fuzzy model of a pattern class\nhorizontal and vertical fuzzy partitions on the sample images of the class are\noptimized using genetic algorithm. To make coarse classification decisions\nabout an unknown pattern, the fuzzy representation of the pattern is compared\nwith models of all pattern classes through a specially designed similarity\nmeasure. Coarse classification decisions are refined in the second pass to\nobtain the final classification decision of the unknown pattern. To do so,\noptimized horizontal and vertical fuzzy partitions are again created on certain\nregions of the image frame, specific to each group of similar type of pattern\nclasses. It is observed through experiments that the technique improves the\noverall recognition rate from 86.2%, in the first pass, to 90.4% after the\nsecond pass, with 500 training samples of handwritten digits.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presents an extension of the fuzzy approach to 2-D shape recognition\n[1] through refinement of initial or coarse classification decisions under a\ntwo pass approach. In this approach, an unknown pattern is classified by\nrefining possible classification decisions obtained through coarse\nclassification of the same. To build a fuzzy model of a pattern class\nhorizontal and vertical fuzzy partitions on the sample images of the class are\noptimized using genetic algorithm. To make coarse classification decisions\nabout an unknown pattern, the fuzzy representation of the pattern is compared\nwith models of all pattern classes through a specially designed similarity\nmeasure. Coarse classification decisions are refined in the second pass to\nobtain the final classification decision of the unknown pattern. To do so,\noptimized horizontal and vertical fuzzy partitions are again created on certain\nregions of the image frame, specific to each group of similar type of pattern\nclasses. It is observed through experiments that the technique improves the\noverall recognition rate from 86.2%, in the first pass, to 90.4% after the\nsecond pass, with 500 training samples of handwritten digits."}, "authors": ["Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1410.4013v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.4013v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.4013v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.4013v1", "arxiv_comment": null, "journal_reference": "Proc. of International Conference on Computer Processing of\n  Bangla, pp. 130-134, Feb-2006, Dhaka", "doi": null}
{"id": "http://arxiv.org/abs/1009.4979v1", "guidislink": true, "updated": "2010-09-25T06:27:49Z", "updated_parsed": [2010, 9, 25, 6, 27, 49, 5, 268, 0], "published": "2010-09-25T06:27:49Z", "published_parsed": [2010, 9, 25, 6, 27, 49, 5, 268, 0], "title": "Smart Bengali Cell Phone Keypad Layout", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Smart Bengali Cell Phone Keypad Layout"}, "summary": "Nowadays cell phone is the most common communicating used by mass people. SMS\nbased communication is a cheap and popular communication method. It is human\ntendency to have the opportunity to write SMS in their mother language. Text\ninput in mother language is more flexible when the alphabets of that language\nare printed on the keypad. Bangla mobile keypad based on phonetics has been\nproposed earlier. But the keypad is not scientific from frequency and\nflexibility point of view. Since it is not a feasible solution in this paper we\nhave proposed an efficient Bengali keypad for cell phone and other cellular\ndevice. The proposed keypad is based on the frequency of the alphabets in\nBengali language and also with the view of structure of human finger movements.\nWe took the two points in count to provide a flexible and fast cell phone\nkeypad.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Nowadays cell phone is the most common communicating used by mass people. SMS\nbased communication is a cheap and popular communication method. It is human\ntendency to have the opportunity to write SMS in their mother language. Text\ninput in mother language is more flexible when the alphabets of that language\nare printed on the keypad. Bangla mobile keypad based on phonetics has been\nproposed earlier. But the keypad is not scientific from frequency and\nflexibility point of view. Since it is not a feasible solution in this paper we\nhave proposed an efficient Bengali keypad for cell phone and other cellular\ndevice. The proposed keypad is based on the frequency of the alphabets in\nBengali language and also with the view of structure of human finger movements.\nWe took the two points in count to provide a flexible and fast cell phone\nkeypad."}, "authors": ["Md. Abul Kalam Azad", "Rezwana Sharmeen", "Shabbir Ahmad", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "4 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4979v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4979v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4979v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4979v1", "journal_reference": "Proc. 8th International Conference on Computer and Information\n  Technology (ICCIT 2005), Dhaka, Bangladesh, pp. 1208-1211, Dec. 2005", "doi": null}
{"id": "http://arxiv.org/abs/1707.08385v1", "guidislink": true, "updated": "2017-07-26T11:40:13Z", "updated_parsed": [2017, 7, 26, 11, 40, 13, 2, 207, 0], "published": "2017-07-26T11:40:13Z", "published_parsed": [2017, 7, 26, 11, 40, 13, 2, 207, 0], "title": "A Novel Transfer Learning Approach upon Hindi, Arabic, and Bangla\n  Numerals using Convolutional Neural Networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Novel Transfer Learning Approach upon Hindi, Arabic, and Bangla\n  Numerals using Convolutional Neural Networks"}, "summary": "Increased accuracy in predictive models for handwritten character recognition\nwill open up new frontiers for optical character recognition. Major drawbacks\nof predictive machine learning models are headed by the elongated training time\ntaken by some models, and the requirement that training and test data be in the\nsame feature space and consist of the same distribution. In this study, these\nobstacles are minimized by presenting a model for transferring knowledge from\none task to another. This model is presented for the recognition of handwritten\nnumerals in Indic languages. The model utilizes convolutional neural networks\nwith backpropagation for error reduction and dropout for data overfitting. The\noutput performance of the proposed neural network is shown to have closely\nmatched other state-of-the-art methods using only a fraction of time used by\nthe state-of-the-arts.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Increased accuracy in predictive models for handwritten character recognition\nwill open up new frontiers for optical character recognition. Major drawbacks\nof predictive machine learning models are headed by the elongated training time\ntaken by some models, and the requirement that training and test data be in the\nsame feature space and consist of the same distribution. In this study, these\nobstacles are minimized by presenting a model for transferring knowledge from\none task to another. This model is presented for the recognition of handwritten\nnumerals in Indic languages. The model utilizes convolutional neural networks\nwith backpropagation for error reduction and dropout for data overfitting. The\noutput performance of the proposed neural network is shown to have closely\nmatched other state-of-the-art methods using only a fraction of time used by\nthe state-of-the-arts."}, "authors": ["Abdul Kawsar Tushar", "Akm Ashiquzzaman", "Afia Afrin", "Md. Rashedul Islam"], "author_detail": {"name": "Md. Rashedul Islam"}, "author": "Md. Rashedul Islam", "arxiv_comment": "10 pages; 2 figures, 4 tables; conference - International Conference\n  On Computational Vision and Bio Inspired Computing 2017 (http://iccvbic.com/)\n  (accepted)", "links": [{"href": "http://arxiv.org/abs/1707.08385v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1707.08385v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1707.08385v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1707.08385v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1804.04475v1", "guidislink": true, "updated": "2018-04-12T12:46:08Z", "updated_parsed": [2018, 4, 12, 12, 46, 8, 3, 102, 0], "published": "2018-04-12T12:46:08Z", "published_parsed": [2018, 4, 12, 12, 46, 8, 3, 102, 0], "title": "Learning Multilingual Embeddings for Cross-Lingual Information Retrieval\n  in the Presence of Topically Aligned Corpora", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Learning Multilingual Embeddings for Cross-Lingual Information Retrieval\n  in the Presence of Topically Aligned Corpora"}, "summary": "Cross-lingual information retrieval is a challenging task in the absence of\naligned parallel corpora. In this paper, we address this problem by considering\ntopically aligned corpora designed for evaluating an IR setup. To emphasize, we\nneither use any sentence-aligned corpora or document-aligned corpora, nor do we\nuse any language specific resources such as dictionary, thesaurus, or grammar\nrules. Instead, we use an embedding into a common space and learn word\ncorrespondences directly from there. We test our proposed approach for\nbilingual IR on standard FIRE datasets for Bangla, Hindi and English. The\nproposed method is superior to the state-of-the-art method not only for IR\nevaluation measures but also in terms of time requirements. We extend our\nmethod successfully to the trilingual setting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Cross-lingual information retrieval is a challenging task in the absence of\naligned parallel corpora. In this paper, we address this problem by considering\ntopically aligned corpora designed for evaluating an IR setup. To emphasize, we\nneither use any sentence-aligned corpora or document-aligned corpora, nor do we\nuse any language specific resources such as dictionary, thesaurus, or grammar\nrules. Instead, we use an embedding into a common space and learn word\ncorrespondences directly from there. We test our proposed approach for\nbilingual IR on standard FIRE datasets for Bangla, Hindi and English. The\nproposed method is superior to the state-of-the-art method not only for IR\nevaluation measures but also in terms of time requirements. We extend our\nmethod successfully to the trilingual setting."}, "authors": ["Mitodru Niyogi", "Kripabandhu Ghosh", "Arnab Bhattacharya"], "author_detail": {"name": "Arnab Bhattacharya"}, "author": "Arnab Bhattacharya", "links": [{"href": "http://arxiv.org/abs/1804.04475v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1804.04475v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1804.04475v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1804.04475v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1902.11133v1", "guidislink": true, "updated": "2019-02-25T13:52:53Z", "updated_parsed": [2019, 2, 25, 13, 52, 53, 0, 56, 0], "published": "2019-02-25T13:52:53Z", "published_parsed": [2019, 2, 25, 13, 52, 53, 0, 56, 0], "title": "Bengali Handwritten Character Classification using Transfer Learning on\n  Deep Convolutional Neural Network", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bengali Handwritten Character Classification using Transfer Learning on\n  Deep Convolutional Neural Network"}, "summary": "In this paper, we propose a solution which uses state-of-the-art techniques\nin Deep Learning to tackle the problem of Bengali Handwritten Character\nRecognition ( HCR ). Our method uses lesser iterations to train than most other\ncomparable methods. We employ Transfer Learning on ResNet 50, a\nstate-of-the-art deep Convolutional Neural Network Model, pretrained on\nImageNet dataset. We also use other techniques like a modified version of One\nCycle Policy, varying the input image sizes etc. to ensure that our training\noccurs fast. We use the BanglaLekha-Isolated Dataset for evaluation of our\ntechnique which consists of 84 classes (50 Basic, 10 Numerals and 24 Compound\nCharacters). We are able to achieve 96.12% accuracy in just 47 epochs on\nBanglaLekha-Isolated dataset. When comparing our method with that of other\nresearchers, considering number of classes and without using Ensemble Learning,\nthe proposed solution achieves state of the art result for Handwritten Bengali\nCharacter Recognition. Code and weight files are available at\nhttps://github.com/swagato-c/bangla-hwcr-present.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we propose a solution which uses state-of-the-art techniques\nin Deep Learning to tackle the problem of Bengali Handwritten Character\nRecognition ( HCR ). Our method uses lesser iterations to train than most other\ncomparable methods. We employ Transfer Learning on ResNet 50, a\nstate-of-the-art deep Convolutional Neural Network Model, pretrained on\nImageNet dataset. We also use other techniques like a modified version of One\nCycle Policy, varying the input image sizes etc. to ensure that our training\noccurs fast. We use the BanglaLekha-Isolated Dataset for evaluation of our\ntechnique which consists of 84 classes (50 Basic, 10 Numerals and 24 Compound\nCharacters). We are able to achieve 96.12% accuracy in just 47 epochs on\nBanglaLekha-Isolated dataset. When comparing our method with that of other\nresearchers, considering number of classes and without using Ensemble Learning,\nthe proposed solution achieves state of the art result for Handwritten Bengali\nCharacter Recognition. Code and weight files are available at\nhttps://github.com/swagato-c/bangla-hwcr-present."}, "authors": ["Swagato Chatterjee", "Rwik Kumar Dutta", "Debayan Ganguly", "Kingshuk Chatterjee", "Sudipta Roy"], "author_detail": {"name": "Sudipta Roy"}, "author": "Sudipta Roy", "links": [{"href": "http://arxiv.org/abs/1902.11133v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1902.11133v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1902.11133v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1902.11133v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1912.12405v2", "guidislink": true, "updated": "2020-03-16T17:06:44Z", "updated_parsed": [2020, 3, 16, 17, 6, 44, 0, 76, 0], "published": "2019-12-28T05:37:28Z", "published_parsed": [2019, 12, 28, 5, 37, 28, 5, 362, 0], "title": "A Genetic Algorithm based Kernel-size Selection Approach for a\n  Multi-column Convolutional Neural Network", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Genetic Algorithm based Kernel-size Selection Approach for a\n  Multi-column Convolutional Neural Network"}, "summary": "Deep neural network-based architectures give promising results in various\ndomains including pattern recognition. Finding the optimal combination of the\nhyper-parameters of such a large-sized architecture is tedious and requires a\nlarge number of laboratory experiments. But, identifying the optimal\ncombination of a hyper-parameter or appropriate kernel size for a given\narchitecture of deep learning is always a challenging and tedious task. Here,\nwe introduced a genetic algorithm-based technique to reduce the efforts of\nfinding the optimal combination of a hyper-parameter (kernel size) of a\nconvolutional neural network-based architecture. The method is evaluated on\nthree popular datasets of different handwritten Bangla characters and digits.\nThe implementation of the proposed methodology can be found in the following\nlink: https://github.com/DeepQn/GA-Based-Kernel-Size.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Deep neural network-based architectures give promising results in various\ndomains including pattern recognition. Finding the optimal combination of the\nhyper-parameters of such a large-sized architecture is tedious and requires a\nlarge number of laboratory experiments. But, identifying the optimal\ncombination of a hyper-parameter or appropriate kernel size for a given\narchitecture of deep learning is always a challenging and tedious task. Here,\nwe introduced a genetic algorithm-based technique to reduce the efforts of\nfinding the optimal combination of a hyper-parameter (kernel size) of a\nconvolutional neural network-based architecture. The method is evaluated on\nthree popular datasets of different handwritten Bangla characters and digits.\nThe implementation of the proposed methodology can be found in the following\nlink: https://github.com/DeepQn/GA-Based-Kernel-Size."}, "authors": ["Animesh Singh", "Sandip Saha", "Ritesh Sarkhel", "Mahantapas Kundu", "Mita Nasipuri", "Nibaran Das"], "author_detail": {"name": "Nibaran Das"}, "author": "Nibaran Das", "links": [{"href": "http://arxiv.org/abs/1912.12405v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1912.12405v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1912.12405v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1912.12405v2", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2003.07428v1", "guidislink": true, "updated": "2020-03-16T20:19:21Z", "updated_parsed": [2020, 3, 16, 20, 19, 21, 0, 76, 0], "published": "2020-03-16T20:19:21Z", "published_parsed": [2020, 3, 16, 20, 19, 21, 0, 76, 0], "title": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression"}, "summary": "In this paper, we discuss the development of a multilingual annotated corpus\nof misogyny and aggression in Indian English, Hindi, and Indian Bangla as part\nof a project on studying and automatically identifying misogyny and communalism\non social media (the ComMA Project). The dataset is collected from comments on\nYouTube videos and currently contains a total of over 20,000 comments. The\ncomments are annotated at two levels - aggression (overtly aggressive, covertly\naggressive, and non-aggressive) and misogyny (gendered and non-gendered). We\ndescribe the process of data collection, the tagset used for annotation, and\nissues and challenges faced during the process of annotation. Finally, we\ndiscuss the results of the baseline experiments conducted to develop a\nclassifier for misogyny in the three languages.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we discuss the development of a multilingual annotated corpus\nof misogyny and aggression in Indian English, Hindi, and Indian Bangla as part\nof a project on studying and automatically identifying misogyny and communalism\non social media (the ComMA Project). The dataset is collected from comments on\nYouTube videos and currently contains a total of over 20,000 comments. The\ncomments are annotated at two levels - aggression (overtly aggressive, covertly\naggressive, and non-aggressive) and misogyny (gendered and non-gendered). We\ndescribe the process of data collection, the tagset used for annotation, and\nissues and challenges faced during the process of annotation. Finally, we\ndiscuss the results of the baseline experiments conducted to develop a\nclassifier for misogyny in the three languages."}, "authors": ["Shiladitya Bhattacharya", "Siddharth Singh", "Ritesh Kumar", "Akanksha Bansal", "Akash Bhagat", "Yogesh Dawer", "Bornini Lahiri", "Atul Kr. Ojha"], "author_detail": {"name": "Atul Kr. Ojha"}, "author": "Atul Kr. Ojha", "arxiv_comment": "Submitted for review to Second Workshop on Trolling, Aggression and\n  Cyberbullying (TRAC 2020)", "links": [{"href": "http://arxiv.org/abs/2003.07428v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2003.07428v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2003.07428v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2003.07428v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2003.08384v5", "guidislink": true, "updated": "2021-01-05T18:11:50Z", "updated_parsed": [2021, 1, 5, 18, 11, 50, 1, 5, 0], "published": "2020-03-18T17:58:05Z", "published_parsed": [2020, 3, 18, 17, 58, 5, 2, 78, 0], "title": "Confronting the Constraints for Optical Character Segmentation from\n  Printed Bangla Text Image", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Confronting the Constraints for Optical Character Segmentation from\n  Printed Bangla Text Image"}, "summary": "In a world of digitization, optical character recognition holds the\nautomation to written history. Optical character recognition system basically\nconverts printed images into editable texts for better storage and usability.\nTo be completely functional, the system needs to go through some crucial\nmethods such as pre-processing and segmentation. Pre-processing helps printed\ndata to be noise free and gets rid of skewness efficiently whereas segmentation\nhelps the image fragment into line, word and character precisely for better\nconversion. These steps hold the door to better accuracy and consistent results\nfor a printed image to be ready for conversion. Our proposed algorithm is able\nto segment characters both from ideal and non-ideal cases of scanned or\ncaptured images giving a sustainable outcome. The implementation of our work is\nprovided here: https://cutt.ly/rgdfBIa", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In a world of digitization, optical character recognition holds the\nautomation to written history. Optical character recognition system basically\nconverts printed images into editable texts for better storage and usability.\nTo be completely functional, the system needs to go through some crucial\nmethods such as pre-processing and segmentation. Pre-processing helps printed\ndata to be noise free and gets rid of skewness efficiently whereas segmentation\nhelps the image fragment into line, word and character precisely for better\nconversion. These steps hold the door to better accuracy and consistent results\nfor a printed image to be ready for conversion. Our proposed algorithm is able\nto segment characters both from ideal and non-ideal cases of scanned or\ncaptured images giving a sustainable outcome. The implementation of our work is\nprovided here: https://cutt.ly/rgdfBIa"}, "authors": ["Abu Saleh Md. Abir", "Sanjana Rahman", "Samia Ellin", "Maisha Farzana", "Md Hridoy Manik", "Chowdhury Rafeed Rahman"], "author_detail": {"name": "Chowdhury Rafeed Rahman"}, "author": "Chowdhury Rafeed Rahman", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1145/3428363.3428367", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/2003.08384v5", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2003.08384v5", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2003.08384v5", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2003.08384v5", "arxiv_comment": null, "journal_reference": null, "doi": "10.1145/3428363.3428367"}
{"id": "http://arxiv.org/abs/2004.01551v1", "guidislink": true, "updated": "2020-04-03T13:20:12Z", "updated_parsed": [2020, 4, 3, 13, 20, 12, 4, 94, 0], "published": "2020-04-03T13:20:12Z", "published_parsed": [2020, 4, 3, 13, 20, 12, 4, 94, 0], "title": "Sparse Concept Coded Tetrolet Transform for Unconstrained Odia Character\n  Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sparse Concept Coded Tetrolet Transform for Unconstrained Odia Character\n  Recognition"}, "summary": "Feature representation in the form of spatio-spectral decomposition is one of\nthe robust techniques adopted in automatic handwritten character recognition\nsystems. In this regard, we propose a new image representation approach for\nunconstrained handwritten alphanumeric characters using sparse concept coded\nTetrolets. Tetrolets, which does not use fixed dyadic square blocks for\nspectral decomposition like conventional wavelets, preserve the localized\nvariations in handwritings by adopting tetrominoes those capture the shape\ngeometry. The sparse concept coding of low entropy Tetrolet representation is\nfound to extract the important hidden information (concept) for superior\npattern discrimination. Large scale experimentation using ten databases in six\ndifferent scripts (Bangla, Devanagari, Odia, English, Arabic and Telugu) has\nbeen performed. The proposed feature representation along with standard\nclassifiers such as random forest, support vector machine (SVM), nearest\nneighbor and modified quadratic discriminant function (MQDF) is found to\nachieve state-of-the-art recognition performance in all the databases, viz.\n99.40% (MNIST); 98.72% and 93.24% (IITBBS); 99.38% and 99.22% (ISI Kolkata).\nThe proposed OCR system is shown to perform better than other sparse based\ntechniques such as PCA, SparsePCA and SparseLDA, as well as better than\nexisting transforms (Wavelet, Slantlet and Stockwell).", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Feature representation in the form of spatio-spectral decomposition is one of\nthe robust techniques adopted in automatic handwritten character recognition\nsystems. In this regard, we propose a new image representation approach for\nunconstrained handwritten alphanumeric characters using sparse concept coded\nTetrolets. Tetrolets, which does not use fixed dyadic square blocks for\nspectral decomposition like conventional wavelets, preserve the localized\nvariations in handwritings by adopting tetrominoes those capture the shape\ngeometry. The sparse concept coding of low entropy Tetrolet representation is\nfound to extract the important hidden information (concept) for superior\npattern discrimination. Large scale experimentation using ten databases in six\ndifferent scripts (Bangla, Devanagari, Odia, English, Arabic and Telugu) has\nbeen performed. The proposed feature representation along with standard\nclassifiers such as random forest, support vector machine (SVM), nearest\nneighbor and modified quadratic discriminant function (MQDF) is found to\nachieve state-of-the-art recognition performance in all the databases, viz.\n99.40% (MNIST); 98.72% and 93.24% (IITBBS); 99.38% and 99.22% (ISI Kolkata).\nThe proposed OCR system is shown to perform better than other sparse based\ntechniques such as PCA, SparsePCA and SparseLDA, as well as better than\nexisting transforms (Wavelet, Slantlet and Stockwell)."}, "authors": ["Kalyan S Dash", "N B Puhan", "G Panda"], "author_detail": {"name": "G Panda"}, "author": "G Panda", "links": [{"href": "http://arxiv.org/abs/2004.01551v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.01551v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "eess.IV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.01551v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.01551v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2009.07435v1", "guidislink": true, "updated": "2020-09-16T02:50:03Z", "updated_parsed": [2020, 9, 16, 2, 50, 3, 2, 260, 0], "published": "2020-09-16T02:50:03Z", "published_parsed": [2020, 9, 16, 2, 50, 3, 2, 260, 0], "title": "A New Approach for Texture based Script Identification At Block Level\n  using Quad Tree Decomposition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A New Approach for Texture based Script Identification At Block Level\n  using Quad Tree Decomposition"}, "summary": "A considerable amount of success has been achieved in developing monolingual\nOCR systems for Indic scripts. But in a country like India, where multi-script\nscenario is prevalent, identifying scripts beforehand becomes obligatory. In\nthis paper, we present the significance of Gabor wavelets filters in extracting\ndirectional energy and entropy distributions for 11 official handwritten\nscripts namely, Bangla, Devanagari, Gujarati, Gurumukhi, Kannada, Malayalam,\nOriya, Tamil, Telugu, Urdu and Roman. The experimentation is conducted at block\nlevel based on a quad-tree decomposition approach and evaluated using six\ndifferent well-known classifiers. Finally, the best identification accuracy of\n96.86% has been achieved by Multi Layer Perceptron (MLP) classifier for 3-fold\ncross validation at level-2 decomposition. The results serve to establish the\nefficacy of the present approach to the classification of handwritten Indic\nscripts", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A considerable amount of success has been achieved in developing monolingual\nOCR systems for Indic scripts. But in a country like India, where multi-script\nscenario is prevalent, identifying scripts beforehand becomes obligatory. In\nthis paper, we present the significance of Gabor wavelets filters in extracting\ndirectional energy and entropy distributions for 11 official handwritten\nscripts namely, Bangla, Devanagari, Gujarati, Gurumukhi, Kannada, Malayalam,\nOriya, Tamil, Telugu, Urdu and Roman. The experimentation is conducted at block\nlevel based on a quad-tree decomposition approach and evaluated using six\ndifferent well-known classifiers. Finally, the best identification accuracy of\n96.86% has been achieved by Multi Layer Perceptron (MLP) classifier for 3-fold\ncross validation at level-2 decomposition. The results serve to establish the\nefficacy of the present approach to the classification of handwritten Indic\nscripts"}, "authors": ["Pawan Kumar Singh", "Supratim Das", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "13 pages, 5 figures, conference", "links": [{"href": "http://arxiv.org/abs/2009.07435v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2009.07435v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2009.07435v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2009.07435v1", "journal_reference": "7th International Conference on Advances in Communication, Network\n  and Computing (CNC), pp. 247-259, 2016", "doi": null}
{"id": "http://arxiv.org/abs/2010.03065v1", "guidislink": true, "updated": "2020-10-06T22:33:58Z", "updated_parsed": [2020, 10, 6, 22, 33, 58, 1, 280, 0], "published": "2020-10-06T22:33:58Z", "published_parsed": [2020, 10, 6, 22, 33, 58, 1, 280, 0], "title": "Anubhuti -- An annotated dataset for emotional analysis of Bengali short\n  stories", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Anubhuti -- An annotated dataset for emotional analysis of Bengali short\n  stories"}, "summary": "Thousands of short stories and articles are being written in many different\nlanguages all around the world today. Bengali, or Bangla, is the second highest\nspoken language in India after Hindi and is the national language of the\ncountry of Bangladesh. This work reports in detail the creation of Anubhuti --\nthe first and largest text corpus for analyzing emotions expressed by writers\nof Bengali short stories. We explain the data collection methods, the manual\nannotation process and the resulting high inter-annotator agreement of the\ndataset due to the linguistic expertise of the annotators and the clear\nmethodology of labelling followed. We also address some of the challenges faced\nin the collection of raw data and annotation process of a low resource language\nlike Bengali. We have verified the performance of our dataset with baseline\nMachine Learning as well as a Deep Learning model for emotion classification\nand have found that these standard models have a high accuracy and relevant\nfeature selection on Anubhuti. In addition, we also explain how this dataset\ncan be of interest to linguists and data analysts to study the flow of emotions\nas expressed by writers of Bengali literature.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Thousands of short stories and articles are being written in many different\nlanguages all around the world today. Bengali, or Bangla, is the second highest\nspoken language in India after Hindi and is the national language of the\ncountry of Bangladesh. This work reports in detail the creation of Anubhuti --\nthe first and largest text corpus for analyzing emotions expressed by writers\nof Bengali short stories. We explain the data collection methods, the manual\nannotation process and the resulting high inter-annotator agreement of the\ndataset due to the linguistic expertise of the annotators and the clear\nmethodology of labelling followed. We also address some of the challenges faced\nin the collection of raw data and annotation process of a low resource language\nlike Bengali. We have verified the performance of our dataset with baseline\nMachine Learning as well as a Deep Learning model for emotion classification\nand have found that these standard models have a high accuracy and relevant\nfeature selection on Anubhuti. In addition, we also explain how this dataset\ncan be of interest to linguists and data analysts to study the flow of emotions\nas expressed by writers of Bengali literature."}, "authors": ["Aditya Pal", "Bhaskar Karn"], "author_detail": {"name": "Bhaskar Karn"}, "author": "Bhaskar Karn", "arxiv_comment": "4 pages, 6 figures", "links": [{"href": "http://arxiv.org/abs/2010.03065v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.03065v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.03065v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.03065v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2010.08066v1", "guidislink": true, "updated": "2020-10-15T23:24:15Z", "updated_parsed": [2020, 10, 15, 23, 24, 15, 3, 289, 0], "published": "2020-10-15T23:24:15Z", "published_parsed": [2020, 10, 15, 23, 24, 15, 3, 289, 0], "title": "TextMage: The Automated Bangla Caption Generator Based On Deep Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "TextMage: The Automated Bangla Caption Generator Based On Deep Learning"}, "summary": "Neural Networks and Deep Learning have seen an upsurge of research in the\npast decade due to the improved results. Generates text from the given image is\na crucial task that requires the combination of both sectors which are computer\nvision and natural language processing in order to understand an image and\nrepresent it using a natural language. However existing works have all been\ndone on a particular lingual domain and on the same set of data. This leads to\nthe systems being developed to perform poorly on images that belong to specific\nlocales' geographical context. TextMage is a system that is capable of\nunderstanding visual scenes that belong to the Bangladeshi geographical context\nand use its knowledge to represent what it understands in Bengali. Hence, we\nhave trained a model on our previously developed and published dataset named\nBanglaLekhaImageCaptions. This dataset contains 9,154 images along with two\nannotations for each image. In order to access performance, the proposed model\nhas been implemented and evaluated.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Neural Networks and Deep Learning have seen an upsurge of research in the\npast decade due to the improved results. Generates text from the given image is\na crucial task that requires the combination of both sectors which are computer\nvision and natural language processing in order to understand an image and\nrepresent it using a natural language. However existing works have all been\ndone on a particular lingual domain and on the same set of data. This leads to\nthe systems being developed to perform poorly on images that belong to specific\nlocales' geographical context. TextMage is a system that is capable of\nunderstanding visual scenes that belong to the Bangladeshi geographical context\nand use its knowledge to represent what it understands in Bengali. Hence, we\nhave trained a model on our previously developed and published dataset named\nBanglaLekhaImageCaptions. This dataset contains 9,154 images along with two\nannotations for each image. In order to access performance, the proposed model\nhas been implemented and evaluated."}, "authors": ["Abrar Hasin Kamal", "Md. Asifuzzaman Jishan", "Nafees Mansoor"], "author_detail": {"name": "Nafees Mansoor"}, "author": "Nafees Mansoor", "arxiv_comment": "5 pages", "links": [{"href": "http://arxiv.org/abs/2010.08066v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.08066v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.08066v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.08066v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.06908v2", "guidislink": true, "updated": "2018-01-28T15:10:48Z", "updated_parsed": [2018, 1, 28, 15, 10, 48, 6, 28, 0], "published": "2017-12-19T13:12:29Z", "published_parsed": [2017, 12, 19, 13, 12, 29, 1, 353, 0], "title": "Cross-language Framework for Word Recognition and Spotting of Indic\n  Scripts", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Cross-language Framework for Word Recognition and Spotting of Indic\n  Scripts"}, "summary": "Handwritten word recognition and spotting of low-resource scripts are\ndifficult as sufficient training data is not available and it is often\nexpensive for collecting data of such scripts. This paper presents a novel\ncross language platform for handwritten word recognition and spotting for such\nlow-resource scripts where training is performed with a sufficiently large\ndataset of an available script (considered as source script) and testing is\ndone on other scripts (considered as target script). Training with one source\nscript and testing with another script to have a reasonable result is not easy\nin handwriting domain due to the complex nature of handwriting variability\namong scripts. Also it is difficult in mapping between source and target\ncharacters when they appear in cursive word images. The proposed Indic cross\nlanguage framework exploits a large resource of dataset for training and uses\nit for recognizing and spotting text of other target scripts where sufficient\namount of training data is not available. Since, Indic scripts are mostly\nwritten in 3 zones, namely, upper, middle and lower, we employ zone-wise\ncharacter (or component) mapping for efficient learning purpose. The\nperformance of our cross-language framework depends on the extent of similarity\nbetween the source and target scripts. Hence, we devise an entropy based script\nsimilarity score using source to target character mapping that will provide a\nfeasibility of cross language transcription. We have tested our approach in\nthree Indic scripts, namely, Bangla, Devanagari and Gurumukhi, and the\ncorresponding results are reported.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten word recognition and spotting of low-resource scripts are\ndifficult as sufficient training data is not available and it is often\nexpensive for collecting data of such scripts. This paper presents a novel\ncross language platform for handwritten word recognition and spotting for such\nlow-resource scripts where training is performed with a sufficiently large\ndataset of an available script (considered as source script) and testing is\ndone on other scripts (considered as target script). Training with one source\nscript and testing with another script to have a reasonable result is not easy\nin handwriting domain due to the complex nature of handwriting variability\namong scripts. Also it is difficult in mapping between source and target\ncharacters when they appear in cursive word images. The proposed Indic cross\nlanguage framework exploits a large resource of dataset for training and uses\nit for recognizing and spotting text of other target scripts where sufficient\namount of training data is not available. Since, Indic scripts are mostly\nwritten in 3 zones, namely, upper, middle and lower, we employ zone-wise\ncharacter (or component) mapping for efficient learning purpose. The\nperformance of our cross-language framework depends on the extent of similarity\nbetween the source and target scripts. Hence, we devise an entropy based script\nsimilarity score using source to target character mapping that will provide a\nfeasibility of cross language transcription. We have tested our approach in\nthree Indic scripts, namely, Bangla, Devanagari and Gurumukhi, and the\ncorresponding results are reported."}, "authors": ["Ayan Kumar Bhunia", "Partha Pratim Roy", "Akash Mohta", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patcog.2018.01.034", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1712.06908v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.06908v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Accepted in Pattern Recognition, Elsevier(2018)", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.06908v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.06908v2", "journal_reference": null, "doi": "10.1016/j.patcog.2018.01.034"}
{"id": "http://arxiv.org/abs/1804.06254v1", "guidislink": true, "updated": "2018-04-17T13:52:59Z", "updated_parsed": [2018, 4, 17, 13, 52, 59, 1, 107, 0], "published": "2018-04-17T13:52:59Z", "published_parsed": [2018, 4, 17, 13, 52, 59, 1, 107, 0], "title": "Synthetic data generation for Indic handwritten text recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Synthetic data generation for Indic handwritten text recognition"}, "summary": "This paper presents a novel approach to generate synthetic dataset for\nhandwritten word recognition systems. It is difficult to recognize handwritten\nscripts for which sufficient training data is not readily available or it may\nbe expensive to collect such data. Hence, it becomes hard to train recognition\nsystems owing to lack of proper dataset. To overcome such problems, synthetic\ndata could be used to create or expand the existing training dataset to improve\nrecognition performance. Any available digital data from online newspaper and\nsuch sources can be used to generate synthetic data. In this paper, we propose\nto add distortion/deformation to digital data in such a way that the underlying\npattern is preserved, so that the image so produced bears a close similarity to\nactual handwritten samples. The images thus produced can be used independently\nto train the system or be combined with natural handwritten data to augment the\noriginal dataset and improve the recognition system. We experimented using\nsynthetic data to improve the recognition accuracy of isolated characters and\nwords. The framework is tested on 2 Indic scripts - Devanagari (Hindi) and\nBengali (Bangla), for numeral, character and word recognition. We have obtained\nencouraging results from the experiment. Finally, the experiment with Latin\ntext verifies the utility of the approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents a novel approach to generate synthetic dataset for\nhandwritten word recognition systems. It is difficult to recognize handwritten\nscripts for which sufficient training data is not readily available or it may\nbe expensive to collect such data. Hence, it becomes hard to train recognition\nsystems owing to lack of proper dataset. To overcome such problems, synthetic\ndata could be used to create or expand the existing training dataset to improve\nrecognition performance. Any available digital data from online newspaper and\nsuch sources can be used to generate synthetic data. In this paper, we propose\nto add distortion/deformation to digital data in such a way that the underlying\npattern is preserved, so that the image so produced bears a close similarity to\nactual handwritten samples. The images thus produced can be used independently\nto train the system or be combined with natural handwritten data to augment the\noriginal dataset and improve the recognition system. We experimented using\nsynthetic data to improve the recognition accuracy of isolated characters and\nwords. The framework is tested on 2 Indic scripts - Devanagari (Hindi) and\nBengali (Bangla), for numeral, character and word recognition. We have obtained\nencouraging results from the experiment. Finally, the experiment with Latin\ntext verifies the utility of the approach."}, "authors": ["Partha Pratim Roy", "Akash Mohta", "Bidyut B. Chaudhuri"], "author_detail": {"name": "Bidyut B. Chaudhuri"}, "author": "Bidyut B. Chaudhuri", "links": [{"href": "http://arxiv.org/abs/1804.06254v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1804.06254v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1804.06254v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1804.06254v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1807.06772v1", "guidislink": true, "updated": "2018-07-18T04:29:20Z", "updated_parsed": [2018, 7, 18, 4, 29, 20, 2, 199, 0], "published": "2018-07-18T04:29:20Z", "published_parsed": [2018, 7, 18, 4, 29, 20, 2, 199, 0], "title": "Bag-of-Visual-Words for Signature-Based Multi-Script Document Retrieval", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bag-of-Visual-Words for Signature-Based Multi-Script Document Retrieval"}, "summary": "An end-to-end architecture for multi-script document retrieval using\nhandwritten signatures is proposed in this paper. The user supplies a query\nsignature sample and the system exclusively returns a set of documents that\ncontain the query signature. In the first stage, a component-wise\nclassification technique separates the potential signature components from all\nother components. A bag-of-visual-words powered by SIFT descriptors in a\npatch-based framework is proposed to compute the features and a Support Vector\nMachine (SVM)-based classifier was used to separate signatures from the\ndocuments. In the second stage, features from the foreground (i.e. signature\nstrokes) and the background spatial information (i.e. background loops,\nreservoirs etc.) were combined to characterize the signature object to match\nwith the query signature. Finally, three distance measures were used to match a\nquery signature with the signature present in target documents for retrieval.\nThe `Tobacco' document database and an Indian script database containing 560\ndocuments of Devanagari (Hindi) and Bangla scripts were used for the\nperformance evaluation. The proposed system was also tested on noisy documents\nand promising results were obtained. A comparative study shows that the\nproposed method outperforms the state-of-the-art approaches.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An end-to-end architecture for multi-script document retrieval using\nhandwritten signatures is proposed in this paper. The user supplies a query\nsignature sample and the system exclusively returns a set of documents that\ncontain the query signature. In the first stage, a component-wise\nclassification technique separates the potential signature components from all\nother components. A bag-of-visual-words powered by SIFT descriptors in a\npatch-based framework is proposed to compute the features and a Support Vector\nMachine (SVM)-based classifier was used to separate signatures from the\ndocuments. In the second stage, features from the foreground (i.e. signature\nstrokes) and the background spatial information (i.e. background loops,\nreservoirs etc.) were combined to characterize the signature object to match\nwith the query signature. Finally, three distance measures were used to match a\nquery signature with the signature present in target documents for retrieval.\nThe `Tobacco' document database and an Indian script database containing 560\ndocuments of Devanagari (Hindi) and Bangla scripts were used for the\nperformance evaluation. The proposed system was also tested on noisy documents\nand promising results were obtained. A comparative study shows that the\nproposed method outperforms the state-of-the-art approaches."}, "authors": ["Ranju Mandal", "Partha Pratim Roy", "Umapada Pal", "Michael Blumenstein"], "author_detail": {"name": "Michael Blumenstein"}, "author": "Michael Blumenstein", "links": [{"href": "http://arxiv.org/abs/1807.06772v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1807.06772v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1807.06772v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1807.06772v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1811.08816v2", "guidislink": true, "updated": "2019-07-22T11:02:06Z", "updated_parsed": [2019, 7, 22, 11, 2, 6, 0, 203, 0], "published": "2018-11-21T16:36:08Z", "published_parsed": [2018, 11, 21, 16, 36, 8, 2, 325, 0], "title": "Learning cross-lingual phonological and orthagraphic adaptations: a case\n  study in improving neural machine translation between low-resource languages", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Learning cross-lingual phonological and orthagraphic adaptations: a case\n  study in improving neural machine translation between low-resource languages"}, "summary": "Out-of-vocabulary (OOV) words can pose serious challenges for machine\ntranslation (MT) tasks, and in particular, for low-resource language (LRL)\npairs, i.e., language pairs for which few or no parallel corpora exist. Our\nwork adapts variants of seq2seq models to perform transduction of such words\nfrom Hindi to Bhojpuri (an LRL instance), learning from a set of cognate pairs\nbuilt from a bilingual dictionary of Hindi--Bhojpuri words. We demonstrate that\nour models can be effectively used for language pairs that have limited\nparallel corpora; our models work at the character level to grasp phonetic and\northographic similarities across multiple types of word adaptations, whether\nsynchronic or diachronic, loan words or cognates. We describe the training\naspects of several character level NMT systems that we adapted to this task and\ncharacterize their typical errors. Our method improves BLEU score by 6.3 on the\nHindi-to-Bhojpuri translation task. Further, we show that such transductions\ncan generalize well to other languages by applying it successfully to Hindi --\nBangla cognate pairs. Our work can be seen as an important step in the process\nof: (i) resolving the OOV words problem arising in MT tasks, (ii) creating\neffective parallel corpora for resource-constrained languages, and (iii)\nleveraging the enhanced semantic knowledge captured by word-level embeddings to\nperform character-level tasks.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Out-of-vocabulary (OOV) words can pose serious challenges for machine\ntranslation (MT) tasks, and in particular, for low-resource language (LRL)\npairs, i.e., language pairs for which few or no parallel corpora exist. Our\nwork adapts variants of seq2seq models to perform transduction of such words\nfrom Hindi to Bhojpuri (an LRL instance), learning from a set of cognate pairs\nbuilt from a bilingual dictionary of Hindi--Bhojpuri words. We demonstrate that\nour models can be effectively used for language pairs that have limited\nparallel corpora; our models work at the character level to grasp phonetic and\northographic similarities across multiple types of word adaptations, whether\nsynchronic or diachronic, loan words or cognates. We describe the training\naspects of several character level NMT systems that we adapted to this task and\ncharacterize their typical errors. Our method improves BLEU score by 6.3 on the\nHindi-to-Bhojpuri translation task. Further, we show that such transductions\ncan generalize well to other languages by applying it successfully to Hindi --\nBangla cognate pairs. Our work can be seen as an important step in the process\nof: (i) resolving the OOV words problem arising in MT tasks, (ii) creating\neffective parallel corpora for resource-constrained languages, and (iii)\nleveraging the enhanced semantic knowledge captured by word-level embeddings to\nperform character-level tasks."}, "authors": ["Saurav Jha", "Akhilesh Sudhakar", "Anil Kumar Singh"], "author_detail": {"name": "Anil Kumar Singh"}, "author": "Anil Kumar Singh", "arxiv_comment": "47 pages, 4 figures, 21 tables (including Appendices)", "links": [{"href": "http://arxiv.org/abs/1811.08816v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1811.08816v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1811.08816v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1811.08816v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2012.14353v1", "guidislink": true, "updated": "2020-12-28T16:46:03Z", "updated_parsed": [2020, 12, 28, 16, 46, 3, 0, 363, 0], "published": "2020-12-28T16:46:03Z", "published_parsed": [2020, 12, 28, 16, 46, 3, 0, 363, 0], "title": "DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced\n  Bengali Language", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced\n  Bengali Language"}, "summary": "Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices, but also\nenables people to express anti-social behavior like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behavior analysis, by predicting the\ncontexts mostly for highly-resourced languages like English. However, some\nlanguages such as Bengali are under-resourced that lack of computational\nresources for natural language processing(NLP). In this paper, we propose an\nexplainable approach for hate speech detection from under-resourced Bengali\nlanguage, which we called DeepHateExplainer. In our approach, Bengali texts are\nfirst comprehensively preprocessed, before classifying them into political,\npersonal, geopolitical, and religious hates, by employing neural ensemble of\ndifferent transformer-based neural architectures(i.e., monolingual Bangla\nBERT-base, multilingual BERT-cased and uncased, and XLM-RoBERTa), followed by\nidentifying important terms with sensitivity analysis and layer-wise relevance\npropagation(LRP) to provide human-interpretable explanations. Evaluations\nagainst several machine learning~(linear and tree-based models) and deep neural\nnetworks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines\nyield F1 scores of 84%, 90%, 88%, and 88%, for political, personal,\ngeopolitical, and religious hates, respectively, during 3-fold cross-validation\ntests.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices, but also\nenables people to express anti-social behavior like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behavior analysis, by predicting the\ncontexts mostly for highly-resourced languages like English. However, some\nlanguages such as Bengali are under-resourced that lack of computational\nresources for natural language processing(NLP). In this paper, we propose an\nexplainable approach for hate speech detection from under-resourced Bengali\nlanguage, which we called DeepHateExplainer. In our approach, Bengali texts are\nfirst comprehensively preprocessed, before classifying them into political,\npersonal, geopolitical, and religious hates, by employing neural ensemble of\ndifferent transformer-based neural architectures(i.e., monolingual Bangla\nBERT-base, multilingual BERT-cased and uncased, and XLM-RoBERTa), followed by\nidentifying important terms with sensitivity analysis and layer-wise relevance\npropagation(LRP) to provide human-interpretable explanations. Evaluations\nagainst several machine learning~(linear and tree-based models) and deep neural\nnetworks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines\nyield F1 scores of 84%, 90%, 88%, and 88%, for political, personal,\ngeopolitical, and religious hates, respectively, during 3-fold cross-validation\ntests."}, "authors": ["Md. Rezaul Karim", "Sumon Kanti Dey", "Bharathi Raja Chakravarthi"], "author_detail": {"name": "Bharathi Raja Chakravarthi"}, "author": "Bharathi Raja Chakravarthi", "arxiv_comment": "Extended version of this paper is currently under review in the IEEE\n  Access journal", "links": [{"href": "http://arxiv.org/abs/2012.14353v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2012.14353v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2012.14353v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2012.14353v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1204.1198v1", "guidislink": true, "updated": "2012-04-05T12:28:11Z", "updated_parsed": [2012, 4, 5, 12, 28, 11, 3, 96, 0], "published": "2012-04-05T12:28:11Z", "published_parsed": [2012, 4, 5, 12, 28, 11, 3, 96, 0], "title": "A Complete Workflow for Development of Bangla OCR", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Complete Workflow for Development of Bangla OCR"}, "summary": "Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Developing a Bangla OCR requires bunch of algorithm and methods. There were\nmany effort went on for developing a Bangla OCR. But all of them failed to\nprovide an error free Bangla OCR. Each of them has some lacking. We discussed\nabout the problem scope of currently existing Bangla OCR's. In this paper, we\npresent the basic steps required for developing a Bangla OCR and a complete\nworkflow for development of a Bangla OCR with mentioning all the possible\nalgorithms required."}, "authors": ["Farjana Yeasmin Omee", "Shiam Shabbir Himel", "Md. Abu Naser Bikas"], "author_detail": {"name": "Md. Abu Naser Bikas"}, "author": "Md. Abu Naser Bikas", "links": [{"href": "http://arxiv.org/abs/1204.1198v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1204.1198v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1204.1198v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1204.1198v1", "arxiv_comment": null, "journal_reference": "International Journal of Computer Applications, Volume 21, No.9,\n  May 2011", "doi": null}
{"id": "http://arxiv.org/abs/1009.4586v1", "guidislink": true, "updated": "2010-09-23T11:42:41Z", "updated_parsed": [2010, 9, 23, 11, 42, 41, 3, 266, 0], "published": "2010-09-23T11:42:41Z", "published_parsed": [2010, 9, 23, 11, 42, 41, 3, 266, 0], "title": "Optimal Bangla Keyboard Layout using Association Rule of Data Mining", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Optimal Bangla Keyboard Layout using Association Rule of Data Mining"}, "summary": "In this paper we present an optimal Bangla Keyboard Layout, which distributes\nthe load equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Finally, we propose a Bangla Keyboard Layout. Experimental results on\nseveral keyboard layout shows the effectiveness of the proposed approach with\nbetter performance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper we present an optimal Bangla Keyboard Layout, which distributes\nthe load equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Finally, we propose a Bangla Keyboard Layout. Experimental results on\nseveral keyboard layout shows the effectiveness of the proposed approach with\nbetter performance."}, "authors": ["Md. Hijbul Alam", "Abdul Kadar Muhammad Masum", "Mohammad Mahadi Hassan", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "3 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4586v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4586v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4586v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4586v1", "journal_reference": "Proc. 7th International Conference on Computer and Information\n  Technology (ICCIT 2004), Dhaka, Bangladesh, pp. 679-681, Dec. 2004", "doi": null}
{"id": "http://arxiv.org/abs/1703.10661v1", "guidislink": true, "updated": "2017-02-22T07:57:14Z", "updated_parsed": [2017, 2, 22, 7, 57, 14, 2, 53, 0], "published": "2017-02-22T07:57:14Z", "published_parsed": [2017, 2, 22, 7, 57, 14, 2, 53, 0], "title": "BanglaLekha-Isolated: A Comprehensive Bangla Handwritten Character\n  Dataset", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaLekha-Isolated: A Comprehensive Bangla Handwritten Character\n  Dataset"}, "summary": "Bangla handwriting recognition is becoming a very important issue nowadays.\nIt is potentially a very important task specially for Bangla speaking\npopulation of Bangladesh and West Bengal. By keeping that in our mind we are\nintroducing a comprehensive Bangla handwritten character dataset named\nBanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic\ncharacters and compound characters. This dataset was collected from multiple\ngeographical location within Bangladesh and includes sample collected from a\nvariety of aged groups. This dataset can also be used for other classification\nproblems i.e: gender, age, district. This is the largest dataset on Bangla\nhandwritten characters yet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla handwriting recognition is becoming a very important issue nowadays.\nIt is potentially a very important task specially for Bangla speaking\npopulation of Bangladesh and West Bengal. By keeping that in our mind we are\nintroducing a comprehensive Bangla handwritten character dataset named\nBanglaLekha-Isolated. This dataset contains Bangla handwritten numerals, basic\ncharacters and compound characters. This dataset was collected from multiple\ngeographical location within Bangladesh and includes sample collected from a\nvariety of aged groups. This dataset can also be used for other classification\nproblems i.e: gender, age, district. This is the largest dataset on Bangla\nhandwritten characters yet."}, "authors": ["Mithun Biswas", "Rafiqul Islam", "Gautam Kumar Shom", "Md Shopon", "Nabeel Mohammed", "Sifat Momen", "Md Anowarul Abedin"], "author_detail": {"name": "Md Anowarul Abedin"}, "author": "Md Anowarul Abedin", "arxiv_comment": "Bangla Handwriting Dataset, OCR", "links": [{"href": "http://arxiv.org/abs/1703.10661v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1703.10661v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1703.10661v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1703.10661v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.07955v1", "guidislink": true, "updated": "2017-01-27T06:30:21Z", "updated_parsed": [2017, 1, 27, 6, 30, 21, 4, 27, 0], "published": "2017-01-27T06:30:21Z", "published_parsed": [2017, 1, 27, 6, 30, 21, 4, 27, 0], "title": "Statistical Analysis on Bangla Newspaper Data to Extract Trending Topic\n  and Visualize Its Change Over Time", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Statistical Analysis on Bangla Newspaper Data to Extract Trending Topic\n  and Visualize Its Change Over Time"}, "summary": "Trending topic of newspapers is an indicator to understand the situation of a\ncountry and also a way to evaluate the particular newspaper. This paper\nrepresents a model describing few techniques to select trending topics from\nBangla Newspaper. Topics that are discussed more frequently than other in\nBangla newspaper will be marked and how a very famous topic loses its\nimportance with the change of time and another topic takes its place will be\ndemonstrated. Data from two popular Bangla Newspaper with date and time were\ncollected. Statistical analysis was performed after on these data after\npreprocessing. Popular and most used keywords were extracted from the stream of\nBangla keyword with this analysis. This model can also cluster category wise\nnews trend or a list of news trend in daily or weekly basis with enough data. A\npattern can be found on their news trend too. Comparison among past news trend\nof Bangla newspapers will give a visualization of the situation of Bangladesh.\nThis visualization will be helpful to predict future trending topics of Bangla\nNewspaper.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Trending topic of newspapers is an indicator to understand the situation of a\ncountry and also a way to evaluate the particular newspaper. This paper\nrepresents a model describing few techniques to select trending topics from\nBangla Newspaper. Topics that are discussed more frequently than other in\nBangla newspaper will be marked and how a very famous topic loses its\nimportance with the change of time and another topic takes its place will be\ndemonstrated. Data from two popular Bangla Newspaper with date and time were\ncollected. Statistical analysis was performed after on these data after\npreprocessing. Popular and most used keywords were extracted from the stream of\nBangla keyword with this analysis. This model can also cluster category wise\nnews trend or a list of news trend in daily or weekly basis with enough data. A\npattern can be found on their news trend too. Comparison among past news trend\nof Bangla newspapers will give a visualization of the situation of Bangladesh.\nThis visualization will be helpful to predict future trending topics of Bangla\nNewspaper."}, "authors": ["Syed Mehedi Hasan Nirob", "Md. Kazi Nayeem", "Md. Saiful Islam"], "author_detail": {"name": "Md. Saiful Islam"}, "author": "Md. Saiful Islam", "arxiv_comment": "8 pages", "links": [{"href": "http://arxiv.org/abs/1701.07955v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.07955v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.07955v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.07955v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2005.02155v2", "guidislink": true, "updated": "2020-05-06T07:59:45Z", "updated_parsed": [2020, 5, 6, 7, 59, 45, 2, 127, 0], "published": "2020-04-29T06:38:12Z", "published_parsed": [2020, 4, 29, 6, 38, 12, 2, 120, 0], "title": "MatriVasha: A Multipurpose Comprehensive Database for Bangla Handwritten\n  Compound Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "MatriVasha: A Multipurpose Comprehensive Database for Bangla Handwritten\n  Compound Characters"}, "summary": "At present, recognition of the Bangla handwriting compound character has been\nan essential issue for many years. In recent years there have been\napplication-based researches in machine learning, and deep learning, which is\ngained interest, and most notably is handwriting recognition because it has a\ntremendous application such as Bangla OCR. MatrriVasha, the project which can\nrecognize Bangla, handwritten several compound characters. Currently, compound\ncharacter recognition is an important topic due to its variant application, and\nhelps to create old forms, and information digitization with reliability. But\nunfortunately, there is a lack of a comprehensive dataset that can categorize\nall types of Bangla compound characters. MatrriVasha is an attempt to align\ncompound character, and it's challenging because each person has a unique style\nof writing shapes. After all, MatrriVasha has proposed a dataset that intends\nto recognize Bangla 120(one hundred twenty) compound characters that consist of\n2552(two thousand five hundred fifty-two) isolated handwritten characters\nwritten unique writers which were collected from within Bangladesh. This\ndataset faced problems in terms of the district, age, and gender-based written\nrelated research because the samples were collected that includes a verity of\nthe district, age group, and the equal number of males, and females. As of now,\nour proposed dataset is so far the most extensive dataset for Bangla compound\ncharacters. It is intended to frame the acknowledgment technique for\nhandwritten Bangla compound character. In the future, this dataset will be made\npublicly available to help to widen the research.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "At present, recognition of the Bangla handwriting compound character has been\nan essential issue for many years. In recent years there have been\napplication-based researches in machine learning, and deep learning, which is\ngained interest, and most notably is handwriting recognition because it has a\ntremendous application such as Bangla OCR. MatrriVasha, the project which can\nrecognize Bangla, handwritten several compound characters. Currently, compound\ncharacter recognition is an important topic due to its variant application, and\nhelps to create old forms, and information digitization with reliability. But\nunfortunately, there is a lack of a comprehensive dataset that can categorize\nall types of Bangla compound characters. MatrriVasha is an attempt to align\ncompound character, and it's challenging because each person has a unique style\nof writing shapes. After all, MatrriVasha has proposed a dataset that intends\nto recognize Bangla 120(one hundred twenty) compound characters that consist of\n2552(two thousand five hundred fifty-two) isolated handwritten characters\nwritten unique writers which were collected from within Bangladesh. This\ndataset faced problems in terms of the district, age, and gender-based written\nrelated research because the samples were collected that includes a verity of\nthe district, age group, and the equal number of males, and females. As of now,\nour proposed dataset is so far the most extensive dataset for Bangla compound\ncharacters. It is intended to frame the acknowledgment technique for\nhandwritten Bangla compound character. In the future, this dataset will be made\npublicly available to help to widen the research."}, "authors": ["Jannatul Ferdous", "Suvrajit Karmaker", "A K M Shahariar Azad Rabby", "Syed Akhter Hossain"], "author_detail": {"name": "Syed Akhter Hossain"}, "author": "Syed Akhter Hossain", "arxiv_comment": "19 fig, 2 table", "links": [{"href": "http://arxiv.org/abs/2005.02155v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2005.02155v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2005.02155v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2005.02155v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1201.2010v1", "guidislink": true, "updated": "2012-01-10T10:33:18Z", "updated_parsed": [2012, 1, 10, 10, 33, 18, 1, 10, 0], "published": "2012-01-10T10:33:18Z", "published_parsed": [2012, 1, 10, 10, 33, 18, 1, 10, 0], "title": "Recognizing Bangla Grammar using Predictive Parser", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recognizing Bangla Grammar using Predictive Parser"}, "summary": "We describe a Context Free Grammar (CFG) for Bangla language and hence we\npropose a Bangla parser based on the grammar. Our approach is very much general\nto apply in Bangla Sentences and the method is well accepted for parsing a\nlanguage of a grammar. The proposed parser is a predictive parser and we\nconstruct the parse table for recognizing Bangla grammar. Using the parse table\nwe recognize syntactical mistakes of Bangla sentences when there is no entry\nfor a terminal in the parse table. If a natural language can be successfully\nparsed then grammar checking from this language becomes possible. The proposed\nscheme is based on Top down parsing method and we have avoided the left\nrecursion of the CFG using the idea of left factoring.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "We describe a Context Free Grammar (CFG) for Bangla language and hence we\npropose a Bangla parser based on the grammar. Our approach is very much general\nto apply in Bangla Sentences and the method is well accepted for parsing a\nlanguage of a grammar. The proposed parser is a predictive parser and we\nconstruct the parse table for recognizing Bangla grammar. Using the parse table\nwe recognize syntactical mistakes of Bangla sentences when there is no entry\nfor a terminal in the parse table. If a natural language can be successfully\nparsed then grammar checking from this language becomes possible. The proposed\nscheme is based on Top down parsing method and we have avoided the left\nrecursion of the CFG using the idea of left factoring."}, "authors": ["K. M. Azharul Hasan", "Al-Mahmud", "Amit Mondal", "Amit Saha"], "author_detail": {"name": "Amit Saha"}, "author": "Amit Saha", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijcsit.2011.3605", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1201.2010v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1201.2010v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "13 pages, 13 figures", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1201.2010v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1201.2010v1", "journal_reference": null, "doi": "10.5121/ijcsit.2011.3605"}
{"id": "http://arxiv.org/abs/1203.0876v1", "guidislink": true, "updated": "2012-03-05T12:06:54Z", "updated_parsed": [2012, 3, 5, 12, 6, 54, 0, 65, 0], "published": "2012-03-05T12:06:54Z", "published_parsed": [2012, 3, 5, 12, 6, 54, 0, 65, 0], "title": "An MLP based Approach for Recognition of Handwritten `Bangla' Numerals", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An MLP based Approach for Recognition of Handwritten `Bangla' Numerals"}, "summary": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased pattern classifier for recognition of handwritten Bangla digits using a\n76 element feature vector. Bangla is the second most popular script and\nlanguage in the Indian subcontinent and the fifth most popular language in the\nworld. The feature set developed for representing handwritten Bangla numerals\nhere includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. On experimentation with a database of 6000 samples, the technique\nyields an average recognition rate of 96.67% evaluated after three-fold cross\nvalidation of results. It is useful for applications related to OCR of\nhandwritten Bangla Digit and can also be extended to include OCR of handwritten\ncharacters of Bangla alphabet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased pattern classifier for recognition of handwritten Bangla digits using a\n76 element feature vector. Bangla is the second most popular script and\nlanguage in the Indian subcontinent and the fifth most popular language in the\nworld. The feature set developed for representing handwritten Bangla numerals\nhere includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. On experimentation with a database of 6000 samples, the technique\nyields an average recognition rate of 96.67% evaluated after three-fold cross\nvalidation of results. It is useful for applications related to OCR of\nhandwritten Bangla Digit and can also be extended to include OCR of handwritten\ncharacters of Bangla alphabet."}, "authors": ["Subhadip Basu", "Nibaran Das", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1203.0876v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.0876v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.0876v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.0876v1", "arxiv_comment": null, "journal_reference": "Proc. 2nd Indian International Conference on Artificial\n  Intelligence, pp. 407-417, Dec. 2005, Pune", "doi": null}
{"id": "http://arxiv.org/abs/1203.0882v1", "guidislink": true, "updated": "2012-03-05T12:22:23Z", "updated_parsed": [2012, 3, 5, 12, 22, 23, 0, 65, 0], "published": "2012-03-05T12:22:23Z", "published_parsed": [2012, 3, 5, 12, 22, 23, 0, 65, 0], "title": "Handwritten Bangla Alphabet Recognition using an MLP Based Classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Alphabet Recognition using an MLP Based Classifier"}, "summary": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased classifier for recognition of handwritten Bangla alphabet using a 76\nelement feature set Bangla is the second most popular script and language in\nthe Indian subcontinent and the fifth most popular language in the world. The\nfeature set developed for representing handwritten characters of Bangla\nalphabet includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. Recognition performances of the MLP designed to work with this\nfeature set are experimentally observed as 86.46% and 75.05% on the samples of\nthe training and the test sets respectively. The work has useful application in\nthe development of a complete OCR system for handwritten Bangla text.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presented here involves the design of a Multi Layer Perceptron (MLP)\nbased classifier for recognition of handwritten Bangla alphabet using a 76\nelement feature set Bangla is the second most popular script and language in\nthe Indian subcontinent and the fifth most popular language in the world. The\nfeature set developed for representing handwritten characters of Bangla\nalphabet includes 24 shadow features, 16 centroid features and 36 longest-run\nfeatures. Recognition performances of the MLP designed to work with this\nfeature set are experimentally observed as 86.46% and 75.05% on the samples of\nthe training and the test sets respectively. The work has useful application in\nthe development of a complete OCR system for handwritten Bangla text."}, "authors": ["Subhadip Basu", "Nibaran Das", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1203.0882v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1203.0882v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1203.0882v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1203.0882v1", "arxiv_comment": null, "journal_reference": "Proc. of the 2nd National Conf. on Computer Processing of Bangla,\n  pp. 285-291, Feb-2005, Dhaka", "doi": null}
{"id": "http://arxiv.org/abs/1410.2045v1", "guidislink": true, "updated": "2014-10-08T10:01:47Z", "updated_parsed": [2014, 10, 8, 10, 1, 47, 2, 281, 0], "published": "2014-10-08T10:01:47Z", "published_parsed": [2014, 10, 8, 10, 1, 47, 2, 281, 0], "title": "Supervised learning Methods for Bangla Web Document Categorization", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Supervised learning Methods for Bangla Web Document Categorization"}, "summary": "This paper explores the use of machine learning approaches, or more\nspecifically, four supervised learning Methods, namely Decision Tree(C 4.5),\nK-Nearest Neighbour (KNN), Na\\\"ive Bays (NB), and Support Vector Machine (SVM)\nfor categorization of Bangla web documents. This is a task of automatically\nsorting a set of documents into categories from a predefined set. Whereas a\nwide range of methods have been applied to English text categorization,\nrelatively few studies have been conducted on Bangla language text\ncategorization. Hence, we attempt to analyze the efficiency of those four\nmethods for categorization of Bangla documents. In order to validate, Bangla\ncorpus from various websites has been developed and used as examples for the\nexperiment. For Bangla, empirical results support that all four methods produce\nsatisfactory performance with SVM attaining good result in terms of high\ndimensional and relatively noisy document feature vectors.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper explores the use of machine learning approaches, or more\nspecifically, four supervised learning Methods, namely Decision Tree(C 4.5),\nK-Nearest Neighbour (KNN), Na\\\"ive Bays (NB), and Support Vector Machine (SVM)\nfor categorization of Bangla web documents. This is a task of automatically\nsorting a set of documents into categories from a predefined set. Whereas a\nwide range of methods have been applied to English text categorization,\nrelatively few studies have been conducted on Bangla language text\ncategorization. Hence, we attempt to analyze the efficiency of those four\nmethods for categorization of Bangla documents. In order to validate, Bangla\ncorpus from various websites has been developed and used as examples for the\nexperiment. For Bangla, empirical results support that all four methods produce\nsatisfactory performance with SVM attaining good result in terms of high\ndimensional and relatively noisy document feature vectors."}, "authors": ["Ashis Kumar Mandal", "Rikta Sen"], "author_detail": {"name": "Rikta Sen"}, "author": "Rikta Sen", "arxiv_comment": "13 pages, International Journal of Artificial Intelligence &\n  Applications (IJAIA), Vol. 5, No. 5, September 2014", "links": [{"href": "http://arxiv.org/abs/1410.2045v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.2045v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.2045v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.2045v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1009.4982v1", "guidislink": true, "updated": "2010-09-25T06:55:27Z", "updated_parsed": [2010, 9, 25, 6, 55, 27, 5, 268, 0], "published": "2010-09-25T06:55:27Z", "published_parsed": [2010, 9, 25, 6, 55, 27, 5, 268, 0], "title": "Optimal Bangla Keyboard Layout using Data Mining Technique", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Optimal Bangla Keyboard Layout using Data Mining Technique"}, "summary": "This paper presents an optimal Bangla Keyboard Layout, which distributes the\nload equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Experimental results on several data show the effectiveness of the\nproposed approach with better performance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=0&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents an optimal Bangla Keyboard Layout, which distributes the\nload equally on both hands so that maximizing the ease and minimizing the\neffort. Bangla alphabet has a large number of letters, for this it is difficult\nto type faster using Bangla keyboard. Our proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Here we use the\nassociation rule of data mining to distribute the Bangla characters in the\nkeyboard. First, we analyze the frequencies of data consisting of monograph,\ndigraph and trigraph, which are derived from data wire-house, and then used\nassociation rule of data mining to distribute the Bangla characters in the\nlayout. Experimental results on several data show the effectiveness of the\nproposed approach with better performance."}, "authors": ["S. M. Kamruzzaman", "Md. Hijbul Alam", "Abdul Kadar Muhammad Masum", "Md. Mahadi Hassan"], "author_detail": {"name": "Md. Mahadi Hassan"}, "author": "Md. Mahadi Hassan", "arxiv_comment": "9 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4982v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4982v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4982v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4982v1", "journal_reference": "Proc. International Conference on Information and Communication\n  Technology in Management (ICTM 2005), Multimedia University, Malaysia, May\n  2005", "doi": null}
{"id": "http://arxiv.org/abs/1009.5048v1", "guidislink": true, "updated": "2010-09-26T02:09:41Z", "updated_parsed": [2010, 9, 26, 2, 9, 41, 6, 269, 0], "published": "2010-09-26T02:09:41Z", "published_parsed": [2010, 9, 26, 2, 9, 41, 6, 269, 0], "title": "The Most Advantageous Bangla Keyboard Layout Using Data Mining Technique", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The Most Advantageous Bangla Keyboard Layout Using Data Mining Technique"}, "summary": "Bangla alphabet has a large number of letters, for this it is complicated to\ntype faster using Bangla keyboard. The proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Association rule\nof data mining to distribute the Bangla characters in the keyboard is used\nhere. The frequencies of data consisting of monograph, digraph and trigraph are\nanalyzed, which are derived from data wire-house, and then used association\nrule of data mining to distribute the Bangla characters in the layout.\nExperimental results on several data show the effectiveness of the proposed\napproach with better performance. This paper presents an optimal Bangla\nKeyboard Layout, which distributes the load equally on both hands so that\nmaximizing the ease and minimizing the effort.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla alphabet has a large number of letters, for this it is complicated to\ntype faster using Bangla keyboard. The proposed keyboard will maximize the\nspeed of operator as they can type with both hands parallel. Association rule\nof data mining to distribute the Bangla characters in the keyboard is used\nhere. The frequencies of data consisting of monograph, digraph and trigraph are\nanalyzed, which are derived from data wire-house, and then used association\nrule of data mining to distribute the Bangla characters in the layout.\nExperimental results on several data show the effectiveness of the proposed\napproach with better performance. This paper presents an optimal Bangla\nKeyboard Layout, which distributes the load equally on both hands so that\nmaximizing the ease and minimizing the effort."}, "authors": ["Abdul Kadar Muhammad Masum", "Mohammad Mahadi Hassan", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "10 Pages, International Journal", "links": [{"href": "http://arxiv.org/abs/1009.5048v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.5048v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.5048v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.5048v1", "journal_reference": "Journal of Computer Science, IBAIS University, Dkhaka, Bangladesh,\n  Vol. 1, No. 2, Dec. 2007", "doi": null}
{"id": "http://arxiv.org/abs/1002.4040v2", "guidislink": true, "updated": "2010-02-23T06:44:32Z", "updated_parsed": [2010, 2, 23, 6, 44, 32, 1, 54, 0], "published": "2010-02-22T02:58:49Z", "published_parsed": [2010, 2, 22, 2, 58, 49, 0, 53, 0], "title": "Handwritten Bangla Basic and Compound character recognition using MLP\n  and SVM classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Basic and Compound character recognition using MLP\n  and SVM classifier"}, "summary": "A novel approach for recognition of handwritten compound Bangla characters,\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\nto English like Roman script, one of the major stumbling blocks in Optical\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\ncharacter classes, there are nearly 160 complex shaped compound character\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\ncharacters with a suitably designed feature set is a challenging problem.\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\na large varieties of complex shaped characters, some of which have close\nresemblance, makes the problem of OCR of handwritten Bangla characters more\ndifficult. Considering the complexity of the problem, the present approach\nmakes an attempt to identify compound character classes from most frequently to\nless frequently occurred ones, i.e., in order of importance. This is to develop\na frame work for incrementally increasing the number of learned classes of\ncompound characters from more frequently occurred ones to less frequently\noccurred ones along with Basic characters. On experimentation, the technique is\nobserved produce an average recognition rate of 79.25 after three fold cross\nvalidation of data with future scope of improvement and extension.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A novel approach for recognition of handwritten compound Bangla characters,\nalong with the Basic characters of Bangla alphabet, is presented here. Compared\nto English like Roman script, one of the major stumbling blocks in Optical\nCharacter Recognition (OCR) of handwritten Bangla script is the large number of\ncomplex shaped character classes of Bangla alphabet. In addition to 50 basic\ncharacter classes, there are nearly 160 complex shaped compound character\nclasses in Bangla alphabet. Dealing with such a large varieties of handwritten\ncharacters with a suitably designed feature set is a challenging problem.\nUncertainty and imprecision are inherent in handwritten script. Moreover, such\na large varieties of complex shaped characters, some of which have close\nresemblance, makes the problem of OCR of handwritten Bangla characters more\ndifficult. Considering the complexity of the problem, the present approach\nmakes an attempt to identify compound character classes from most frequently to\nless frequently occurred ones, i.e., in order of importance. This is to develop\na frame work for incrementally increasing the number of learned classes of\ncompound characters from more frequently occurred ones to less frequently\noccurred ones along with Basic characters. On experimentation, the technique is\nobserved produce an average recognition rate of 79.25 after three fold cross\nvalidation of data with future scope of improvement and extension."}, "authors": ["Nibaran Das", "Bindaban Das", "Ram Sarkar", "Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/1002.4040v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.4040v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.4040v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1002.4040v2", "arxiv_comment": null, "journal_reference": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null}
{"id": "http://arxiv.org/abs/1410.0478v1", "guidislink": true, "updated": "2014-10-02T08:26:38Z", "updated_parsed": [2014, 10, 2, 8, 26, 38, 3, 275, 0], "published": "2014-10-02T08:26:38Z", "published_parsed": [2014, 10, 2, 8, 26, 38, 3, 275, 0], "title": "Recognition of Handwritten Bangla Basic Characters and Digits using\n  Convex Hull based Feature Set", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recognition of Handwritten Bangla Basic Characters and Digits using\n  Convex Hull based Feature Set"}, "summary": "In dealing with the problem of recognition of handwritten character patterns\nof varying shapes and sizes, selection of a proper feature set is important to\nachieve high recognition performance. The current research aims to evaluate the\nperformance of the convex hull based feature set, i.e. 125 features in all\ncomputed over different bays attributes of the convex hull of a pattern, for\neffective recognition of isolated handwritten Bangla basic characters and\ndigits. On experimentation with a database of 10000 samples, the maximum\nrecognition rate of 76.86% is observed for handwritten Bangla characters. For\nBangla numerals the maximum success rate of 99.45%. is achieved on a database\nof 12000 sample. The current work validates the usefulness of a new kind of\nfeature set for recognition of handwritten Bangla basic characters and\nnumerals.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In dealing with the problem of recognition of handwritten character patterns\nof varying shapes and sizes, selection of a proper feature set is important to\nachieve high recognition performance. The current research aims to evaluate the\nperformance of the convex hull based feature set, i.e. 125 features in all\ncomputed over different bays attributes of the convex hull of a pattern, for\neffective recognition of isolated handwritten Bangla basic characters and\ndigits. On experimentation with a database of 10000 samples, the maximum\nrecognition rate of 76.86% is observed for handwritten Bangla characters. For\nBangla numerals the maximum success rate of 99.45%. is achieved on a database\nof 12000 sample. The current work validates the usefulness of a new kind of\nfeature set for recognition of handwritten Bangla basic characters and\nnumerals."}, "authors": ["Nibaran Das", "Sandip Pramanik", "Subhadip Basu", "Punam Kumar Saha", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"title": "doi", "href": "http://dx.doi.org/10.13140/2.1.3689.4089", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1410.0478v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.0478v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.0478v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.0478v1", "arxiv_comment": null, "journal_reference": "2009 International Conference on Artificial Intelligence and\n  Pattern Recognition, At Orlando, Florida pp. 380-386", "doi": "10.13140/2.1.3689.4089"}
{"id": "http://arxiv.org/abs/1701.08702v1", "guidislink": true, "updated": "2017-01-27T18:43:31Z", "updated_parsed": [2017, 1, 27, 18, 43, 31, 4, 27, 0], "published": "2017-01-27T18:43:31Z", "published_parsed": [2017, 1, 27, 18, 43, 31, 4, 27, 0], "title": "Bangla Word Clustering Based on Tri-gram, 4-gram and 5-gram Language\n  Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Word Clustering Based on Tri-gram, 4-gram and 5-gram Language\n  Model"}, "summary": "In this paper, we describe a research method that generates Bangla word\nclusters on the basis of relating to meaning in language and contextual\nsimilarity. The importance of word clustering is in parts of speech (POS)\ntagging, word sense disambiguation, text classification, recommender system,\nspell checker, grammar checker, knowledge discover and for many others Natural\nLanguage Processing (NLP) applications. In the history of word clustering,\nEnglish and some other languages have already implemented some methods on word\nclustering efficiently. But due to lack of the resources, word clustering in\nBangla has not been still implemented efficiently. Presently, its\nimplementation is in the beginning stage. In some research of word clustering\nin English based on preceding and next five words of a key word they found an\nefficient result. Now, we are trying to implement the tri-gram, 4-gram and\n5-gram model of word clustering for Bangla to observe which one is the best\namong them. We have started our research with quite a large corpus of\napproximate 1 lakh Bangla words. We are using a machine learning technique in\nthis research. We will generate word clusters and analyze the clusters by\ntesting some different threshold values.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we describe a research method that generates Bangla word\nclusters on the basis of relating to meaning in language and contextual\nsimilarity. The importance of word clustering is in parts of speech (POS)\ntagging, word sense disambiguation, text classification, recommender system,\nspell checker, grammar checker, knowledge discover and for many others Natural\nLanguage Processing (NLP) applications. In the history of word clustering,\nEnglish and some other languages have already implemented some methods on word\nclustering efficiently. But due to lack of the resources, word clustering in\nBangla has not been still implemented efficiently. Presently, its\nimplementation is in the beginning stage. In some research of word clustering\nin English based on preceding and next five words of a key word they found an\nefficient result. Now, we are trying to implement the tri-gram, 4-gram and\n5-gram model of word clustering for Bangla to observe which one is the best\namong them. We have started our research with quite a large corpus of\napproximate 1 lakh Bangla words. We are using a machine learning technique in\nthis research. We will generate word clusters and analyze the clusters by\ntesting some different threshold values."}, "authors": ["Dipaloke Saha", "Md Saddam Hossain", "MD. Saiful Islam", "Sabir Ismail"], "author_detail": {"name": "Sabir Ismail"}, "author": "Sabir Ismail", "arxiv_comment": "6 pages", "links": [{"href": "http://arxiv.org/abs/1701.08702v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08702v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08702v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08702v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1809.00339v1", "guidislink": true, "updated": "2018-09-02T14:03:30Z", "updated_parsed": [2018, 9, 2, 14, 3, 30, 6, 245, 0], "published": "2018-09-02T14:03:30Z", "published_parsed": [2018, 9, 2, 14, 3, 30, 6, 245, 0], "title": "Chittron: An Automatic Bangla Image Captioning System", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Chittron: An Automatic Bangla Image Captioning System"}, "summary": "Automatic image caption generation aims to produce an accurate description of\nan image in natural language automatically. However, Bangla, the fifth most\nwidely spoken language in the world, is lagging considerably in the research\nand development of such domain. Besides, while there are many established data\nsets to related to image annotation in English, no such resource exists for\nBangla yet. Hence, this paper outlines the development of \"Chittron\", an\nautomatic image captioning system in Bangla. Moreover, to address the data set\navailability issue, a collection of 16,000 Bangladeshi contextual images has\nbeen accumulated and manually annotated in Bangla. This data set is then used\nto train a model which integrates a pre-trained VGG16 image embedding model\nwith stacked LSTM layers. The model is trained to predict the caption when the\ninput is an image, one word at a time. The results show that the model has\nsuccessfully been able to learn a working language model and to generate\ncaptions of images quite accurately in many cases. The results are evaluated\nmainly qualitatively. However, BLEU scores are also reported. It is expected\nthat a better result can be obtained with a bigger and more varied data set.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic image caption generation aims to produce an accurate description of\nan image in natural language automatically. However, Bangla, the fifth most\nwidely spoken language in the world, is lagging considerably in the research\nand development of such domain. Besides, while there are many established data\nsets to related to image annotation in English, no such resource exists for\nBangla yet. Hence, this paper outlines the development of \"Chittron\", an\nautomatic image captioning system in Bangla. Moreover, to address the data set\navailability issue, a collection of 16,000 Bangladeshi contextual images has\nbeen accumulated and manually annotated in Bangla. This data set is then used\nto train a model which integrates a pre-trained VGG16 image embedding model\nwith stacked LSTM layers. The model is trained to predict the caption when the\ninput is an image, one word at a time. The results show that the model has\nsuccessfully been able to learn a working language model and to generate\ncaptions of images quite accurately in many cases. The results are evaluated\nmainly qualitatively. However, BLEU scores are also reported. It is expected\nthat a better result can be obtained with a bigger and more varied data set."}, "authors": ["Motiur Rahman", "Nabeel Mohammed", "Nafees Mansoor", "Sifat Momen"], "author_detail": {"name": "Sifat Momen"}, "author": "Sifat Momen", "links": [{"href": "http://arxiv.org/abs/1809.00339v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1809.00339v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1809.00339v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1809.00339v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1401.1190v1", "guidislink": true, "updated": "2014-01-06T20:25:26Z", "updated_parsed": [2014, 1, 6, 20, 25, 26, 0, 6, 0], "published": "2014-01-06T20:25:26Z", "published_parsed": [2014, 1, 6, 20, 25, 26, 0, 6, 0], "title": "Bangla Text Recognition from Video Sequence: A New Focus", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Text Recognition from Video Sequence: A New Focus"}, "summary": "Extraction and recognition of Bangla text from video frame images is\nchallenging due to complex color background, low-resolution etc. In this paper,\nwe propose an algorithm for extraction and recognition of Bangla text form such\nvideo frames with complex background. Here, a two-step approach has been\nproposed. First, the text line is segmented into words using information based\non line contours. First order gradient value of the text blocks are used to\nfind the word gap. Next, a local binarization technique is applied on each word\nand text line is reconstructed using those words. Secondly, this binarized text\nblock is sent to OCR for recognition purpose.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Extraction and recognition of Bangla text from video frame images is\nchallenging due to complex color background, low-resolution etc. In this paper,\nwe propose an algorithm for extraction and recognition of Bangla text form such\nvideo frames with complex background. Here, a two-step approach has been\nproposed. First, the text line is segmented into words using information based\non line contours. First order gradient value of the text blocks are used to\nfind the word gap. Next, a local binarization technique is applied on each word\nand text line is reconstructed using those words. Secondly, this binarized text\nblock is sent to OCR for recognition purpose."}, "authors": ["Souvik Bhowmick", "Purnendu Banerjee"], "author_detail": {"name": "Purnendu Banerjee"}, "author": "Purnendu Banerjee", "links": [{"href": "http://arxiv.org/abs/1401.1190v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1401.1190v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1401.1190v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1401.1190v1", "arxiv_comment": null, "journal_reference": "NATIONAL CONFERENCE ON COMPUTING AND SYSTEMS (NaCCS), pp.\n  62-67,2012", "doi": null}
{"id": "http://arxiv.org/abs/1610.00369v2", "guidislink": true, "updated": "2016-11-24T02:13:05Z", "updated_parsed": [2016, 11, 24, 2, 13, 5, 3, 329, 0], "published": "2016-10-02T23:45:23Z", "published_parsed": [2016, 10, 2, 23, 45, 23, 6, 276, 0], "title": "Sentiment Analysis on Bangla and Romanized Bangla Text (BRBT) using Deep\n  Recurrent models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Analysis on Bangla and Romanized Bangla Text (BRBT) using Deep\n  Recurrent models"}, "summary": "Sentiment Analysis (SA) is an action research area in the digital age. With\nrapid and constant growth of online social media sites and services, and the\nincreasing amount of textual data such as - statuses, comments, reviews etc.\navailable in them, application of automatic SA is on the rise. However, most of\nthe research works on SA in natural language processing (NLP) are based on\nEnglish language. Despite being the sixth most widely spoken language in the\nworld, Bangla still does not have a large and standard dataset. Because of\nthis, recent research works in Bangla have failed to produce results that can\nbe both comparable to works done by others and reusable as stepping stones for\nfuture researchers to progress in this field. Therefore, we first tried to\nprovide a textual dataset - that includes not just Bangla, but Romanized Bangla\ntexts as well, is substantial, post-processed and multiple validated, ready to\nbe used in SA experiments. We tested this dataset in Deep Recurrent model,\nspecifically, Long Short Term Memory (LSTM), using two types of loss functions\n- binary crossentropy and categorical crossentropy, and also did some\nexperimental pre-training by using data from one validation to pre-train the\nother and vice versa. Lastly, we documented the results along with some\nanalysis on them, which were promising.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Analysis (SA) is an action research area in the digital age. With\nrapid and constant growth of online social media sites and services, and the\nincreasing amount of textual data such as - statuses, comments, reviews etc.\navailable in them, application of automatic SA is on the rise. However, most of\nthe research works on SA in natural language processing (NLP) are based on\nEnglish language. Despite being the sixth most widely spoken language in the\nworld, Bangla still does not have a large and standard dataset. Because of\nthis, recent research works in Bangla have failed to produce results that can\nbe both comparable to works done by others and reusable as stepping stones for\nfuture researchers to progress in this field. Therefore, we first tried to\nprovide a textual dataset - that includes not just Bangla, but Romanized Bangla\ntexts as well, is substantial, post-processed and multiple validated, ready to\nbe used in SA experiments. We tested this dataset in Deep Recurrent model,\nspecifically, Long Short Term Memory (LSTM), using two types of loss functions\n- binary crossentropy and categorical crossentropy, and also did some\nexperimental pre-training by using data from one validation to pre-train the\nother and vice versa. Lastly, we documented the results along with some\nanalysis on them, which were promising."}, "authors": ["A. Hassan", "M. R. Amin", "N. Mohammed", "A. K. A. Azad"], "author_detail": {"name": "A. K. A. Azad"}, "author": "A. K. A. Azad", "links": [{"href": "http://arxiv.org/abs/1610.00369v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1610.00369v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1610.00369v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1610.00369v2", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1705.02680v1", "guidislink": true, "updated": "2017-05-07T18:49:27Z", "updated_parsed": [2017, 5, 7, 18, 49, 27, 6, 127, 0], "published": "2017-05-07T18:49:27Z", "published_parsed": [2017, 5, 7, 18, 49, 27, 6, 127, 0], "title": "Handwritten Bangla Digit Recognition Using Deep Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Digit Recognition Using Deep Learning"}, "summary": "In spite of the advances in pattern recognition technology, Handwritten\nBangla Character Recognition (HBCR) (such as alpha-numeric and special\ncharacters) remains largely unsolved due to the presence of many perplexing\ncharacters and excessive cursive in Bangla handwriting. Even the best existing\nrecognizers do not lead to satisfactory performance for practical applications.\nTo improve the performance of Handwritten Bangla Digit Recognition (HBDR), we\nherein present a new approach based on deep neural networks which have recently\nshown excellent performance in many pattern recognition and machine learning\napplications, but has not been throughly attempted for HBDR. We introduce\nBangla digit recognition techniques based on Deep Belief Network (DBN),\nConvolutional Neural Networks (CNN), CNN with dropout, CNN with dropout and\nGaussian filters, and CNN with dropout and Gabor filters. These networks have\nthe advantage of extracting and using feature information, improving the\nrecognition of two dimensional shapes with a high degree of invariance to\ntranslation, scaling and other pattern distortions. We systematically evaluated\nthe performance of our method on publicly available Bangla numeral image\ndatabase named CMATERdb 3.1.1. From experiments, we achieved 98.78% recognition\nrate using the proposed method: CNN with Gabor features and dropout, which\noutperforms the state-of-the-art algorithms for HDBR.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In spite of the advances in pattern recognition technology, Handwritten\nBangla Character Recognition (HBCR) (such as alpha-numeric and special\ncharacters) remains largely unsolved due to the presence of many perplexing\ncharacters and excessive cursive in Bangla handwriting. Even the best existing\nrecognizers do not lead to satisfactory performance for practical applications.\nTo improve the performance of Handwritten Bangla Digit Recognition (HBDR), we\nherein present a new approach based on deep neural networks which have recently\nshown excellent performance in many pattern recognition and machine learning\napplications, but has not been throughly attempted for HBDR. We introduce\nBangla digit recognition techniques based on Deep Belief Network (DBN),\nConvolutional Neural Networks (CNN), CNN with dropout, CNN with dropout and\nGaussian filters, and CNN with dropout and Gabor filters. These networks have\nthe advantage of extracting and using feature information, improving the\nrecognition of two dimensional shapes with a high degree of invariance to\ntranslation, scaling and other pattern distortions. We systematically evaluated\nthe performance of our method on publicly available Bangla numeral image\ndatabase named CMATERdb 3.1.1. From experiments, we achieved 98.78% recognition\nrate using the proposed method: CNN with Gabor features and dropout, which\noutperforms the state-of-the-art algorithms for HDBR."}, "authors": ["Md Zahangir Alom", "Paheding Sidike", "Tarek M. Taha", "Vijayan K. Asari"], "author_detail": {"name": "Vijayan K. Asari"}, "author": "Vijayan K. Asari", "arxiv_comment": "12 pages, 10 figures, 3 tables", "links": [{"href": "http://arxiv.org/abs/1705.02680v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1705.02680v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1705.02680v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1705.02680v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1208.0995v1", "guidislink": true, "updated": "2012-08-05T09:22:06Z", "updated_parsed": [2012, 8, 5, 9, 22, 6, 6, 218, 0], "published": "2012-08-05T09:22:06Z", "published_parsed": [2012, 8, 5, 9, 22, 6, 6, 218, 0], "title": "Design and implementation of a digital clock showing digits in Bangla\n  font using microcontroller AT89C4051", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Design and implementation of a digital clock showing digits in Bangla\n  font using microcontroller AT89C4051"}, "summary": "In this paper, a digital clock is designed where the microcontroller is used\nfor timing controller and the font of the Bangla digits are designed, and\nprogrammed within the microcontroller. The design is cost effective, simple and\neasy for maintenance.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, a digital clock is designed where the microcontroller is used\nfor timing controller and the font of the Bangla digits are designed, and\nprogrammed within the microcontroller. The design is cost effective, simple and\neasy for maintenance."}, "authors": ["Nasif Muslim", "Md. Tanvir Adnan", "Mohammad Zahidul Kabir", "Md. Humayun Kabir", "Sheikh Mominul Islam"], "author_detail": {"name": "Sheikh Mominul Islam"}, "author": "Sheikh Mominul Islam", "links": [{"href": "http://arxiv.org/abs/1208.0995v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1208.0995v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.AR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.AR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1208.0995v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1208.0995v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1308.3785v1", "guidislink": true, "updated": "2013-08-17T14:04:00Z", "updated_parsed": [2013, 8, 17, 14, 4, 0, 5, 229, 0], "published": "2013-08-17T14:04:00Z", "published_parsed": [2013, 8, 17, 14, 4, 0, 5, 229, 0], "title": "Implementation Of Back-Propagation Neural Network For Isolated Bangla\n  Speech Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Implementation Of Back-Propagation Neural Network For Isolated Bangla\n  Speech Recognition"}, "summary": "This paper is concerned with the development of Back-propagation Neural\nNetwork for Bangla Speech Recognition. In this paper, ten bangla digits were\nrecorded from ten speakers and have been recognized. The features of these\nspeech digits were extracted by the method of Mel Frequency Cepstral\nCoefficient (MFCC) analysis. The mfcc features of five speakers were used to\ntrain the network with Back propagation algorithm. The mfcc features of ten\nbangla digit speeches, from 0 to 9, of another five speakers were used to test\nthe system. All the methods and algorithms used in this research were\nimplemented using the features of Turbo C and C++ languages. From our\ninvestigation it is seen that the developed system can successfully encode and\nanalyze the mfcc features of the speech signal to recognition. The developed\nsystem achieved recognition rate about 96.332% for known speakers (i.e.,\nspeaker dependent) and 92% for unknown speakers (i.e., speaker independent).", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=10&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper is concerned with the development of Back-propagation Neural\nNetwork for Bangla Speech Recognition. In this paper, ten bangla digits were\nrecorded from ten speakers and have been recognized. The features of these\nspeech digits were extracted by the method of Mel Frequency Cepstral\nCoefficient (MFCC) analysis. The mfcc features of five speakers were used to\ntrain the network with Back propagation algorithm. The mfcc features of ten\nbangla digit speeches, from 0 to 9, of another five speakers were used to test\nthe system. All the methods and algorithms used in this research were\nimplemented using the features of Turbo C and C++ languages. From our\ninvestigation it is seen that the developed system can successfully encode and\nanalyze the mfcc features of the speech signal to recognition. The developed\nsystem achieved recognition rate about 96.332% for known speakers (i.e.,\nspeaker dependent) and 92% for unknown speakers (i.e., speaker independent)."}, "authors": ["Md. Ali Hossain", "Md. Mijanur Rahman", "Uzzal Kumar Prodhan", "Md. Farukuzzaman Khan"], "author_detail": {"name": "Md. Farukuzzaman Khan"}, "author": "Md. Farukuzzaman Khan", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijist.2013.3401", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1308.3785v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1308.3785v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "9 pages, 3 figures, 1 table", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.NE", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1308.3785v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1308.3785v1", "journal_reference": "International Journal of Information Sciences and Techniques\n  (IJIST) Vol.3, No.4, July 2013", "doi": "10.5121/ijist.2013.3401"}
{"id": "http://arxiv.org/abs/1003.5897v1", "guidislink": true, "updated": "2010-03-30T18:54:57Z", "updated_parsed": [2010, 3, 30, 18, 54, 57, 1, 89, 0], "published": "2010-03-30T18:54:57Z", "published_parsed": [2010, 3, 30, 18, 54, 57, 1, 89, 0], "title": "Development of a Multi-User Recognition Engine for Handwritten Bangla\n  Basic Characters and Digits", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Development of a Multi-User Recognition Engine for Handwritten Bangla\n  Basic Characters and Digits"}, "summary": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The objective of the paper is to recognize handwritten samples of basic\nBangla characters using Tesseract open source Optical Character Recognition\n(OCR) engine under Apache License 2.0. Handwritten data samples containing\nisolated Bangla basic characters and digits were collected from different\nusers. Tesseract is trained with user-specific data samples of document pages\nto generate separate user-models representing a unique language-set. Each such\nlanguage-set recognizes isolated basic Bangla handwritten test samples\ncollected from the designated users. On a three user model, the system is\ntrained with 919, 928 and 648 isolated handwritten character and digit samples\nand the performance is tested on 1527, 14116 and 1279 character and digit\nsamples, collected form the test datasets of the three users respectively. The\nuser specific character/digit recognition accuracies were obtained as 90.66%,\n91.66% and 96.87% respectively. The overall basic character-level and digit\nlevel accuracy of the system is observed as 92.15% and 97.37%. The system fails\nto segment 12.33% characters and 15.96% digits and also erroneously classifies\n7.85% characters and 2.63% on the overall dataset."}, "authors": ["Sandip Rakshit", "Debkumar Ghosal", "Tanmoy Das", "Subhrajit Dutta", "Subhadip Basu"], "author_detail": {"name": "Subhadip Basu"}, "author": "Subhadip Basu", "arxiv_comment": "Proc. (CD) Int. Conf. on Information Technology and Business\n  Intelligence (2009)", "links": [{"href": "http://arxiv.org/abs/1003.5897v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1003.5897v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1003.5897v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1003.5897v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1602.07803v1", "guidislink": true, "updated": "2016-02-25T05:35:16Z", "updated_parsed": [2016, 2, 25, 5, 35, 16, 3, 56, 0], "published": "2016-02-25T05:35:16Z", "published_parsed": [2016, 2, 25, 5, 35, 16, 3, 56, 0], "title": "Automated Word Prediction in Bangla Language Using Stochastic Language\n  Models", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automated Word Prediction in Bangla Language Using Stochastic Language\n  Models"}, "summary": "Word completion and word prediction are two important phenomena in typing\nthat benefit users who type using keyboard or other similar devices. They can\nhave profound impact on the typing of disable people. Our work is based on word\nprediction on Bangla sentence by using stochastic, i.e. N-gram language model\nsuch as unigram, bigram, trigram, deleted Interpolation and backoff models for\nauto completing a sentence by predicting a correct word in a sentence which\nsaves time and keystrokes of typing and also reduces misspelling. We use large\ndata corpus of Bangla language of different word types to predict correct word\nwith the accuracy as much as possible. We have found promising results. We hope\nthat our work will impact on the baseline for automated Bangla typing.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word completion and word prediction are two important phenomena in typing\nthat benefit users who type using keyboard or other similar devices. They can\nhave profound impact on the typing of disable people. Our work is based on word\nprediction on Bangla sentence by using stochastic, i.e. N-gram language model\nsuch as unigram, bigram, trigram, deleted Interpolation and backoff models for\nauto completing a sentence by predicting a correct word in a sentence which\nsaves time and keystrokes of typing and also reduces misspelling. We use large\ndata corpus of Bangla language of different word types to predict correct word\nwith the accuracy as much as possible. We have found promising results. We hope\nthat our work will impact on the baseline for automated Bangla typing."}, "authors": ["Md. Masudul Haque", "Md. Tarek Habib", "Md. Mokhlesur Rahman"], "author_detail": {"name": "Md. Mokhlesur Rahman"}, "author": "Md. Mokhlesur Rahman", "links": [{"title": "doi", "href": "http://dx.doi.org/10.5121/ijfcst.2015.5607", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1602.07803v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1602.07803v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "in International Journal in Foundations of Computer Science &\n  Technology (IJFCST) Vol.5, No.6, November 2015", "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1602.07803v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1602.07803v1", "journal_reference": null, "doi": "10.5121/ijfcst.2015.5607"}
{"id": "http://arxiv.org/abs/1310.1590v1", "guidislink": true, "updated": "2013-10-06T14:37:05Z", "updated_parsed": [2013, 10, 6, 14, 37, 5, 6, 279, 0], "published": "2013-10-06T14:37:05Z", "published_parsed": [2013, 10, 6, 14, 37, 5, 6, 279, 0], "title": "Evolution of the Modern Phase of Written Bangla: A Statistical Study", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Evolution of the Modern Phase of Written Bangla: A Statistical Study"}, "summary": "Active languages such as Bangla (or Bengali) evolve over time due to a\nvariety of social, cultural, economic, and political issues. In this paper, we\nanalyze the change in the written form of the modern phase of Bangla\nquantitatively in terms of character-level, syllable-level, morpheme-level and\nword-level features. We collect three different types of corpora---classical,\nnewspapers and blogs---and test whether the differences in their features are\nstatistically significant. Results suggest that there are significant changes\nin the length of a word when measured in terms of characters, but there is not\nmuch difference in usage of different characters, syllables and morphemes in a\nword or of different words in a sentence. To the best of our knowledge, this is\nthe first work on Bangla of this kind.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Active languages such as Bangla (or Bengali) evolve over time due to a\nvariety of social, cultural, economic, and political issues. In this paper, we\nanalyze the change in the written form of the modern phase of Bangla\nquantitatively in terms of character-level, syllable-level, morpheme-level and\nword-level features. We collect three different types of corpora---classical,\nnewspapers and blogs---and test whether the differences in their features are\nstatistically significant. Results suggest that there are significant changes\nin the length of a word when measured in terms of characters, but there is not\nmuch difference in usage of different characters, syllables and morphemes in a\nword or of different words in a sentence. To the best of our knowledge, this is\nthe first work on Bangla of this kind."}, "authors": ["Paheli Bhattacharya", "Arnab Bhattacharya"], "author_detail": {"name": "Arnab Bhattacharya"}, "author": "Arnab Bhattacharya", "arxiv_comment": "LCC 2013", "links": [{"href": "http://arxiv.org/abs/1310.1590v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1310.1590v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1310.1590v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1310.1590v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1809.00905v1", "guidislink": true, "updated": "2018-09-04T11:55:34Z", "updated_parsed": [2018, 9, 4, 11, 55, 34, 1, 247, 0], "published": "2018-09-04T11:55:34Z", "published_parsed": [2018, 9, 4, 11, 55, 34, 1, 247, 0], "title": "Bangla License Plate Recognition Using Convolutional Neural Networks\n  (CNN)", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla License Plate Recognition Using Convolutional Neural Networks\n  (CNN)"}, "summary": "In the last few years, the deep learning technique in particular\nConvolutional Neural Networks (CNNs) is using massively in the field of\ncomputer vision and machine learning. This deep learning technique provides\nstate-of-the-art accuracy in different classification, segmentation, and\ndetection tasks on different benchmarks such as MNIST, CIFAR-10, CIFAR-100,\nMicrosoft COCO, and ImageNet. However, there are a lot of research has been\nconducted for Bangla License plate recognition with traditional machine\nlearning approaches in last decade. None of them are used to deploy a physical\nsystem for Bangla License Plate Recognition System (BLPRS) due to their poor\nrecognition accuracy. In this paper, we have implemented CNNs based Bangla\nlicense plate recognition system with better accuracy that can be applied for\ndifferent purposes including roadside assistance, automatic parking lot\nmanagement system, vehicle license status detection and so on. Along with that,\nwe have also created and released a very first and standard database for BLPRS.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In the last few years, the deep learning technique in particular\nConvolutional Neural Networks (CNNs) is using massively in the field of\ncomputer vision and machine learning. This deep learning technique provides\nstate-of-the-art accuracy in different classification, segmentation, and\ndetection tasks on different benchmarks such as MNIST, CIFAR-10, CIFAR-100,\nMicrosoft COCO, and ImageNet. However, there are a lot of research has been\nconducted for Bangla License plate recognition with traditional machine\nlearning approaches in last decade. None of them are used to deploy a physical\nsystem for Bangla License Plate Recognition System (BLPRS) due to their poor\nrecognition accuracy. In this paper, we have implemented CNNs based Bangla\nlicense plate recognition system with better accuracy that can be applied for\ndifferent purposes including roadside assistance, automatic parking lot\nmanagement system, vehicle license status detection and so on. Along with that,\nwe have also created and released a very first and standard database for BLPRS."}, "authors": ["M M Shaifur Rahman", "Mst Shamima Nasrin", "Moin Mostakim", "Md Zahangir Alom"], "author_detail": {"name": "Md Zahangir Alom"}, "author": "Md Zahangir Alom", "arxiv_comment": "6 pages,10 figures", "links": [{"href": "http://arxiv.org/abs/1809.00905v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1809.00905v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1809.00905v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1809.00905v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1911.07613v1", "guidislink": true, "updated": "2019-11-15T08:22:33Z", "updated_parsed": [2019, 11, 15, 8, 22, 33, 4, 319, 0], "published": "2019-11-15T08:22:33Z", "published_parsed": [2019, 11, 15, 8, 22, 33, 4, 319, 0], "title": "A Subword Level Language Model for Bangla Language", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Subword Level Language Model for Bangla Language"}, "summary": "Language models are at the core of natural language processing. The ability\nto represent natural language gives rise to its applications in numerous NLP\ntasks including text classification, summarization, and translation. Research\nin this area is very limited in Bangla due to the scarcity of resources, except\nfor some count-based models and very recent neural language models being\nproposed, which are all based on words and limited in practical tasks due to\ntheir high perplexity. This paper attempts to approach this issue of perplexity\nand proposes a subword level neural language model with the AWD-LSTM\narchitecture and various other techniques suitable for training in Bangla\nlanguage. The model is trained on a corpus of Bangla newspaper articles of an\nappreciable size consisting of more than 28.5 million word tokens. The\nperformance comparison with various other models depicts the significant\nreduction in perplexity the proposed model provides, reaching as low as 39.84,\nin just 20 epochs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Language models are at the core of natural language processing. The ability\nto represent natural language gives rise to its applications in numerous NLP\ntasks including text classification, summarization, and translation. Research\nin this area is very limited in Bangla due to the scarcity of resources, except\nfor some count-based models and very recent neural language models being\nproposed, which are all based on words and limited in practical tasks due to\ntheir high perplexity. This paper attempts to approach this issue of perplexity\nand proposes a subword level neural language model with the AWD-LSTM\narchitecture and various other techniques suitable for training in Bangla\nlanguage. The model is trained on a corpus of Bangla newspaper articles of an\nappreciable size consisting of more than 28.5 million word tokens. The\nperformance comparison with various other models depicts the significant\nreduction in perplexity the proposed model provides, reaching as low as 39.84,\nin just 20 epochs."}, "authors": ["Aisha Khatun", "Anisur Rahman", "Hemayet Ahmed Chowdhury", "Md. Saiful Islam", "Ayesha Tasnim"], "author_detail": {"name": "Ayesha Tasnim"}, "author": "Ayesha Tasnim", "arxiv_comment": "12 pages, Conference Paper", "links": [{"href": "http://arxiv.org/abs/1911.07613v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1911.07613v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1911.07613v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1911.07613v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2005.14627v1", "guidislink": true, "updated": "2020-05-29T15:38:54Z", "updated_parsed": [2020, 5, 29, 15, 38, 54, 4, 150, 0], "published": "2020-05-29T15:38:54Z", "published_parsed": [2020, 5, 29, 15, 38, 54, 4, 150, 0], "title": "Detection of Bangla Fake News using MNB and SVM Classifier", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Detection of Bangla Fake News using MNB and SVM Classifier"}, "summary": "Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%."}, "authors": ["Md Gulzar Hussain", "Md Rashidul Hasan", "Mahmuda Rahman", "Joy Protim", "Sakib Al Hasan"], "author_detail": {"name": "Sakib Al Hasan"}, "author": "Sakib Al Hasan", "links": [{"href": "http://arxiv.org/abs/2005.14627v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2005.14627v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2005.14627v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2005.14627v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.09872v3", "guidislink": true, "updated": "2018-02-10T18:40:54Z", "updated_parsed": [2018, 2, 10, 18, 40, 54, 5, 41, 0], "published": "2017-12-28T14:31:56Z", "published_parsed": [2017, 12, 28, 14, 31, 56, 3, 362, 0], "title": "Handwritten Bangla Character Recognition Using The State-of-Art Deep\n  Convolutional Neural Networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Bangla Character Recognition Using The State-of-Art Deep\n  Convolutional Neural Networks"}, "summary": "In spite of advances in object recognition technology, Handwritten Bangla\nCharacter Recognition (HBCR) remains largely unsolved due to the presence of\nmany ambiguous handwritten characters and excessively cursive Bangla\nhandwritings. Even the best existing recognizers do not lead to satisfactory\nperformance for practical applications related to Bangla character recognition\nand have much lower performance than those developed for English alpha-numeric\ncharacters. To improve the performance of HBCR, we herein present the\napplication of the state-of-the-art Deep Convolutional Neural Networks (DCNN)\nincluding VGG Network, All Convolution Network (All-Conv Net), Network in\nNetwork (NiN), Residual Network, FractalNet, and DenseNet for HBCR. The deep\nlearning approaches have the advantage of extracting and using feature\ninformation, improving the recognition of 2D shapes with a high degree of\ninvariance to translation, scaling and other distortions. We systematically\nevaluated the performance of DCNN models on publicly available Bangla\nhandwritten character dataset called CMATERdb and achieved the superior\nrecognition accuracy when using DCNN models. This improvement would help in\nbuilding an automatic HBCR system for practical applications.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In spite of advances in object recognition technology, Handwritten Bangla\nCharacter Recognition (HBCR) remains largely unsolved due to the presence of\nmany ambiguous handwritten characters and excessively cursive Bangla\nhandwritings. Even the best existing recognizers do not lead to satisfactory\nperformance for practical applications related to Bangla character recognition\nand have much lower performance than those developed for English alpha-numeric\ncharacters. To improve the performance of HBCR, we herein present the\napplication of the state-of-the-art Deep Convolutional Neural Networks (DCNN)\nincluding VGG Network, All Convolution Network (All-Conv Net), Network in\nNetwork (NiN), Residual Network, FractalNet, and DenseNet for HBCR. The deep\nlearning approaches have the advantage of extracting and using feature\ninformation, improving the recognition of 2D shapes with a high degree of\ninvariance to translation, scaling and other distortions. We systematically\nevaluated the performance of DCNN models on publicly available Bangla\nhandwritten character dataset called CMATERdb and achieved the superior\nrecognition accuracy when using DCNN models. This improvement would help in\nbuilding an automatic HBCR system for practical applications."}, "authors": ["Md Zahangir Alom", "Peheding Sidike", "Mahmudul Hasan", "Tark M. Taha", "Vijayan K. Asari"], "author_detail": {"name": "Vijayan K. Asari"}, "author": "Vijayan K. Asari", "arxiv_comment": "12 pages,22 figures, 5 tables. arXiv admin note: text overlap with\n  arXiv:1705.02680", "links": [{"href": "http://arxiv.org/abs/1712.09872v3", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.09872v3", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.09872v3", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.09872v3", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2101.00204v1", "guidislink": true, "updated": "2021-01-01T09:28:45Z", "updated_parsed": [2021, 1, 1, 9, 28, 45, 4, 1, 0], "published": "2021-01-01T09:28:45Z", "published_parsed": [2021, 1, 1, 9, 28, 45, 4, 1, 0], "title": "BanglaBERT: Combating Embedding Barrier for Low-Resource Language\n  Understanding", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaBERT: Combating Embedding Barrier for Low-Resource Language\n  Understanding"}, "summary": "Pre-training language models on large volume of data with self-supervised\nobjectives has become a standard practice in natural language processing.\nHowever, most such state-of-the-art models are available in only English and\nother resource-rich languages. Even in multilingual models, which are trained\non hundreds of languages, low-resource ones still remain underrepresented.\nBangla, the seventh most widely spoken language in the world, is still low in\nterms of resources. Few downstream task datasets for language understanding in\nBangla are publicly available, and there is a clear shortage of good quality\ndata for pre-training. In this work, we build a Bangla natural language\nunderstanding model pre-trained on 18.6 GB data we crawled from top Bangla\nsites on the internet. We introduce a new downstream task dataset and benchmark\non four tasks on sentence classification, document classification, natural\nlanguage understanding, and sequence tagging. Our model outperforms\nmultilingual baselines and previous state-of-the-art results by 1-6%. In the\nprocess, we identify a major shortcoming of multilingual models that hurt\nperformance for low-resource languages that don't share writing scripts with\nany high resource one, which we name the `Embedding Barrier'. We perform\nextensive experiments to study this barrier. We release all our datasets and\npre-trained models to aid future NLP research on Bangla and other low-resource\nlanguages. Our code and data are available at\nhttps://github.com/csebuetnlp/banglabert.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Pre-training language models on large volume of data with self-supervised\nobjectives has become a standard practice in natural language processing.\nHowever, most such state-of-the-art models are available in only English and\nother resource-rich languages. Even in multilingual models, which are trained\non hundreds of languages, low-resource ones still remain underrepresented.\nBangla, the seventh most widely spoken language in the world, is still low in\nterms of resources. Few downstream task datasets for language understanding in\nBangla are publicly available, and there is a clear shortage of good quality\ndata for pre-training. In this work, we build a Bangla natural language\nunderstanding model pre-trained on 18.6 GB data we crawled from top Bangla\nsites on the internet. We introduce a new downstream task dataset and benchmark\non four tasks on sentence classification, document classification, natural\nlanguage understanding, and sequence tagging. Our model outperforms\nmultilingual baselines and previous state-of-the-art results by 1-6%. In the\nprocess, we identify a major shortcoming of multilingual models that hurt\nperformance for low-resource languages that don't share writing scripts with\nany high resource one, which we name the `Embedding Barrier'. We perform\nextensive experiments to study this barrier. We release all our datasets and\npre-trained models to aid future NLP research on Bangla and other low-resource\nlanguages. Our code and data are available at\nhttps://github.com/csebuetnlp/banglabert."}, "authors": ["Abhik Bhattacharjee", "Tahmid Hasan", "Kazi Samin", "M. Sohel Rahman", "Anindya Iqbal", "Rifat Shahriyar"], "author_detail": {"name": "Rifat Shahriyar"}, "author": "Rifat Shahriyar", "links": [{"href": "http://arxiv.org/abs/2101.00204v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2101.00204v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2101.00204v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2101.00204v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.10106v1", "guidislink": true, "updated": "2020-11-19T21:06:28Z", "updated_parsed": [2020, 11, 19, 21, 6, 28, 3, 324, 0], "published": "2020-11-19T21:06:28Z", "published_parsed": [2020, 11, 19, 21, 6, 28, 3, 324, 0], "title": "Sentiment Classification in Bangla Textual Content: A Comparative Study", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment Classification in Bangla Textual Content: A Comparative Study"}, "summary": "Sentiment analysis has been widely used to understand our views on social and\npolitical agendas or user experiences over a product. It is one of the cores\nand well-researched areas in NLP. However, for low-resource languages, like\nBangla, one of the prominent challenge is the lack of resources. Another\nimportant limitation, in the current literature for Bangla, is the absence of\ncomparable results due to the lack of a well-defined train/test split. In this\nstudy, we explore several publicly available sentiment labeled datasets and\ndesigned classifiers using both classical and deep learning algorithms. In our\nstudy, the classical algorithms include SVM and Random Forest, and deep\nlearning algorithms include CNN, FastText, and transformer-based models. We\ncompare these models in terms of model performance and time-resource\ncomplexity. Our finding suggests transformer-based models, which have not been\nexplored earlier for Bangla, outperform all other models. Furthermore, we\ncreated a weighted list of lexicon content based on the valence score per\nclass. We then analyzed the content for high significance entries per class, in\nthe datasets. For reproducibility, we make publicly available data splits and\nthe ranked lexicon list. The presented results can be used for future studies\nas a benchmark.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sentiment analysis has been widely used to understand our views on social and\npolitical agendas or user experiences over a product. It is one of the cores\nand well-researched areas in NLP. However, for low-resource languages, like\nBangla, one of the prominent challenge is the lack of resources. Another\nimportant limitation, in the current literature for Bangla, is the absence of\ncomparable results due to the lack of a well-defined train/test split. In this\nstudy, we explore several publicly available sentiment labeled datasets and\ndesigned classifiers using both classical and deep learning algorithms. In our\nstudy, the classical algorithms include SVM and Random Forest, and deep\nlearning algorithms include CNN, FastText, and transformer-based models. We\ncompare these models in terms of model performance and time-resource\ncomplexity. Our finding suggests transformer-based models, which have not been\nexplored earlier for Bangla, outperform all other models. Furthermore, we\ncreated a weighted list of lexicon content based on the valence score per\nclass. We then analyzed the content for high significance entries per class, in\nthe datasets. For reproducibility, we make publicly available data splits and\nthe ranked lexicon list. The presented results can be used for future studies\nas a benchmark."}, "authors": ["Md. Arid Hasan", "Jannatul Tajrin", "Shammur Absar Chowdhury", "Firoj Alam"], "author_detail": {"name": "Firoj Alam"}, "author": "Firoj Alam", "arxiv_comment": "Accepted at ICCIT-2020", "links": [{"href": "http://arxiv.org/abs/2011.10106v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.10106v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T50", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.10106v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.10106v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1002.4007v1", "guidislink": true, "updated": "2010-02-21T19:48:16Z", "updated_parsed": [2010, 2, 21, 19, 48, 16, 6, 52, 0], "published": "2010-02-21T19:48:16Z", "published_parsed": [2010, 2, 21, 19, 48, 16, 6, 52, 0], "title": "Word level Script Identification from Bangla and Devanagri Handwritten\n  Texts mixed with Roman Script", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word level Script Identification from Bangla and Devanagri Handwritten\n  Texts mixed with Roman Script"}, "summary": "India is a multi-lingual country where Roman script is often used alongside\ndifferent Indic scripts in a text document. To develop a script specific\nhandwritten Optical Character Recognition (OCR) system, it is therefore\nnecessary to identify the scripts of handwritten text correctly. In this paper,\nwe present a system, which automatically separates the scripts of handwritten\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\nIn this script separation technique, we first, extract the text lines and words\nfrom document pages using a script independent Neighboring Component Analysis\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\nclassifier for script separation, trained with 8 different wordlevel holistic\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\nOn respective independent text samples, word-level script identification\naccuracies of 99.29% and 98.43% are achieved.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=20&max_results=10&sortBy=relevance&sortOrder=descending", "value": "India is a multi-lingual country where Roman script is often used alongside\ndifferent Indic scripts in a text document. To develop a script specific\nhandwritten Optical Character Recognition (OCR) system, it is therefore\nnecessary to identify the scripts of handwritten text correctly. In this paper,\nwe present a system, which automatically separates the scripts of handwritten\nwords from a document, written in Bangla or Devanagri mixed with Roman scripts.\nIn this script separation technique, we first, extract the text lines and words\nfrom document pages using a script independent Neighboring Component Analysis\ntechnique. Then we have designed a Multi Layer Perceptron (MLP) based\nclassifier for script separation, trained with 8 different wordlevel holistic\nfeatures. Two equal sized datasets, one with Bangla and Roman scripts and the\nother with Devanagri and Roman scripts, are prepared for the system evaluation.\nOn respective independent text samples, word-level script identification\naccuracies of 99.29% and 98.43% are achieved."}, "authors": ["Ram Sarkar", "Nibaran Das", "Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1002.4007v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1002.4007v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1002.4007v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1002.4007v1", "arxiv_comment": null, "journal_reference": "Journal of Computing, Volume 2, Issue 2, February 2010,\n  https://sites.google.com/site/journalofcomputing/", "doi": null}
{"id": "http://arxiv.org/abs/1206.0381v1", "guidislink": true, "updated": "2012-06-02T13:23:18Z", "updated_parsed": [2012, 6, 2, 13, 23, 18, 5, 154, 0], "published": "2012-06-02T13:23:18Z", "published_parsed": [2012, 6, 2, 13, 23, 18, 5, 154, 0], "title": "UNL Based Bangla Natural Text Conversion - Predicate Preserving Parser\n  Approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "UNL Based Bangla Natural Text Conversion - Predicate Preserving Parser\n  Approach"}, "summary": "Universal Networking Language (UNL) is a declarative formal language that is\nused to represent semantic data extracted from natural language texts. This\npaper presents a novel approach to converting Bangla natural language text into\nUNL using a method known as Predicate Preserving Parser (PPP) technique. PPP\nperforms morphological, syntactic and semantic, and lexical analysis of text\nsynchronously. This analysis produces a semantic-net like structure represented\nusing UNL. We demonstrate how Bangla texts are analyzed following the PPP\ntechnique to produce UNL documents which can then be translated into any other\nsuitable natural language facilitating the opportunity to develop a universal\nlanguage translation method via UNL.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Universal Networking Language (UNL) is a declarative formal language that is\nused to represent semantic data extracted from natural language texts. This\npaper presents a novel approach to converting Bangla natural language text into\nUNL using a method known as Predicate Preserving Parser (PPP) technique. PPP\nperforms morphological, syntactic and semantic, and lexical analysis of text\nsynchronously. This analysis produces a semantic-net like structure represented\nusing UNL. We demonstrate how Bangla texts are analyzed following the PPP\ntechnique to produce UNL documents which can then be translated into any other\nsuitable natural language facilitating the opportunity to develop a universal\nlanguage translation method via UNL."}, "authors": ["Md. Nawab Yousuf Ali", "Shamim Ripon", "Shaikh Muhammad Allayear"], "author_detail": {"name": "Shaikh Muhammad Allayear"}, "author": "Shaikh Muhammad Allayear", "arxiv_comment": "7 pages, International Journal of Computer Science Issues (IJCSI),\n  Volume 9, Issue 3 May 2012", "links": [{"href": "http://arxiv.org/abs/1206.0381v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1206.0381v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1206.0381v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1206.0381v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1310.1426v1", "guidislink": true, "updated": "2013-10-05T00:39:02Z", "updated_parsed": [2013, 10, 5, 0, 39, 2, 5, 278, 0], "published": "2013-10-05T00:39:02Z", "published_parsed": [2013, 10, 5, 0, 39, 2, 5, 278, 0], "title": "Local Feature or Mel Frequency Cepstral Coefficients - Which One is\n  Better for MLN-Based Bangla Speech Recognition?", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Local Feature or Mel Frequency Cepstral Coefficients - Which One is\n  Better for MLN-Based Bangla Speech Recognition?"}, "summary": "This paper discusses the dominancy of local features (LFs), as input to the\nmultilayer neural network (MLN), extracted from a Bangla input speech over mel\nfrequency cepstral coefficients (MFCCs). Here, LF-based method comprises three\nstages: (i) LF extraction from input speech, (ii) phoneme probabilities\nextraction using MLN from LF and (iii) the hidden Markov model (HMM) based\nclassifier to obtain more accurate phoneme strings. In the experiments on\nBangla speech corpus prepared by us, it is observed that the LFbased automatic\nspeech recognition (ASR) system provides higher phoneme correct rate than the\nMFCC-based system. Moreover, the proposed system requires fewer mixture\ncomponents in the HMMs.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper discusses the dominancy of local features (LFs), as input to the\nmultilayer neural network (MLN), extracted from a Bangla input speech over mel\nfrequency cepstral coefficients (MFCCs). Here, LF-based method comprises three\nstages: (i) LF extraction from input speech, (ii) phoneme probabilities\nextraction using MLN from LF and (iii) the hidden Markov model (HMM) based\nclassifier to obtain more accurate phoneme strings. In the experiments on\nBangla speech corpus prepared by us, it is observed that the LFbased automatic\nspeech recognition (ASR) system provides higher phoneme correct rate than the\nMFCC-based system. Moreover, the proposed system requires fewer mixture\ncomponents in the HMMs."}, "authors": ["Foyzul Hassan", "Mohammed Rokibul Alam Kotwal", "Md. Mostafizur Rahman", "Mohammad Nasiruddin", "Md. Abdul Latif", "Mohammad Nurul Huda"], "author_detail": {"name": "Mohammad Nurul Huda"}, "author": "Mohammad Nurul Huda", "arxiv_comment": "9 pages Advances in Computing and Communications (ACC) 2011", "links": [{"href": "http://arxiv.org/abs/1310.1426v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1310.1426v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T50", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.2.7", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1310.1426v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1310.1426v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1911.11062v1", "guidislink": true, "updated": "2019-11-19T20:37:03Z", "updated_parsed": [2019, 11, 19, 20, 37, 3, 1, 323, 0], "published": "2019-11-19T20:37:03Z", "published_parsed": [2019, 11, 19, 20, 37, 3, 1, 323, 0], "title": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic Detection of Satire in Bangla Documents: A CNN Approach Based\n  on Hybrid Feature Extraction Model"}, "summary": "Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Widespread of satirical news in online communities is an ongoing trend. The\nnature of satires is so inherently ambiguous that sometimes it's too hard even\nfor humans to understand whether it's actually satire or not. So, research\ninterest has grown in this field. The purpose of this research is to detect\nBangla satirical news spread in online news portals as well as social media. In\nthis paper, we propose a hybrid technique for extracting features from text\ndocuments combining Word2Vec and TF-IDF. Using our proposed feature extraction\ntechnique, with standard CNN architecture we could detect whether a Bangla text\ndocument is satire or not with an accuracy of more than 96%."}, "authors": ["Arnab Sen Sharma", "Maruf Ahmed Mridul", "Md Saiful Islam"], "author_detail": {"name": "Md Saiful Islam"}, "author": "Md Saiful Islam", "arxiv_comment": "5 pages, Conference paper", "links": [{"href": "http://arxiv.org/abs/1911.11062v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1911.11062v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1911.11062v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1911.11062v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2001.05316v1", "guidislink": true, "updated": "2020-01-11T14:54:04Z", "updated_parsed": [2020, 1, 11, 14, 54, 4, 5, 11, 0], "published": "2020-01-11T14:54:04Z", "published_parsed": [2020, 1, 11, 14, 54, 4, 5, 11, 0], "title": "Authorship Attribution in Bangla literature using Character-level CNN", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Authorship Attribution in Bangla literature using Character-level CNN"}, "summary": "Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Characters are the smallest unit of text that can extract stylometric signals\nto determine the author of a text. In this paper, we investigate the\neffectiveness of character-level signals in Authorship Attribution of Bangla\nLiterature and show that the results are promising but improvable. The time and\nmemory efficiency of the proposed model is much higher than the word level\ncounterparts but accuracy is 2-5% less than the best performing word-level\nmodels. Comparison of various word-based models is performed and shown that the\nproposed model performs increasingly better with larger datasets. We also\nanalyze the effect of pre-training character embedding of diverse Bangla\ncharacter set in authorship attribution. It is seen that the performance is\nimproved by up to 10% on pre-training. We used 2 datasets from 6 to 14 authors,\nbalancing them before training and compare the results."}, "authors": ["Aisha Khatun", "Anisur Rahman", "Md. Saiful Islam", "Marium-E-Jannat"], "author_detail": {"name": "Marium-E-Jannat"}, "author": "Marium-E-Jannat", "arxiv_comment": "5 pages", "links": [{"href": "http://arxiv.org/abs/2001.05316v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2001.05316v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2001.05316v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2001.05316v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2004.08789v1", "guidislink": true, "updated": "2020-04-19T07:42:22Z", "updated_parsed": [2020, 4, 19, 7, 42, 22, 6, 110, 0], "published": "2020-04-19T07:42:22Z", "published_parsed": [2020, 4, 19, 7, 42, 22, 6, 110, 0], "title": "BanFakeNews: A Dataset for Detecting Fake News in Bangla", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanFakeNews: A Dataset for Detecting Fake News in Bangla"}, "summary": "Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages."}, "authors": ["Md Zobaer Hossain", "Md Ashraful Rahman", "Md Saiful Islam", "Sudipta Kar"], "author_detail": {"name": "Sudipta Kar"}, "author": "Sudipta Kar", "arxiv_comment": "LREC 2020", "links": [{"href": "http://arxiv.org/abs/2004.08789v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.08789v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.08789v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.08789v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2010.13404v2", "guidislink": true, "updated": "2021-01-12T13:51:27Z", "updated_parsed": [2021, 1, 12, 13, 51, 27, 1, 12, 0], "published": "2020-10-26T08:00:48Z", "published_parsed": [2020, 10, 26, 8, 0, 48, 0, 300, 0], "title": "Robust and Consistent Estimation of Word Embedding for Bangla Language\n  by fine-tuning Word2Vec Model", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Robust and Consistent Estimation of Word Embedding for Bangla Language\n  by fine-tuning Word2Vec Model"}, "summary": "In recent times, data is growing rapidly in every domain such as news, social\nmedia, banking, education, etc. Due to the excessiveness of data, there is a\nneed for an automatic keyword extractor that can help to summarize the data.\nKeyword extraction is a text analysis technique that consists of automatically\nextracting the most important words and expressions in a text. It helps\nsummarize the content of a text and recognize the main topics which are being\ndiscussed. Earlier works regarding this topic have been done but no significant\nwork was done for the Bangla language. So, we tried to achieve the same things\nwhich could be done with other languages in the Bangla language.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In recent times, data is growing rapidly in every domain such as news, social\nmedia, banking, education, etc. Due to the excessiveness of data, there is a\nneed for an automatic keyword extractor that can help to summarize the data.\nKeyword extraction is a text analysis technique that consists of automatically\nextracting the most important words and expressions in a text. It helps\nsummarize the content of a text and recognize the main topics which are being\ndiscussed. Earlier works regarding this topic have been done but no significant\nwork was done for the Bangla language. So, we tried to achieve the same things\nwhich could be done with other languages in the Bangla language."}, "authors": ["Rifat Rahman"], "author_detail": {"name": "Rifat Rahman"}, "author": "Rifat Rahman", "arxiv_comment": "I have implemented some approaches that are wrong. Now I am fixing\n  these issues. The methodology used my previous script may be harmful for\n  relevant researchers", "links": [{"href": "http://arxiv.org/abs/2010.13404v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.13404v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.13404v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.13404v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.04446v1", "guidislink": true, "updated": "2020-11-09T14:12:07Z", "updated_parsed": [2020, 11, 9, 14, 12, 7, 0, 314, 0], "published": "2020-11-09T14:12:07Z", "published_parsed": [2020, 11, 9, 14, 12, 7, 0, 314, 0], "title": "Bangla Text Classification using Transformers", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bangla Text Classification using Transformers"}, "summary": "Text classification has been one of the earliest problems in NLP. Over time\nthe scope of application areas has broadened and the difficulty of dealing with\nnew areas (e.g., noisy social media content) has increased. The problem-solving\nstrategy switched from classical machine learning to deep learning algorithms.\nOne of the recent deep neural network architecture is the Transformer. Models\ndesigned with this type of network and its variants recently showed their\nsuccess in many downstream natural language processing tasks, especially for\nresource-rich languages, e.g., English. However, these models have not been\nexplored fully for Bangla text classification tasks. In this work, we fine-tune\nmultilingual transformer models for Bangla text classification tasks in\ndifferent domains, including sentiment analysis, emotion detection, news\ncategorization, and authorship attribution. We obtain the state of the art\nresults on six benchmark datasets, improving upon the previous results by 5-29%\naccuracy across different tasks.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Text classification has been one of the earliest problems in NLP. Over time\nthe scope of application areas has broadened and the difficulty of dealing with\nnew areas (e.g., noisy social media content) has increased. The problem-solving\nstrategy switched from classical machine learning to deep learning algorithms.\nOne of the recent deep neural network architecture is the Transformer. Models\ndesigned with this type of network and its variants recently showed their\nsuccess in many downstream natural language processing tasks, especially for\nresource-rich languages, e.g., English. However, these models have not been\nexplored fully for Bangla text classification tasks. In this work, we fine-tune\nmultilingual transformer models for Bangla text classification tasks in\ndifferent domains, including sentiment analysis, emotion detection, news\ncategorization, and authorship attribution. We obtain the state of the art\nresults on six benchmark datasets, improving upon the previous results by 5-29%\naccuracy across different tasks."}, "authors": ["Tanvirul Alam", "Akib Khan", "Firoj Alam"], "author_detail": {"name": "Firoj Alam"}, "author": "Firoj Alam", "links": [{"href": "http://arxiv.org/abs/2011.04446v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.04446v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.04446v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.04446v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2011.07499v2", "guidislink": true, "updated": "2020-12-08T09:30:02Z", "updated_parsed": [2020, 12, 8, 9, 30, 2, 1, 343, 0], "published": "2020-11-15T11:08:53Z", "published_parsed": [2020, 11, 15, 11, 8, 53, 6, 320, 0], "title": "BanglaWriting: A multi-purpose offline Bangla handwriting dataset", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "BanglaWriting: A multi-purpose offline Bangla handwriting dataset"}, "summary": "This article presents a Bangla handwriting dataset named BanglaWriting that\ncontains single-page handwritings of 260 individuals of different personalities\nand ages. Each page includes bounding-boxes that bounds each word, along with\nthe unicode representation of the writing. This dataset contains 21,234 words\nand 32,787 characters in total. Moreover, this dataset includes 5,470 unique\nwords of Bangla vocabulary. Apart from the usual words, the dataset comprises\n261 comprehensible overwriting and 450 handwritten strikes and mistakes. All of\nthe bounding-boxes and word labels are manually-generated. The dataset can be\nused for complex optical character/word recognition, writer identification,\nhandwritten word segmentation, and word generation. Furthermore, this dataset\nis suitable for extracting age-based and gender-based variation of handwriting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This article presents a Bangla handwriting dataset named BanglaWriting that\ncontains single-page handwritings of 260 individuals of different personalities\nand ages. Each page includes bounding-boxes that bounds each word, along with\nthe unicode representation of the writing. This dataset contains 21,234 words\nand 32,787 characters in total. Moreover, this dataset includes 5,470 unique\nwords of Bangla vocabulary. Apart from the usual words, the dataset comprises\n261 comprehensible overwriting and 450 handwritten strikes and mistakes. All of\nthe bounding-boxes and word labels are manually-generated. The dataset can be\nused for complex optical character/word recognition, writer identification,\nhandwritten word segmentation, and word generation. Furthermore, this dataset\nis suitable for extracting age-based and gender-based variation of handwriting."}, "authors": ["M. F. Mridha", "Abu Quwsar Ohi", "M. Ameer Ali", "Mazedul Islam Emon", "Muhammad Mohsin Kabir"], "author_detail": {"name": "Muhammad Mohsin Kabir"}, "author": "Muhammad Mohsin Kabir", "arxiv_comment": "Accepted in journal Data in Brief. The dataset is available on\n  https://data.mendeley.com/datasets/r43wkvdk4w/", "links": [{"href": "http://arxiv.org/abs/2011.07499v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2011.07499v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2011.07499v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2011.07499v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1901.05613v1", "guidislink": true, "updated": "2019-01-17T04:27:34Z", "updated_parsed": [2019, 1, 17, 4, 27, 34, 3, 17, 0], "published": "2019-01-17T04:27:34Z", "published_parsed": [2019, 1, 17, 4, 27, 34, 3, 17, 0], "title": "Hand Sign to Bangla Speech: A Deep Learning in Vision based system for\n  Recognizing Hand Sign Digits and Generating Bangla Speech", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Hand Sign to Bangla Speech: A Deep Learning in Vision based system for\n  Recognizing Hand Sign Digits and Generating Bangla Speech"}, "summary": "Recent advancements in the field of computer vision with the help of deep\nneural networks have led us to explore and develop many existing challenges\nthat were once unattended due to the lack of necessary technologies. Hand\nSign/Gesture Recognition is one of the significant areas where the deep neural\nnetwork is making a substantial impact. In the last few years, a large number\nof researches has been conducted to recognize hand signs and hand gestures,\nwhich we aim to extend to our mother-tongue, Bangla (also known as Bengali).\nThe primary goal of our work is to make an automated tool to aid the people who\nare unable to speak. We developed a system that automatically detects hand sign\nbased digits and speaks out the result in Bangla language. According to the\nreport of the World Health Organization (WHO), 15% of people in the world live\nwith some kind of disabilities. Among them, individuals with communication\nimpairment such as speech disabilities experience substantial barrier in social\ninteraction. The proposed system can be invaluable to mitigate such a barrier.\nThe core of the system is built with a deep learning model which is based on\nconvolutional neural networks (CNN). The model classifies hand sign based\ndigits with 92% accuracy over validation data which ensures it a highly\ntrustworthy system. Upon classification of the digits, the resulting output is\nfed to the text to speech engine and the translator unit eventually which\ngenerates audio output in Bangla language. A web application to demonstrate our\ntool is available at http://bit.ly/signdigits2banglaspeech.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Recent advancements in the field of computer vision with the help of deep\nneural networks have led us to explore and develop many existing challenges\nthat were once unattended due to the lack of necessary technologies. Hand\nSign/Gesture Recognition is one of the significant areas where the deep neural\nnetwork is making a substantial impact. In the last few years, a large number\nof researches has been conducted to recognize hand signs and hand gestures,\nwhich we aim to extend to our mother-tongue, Bangla (also known as Bengali).\nThe primary goal of our work is to make an automated tool to aid the people who\nare unable to speak. We developed a system that automatically detects hand sign\nbased digits and speaks out the result in Bangla language. According to the\nreport of the World Health Organization (WHO), 15% of people in the world live\nwith some kind of disabilities. Among them, individuals with communication\nimpairment such as speech disabilities experience substantial barrier in social\ninteraction. The proposed system can be invaluable to mitigate such a barrier.\nThe core of the system is built with a deep learning model which is based on\nconvolutional neural networks (CNN). The model classifies hand sign based\ndigits with 92% accuracy over validation data which ensures it a highly\ntrustworthy system. Upon classification of the digits, the resulting output is\nfed to the text to speech engine and the translator unit eventually which\ngenerates audio output in Bangla language. A web application to demonstrate our\ntool is available at http://bit.ly/signdigits2banglaspeech."}, "authors": ["Shahjalal Ahmed", "Md. Rafiqul Islam", "Jahid Hassan", "Minhaz Uddin Ahmed", "Bilkis Jamal Ferdosi", "Sanjay Saha", "Md. Shopon"], "author_detail": {"name": "Md. Shopon"}, "author": "Md. Shopon", "links": [{"href": "http://arxiv.org/abs/1901.05613v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1901.05613v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1901.05613v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1901.05613v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.08706v1", "guidislink": true, "updated": "2017-01-27T12:54:52Z", "updated_parsed": [2017, 1, 27, 12, 54, 52, 4, 27, 0], "published": "2017-01-27T12:54:52Z", "published_parsed": [2017, 1, 27, 12, 54, 52, 4, 27, 0], "title": "Document Decomposition of Bangla Printed Text", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Document Decomposition of Bangla Printed Text"}, "summary": "Today all kind of information is getting digitized and along with all this\ndigitization, the huge archive of various kinds of documents is being digitized\ntoo. We know that, Optical Character Recognition is the method through which,\nnewspapers and other paper documents convert into digital resources. But, it is\na fact that this method works on texts only. As a result, if we try to process\nany document which contains non-textual zones, then we will get garbage texts\nas output. That is why; in order to digitize documents properly they should be\nprepossessed carefully. And while preprocessing, segmenting document in\ndifferent regions according to the category properly is most important. But,\nthe Optical Character Recognition processes available for Bangla language have\nno such algorithm that can categorize a newspaper/book page fully. So we worked\nto decompose a document into its several parts like headlines, sub headlines,\ncolumns, images etc. And if the input is skewed and rotated, then the input was\nalso deskewed and de-rotated. To decompose any Bangla document we found out the\nedges of the input image. Then we find out the horizontal and vertical area of\nevery pixel where it lies in. Later on the input image was cut according to\nthese areas. Then we pick each and every sub image and found out their\nheight-width ratio, line height. Then according to these values the sub images\nwere categorized. To deskew the image we found out the skew angle and de skewed\nthe image according to this angle. To de-rotate the image we used the line\nheight, matra line, pixel ratio of matra line.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=30&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Today all kind of information is getting digitized and along with all this\ndigitization, the huge archive of various kinds of documents is being digitized\ntoo. We know that, Optical Character Recognition is the method through which,\nnewspapers and other paper documents convert into digital resources. But, it is\na fact that this method works on texts only. As a result, if we try to process\nany document which contains non-textual zones, then we will get garbage texts\nas output. That is why; in order to digitize documents properly they should be\nprepossessed carefully. And while preprocessing, segmenting document in\ndifferent regions according to the category properly is most important. But,\nthe Optical Character Recognition processes available for Bangla language have\nno such algorithm that can categorize a newspaper/book page fully. So we worked\nto decompose a document into its several parts like headlines, sub headlines,\ncolumns, images etc. And if the input is skewed and rotated, then the input was\nalso deskewed and de-rotated. To decompose any Bangla document we found out the\nedges of the input image. Then we find out the horizontal and vertical area of\nevery pixel where it lies in. Later on the input image was cut according to\nthese areas. Then we pick each and every sub image and found out their\nheight-width ratio, line height. Then according to these values the sub images\nwere categorized. To deskew the image we found out the skew angle and de skewed\nthe image according to this angle. To de-rotate the image we used the line\nheight, matra line, pixel ratio of matra line."}, "authors": ["Md. Fahad Hasan", "Tasmin Afroz", "Sabir Ismail", "Md. Saiful Islam"], "author_detail": {"name": "Md. Saiful Islam"}, "author": "Md. Saiful Islam", "arxiv_comment": "6 pages", "links": [{"href": "http://arxiv.org/abs/1701.08706v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08706v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08706v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08706v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1707.08398v1", "guidislink": true, "updated": "2017-07-26T12:03:39Z", "updated_parsed": [2017, 7, 26, 12, 3, 39, 2, 207, 0], "published": "2017-07-26T12:03:39Z", "published_parsed": [2017, 7, 26, 12, 3, 39, 2, 207, 0], "title": "A Harmony Search Based Wrapper Feature Selection Method for Holistic\n  Bangla word Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Harmony Search Based Wrapper Feature Selection Method for Holistic\n  Bangla word Recognition"}, "summary": "A lot of search approaches have been explored for the selection of features\nin pattern classification domain in order to discover significant subset of the\nfeatures which produces better accuracy. In this paper, we introduced a Harmony\nSearch (HS) algorithm based feature selection method for feature dimensionality\nreduction in handwritten Bangla word recognition problem. This algorithm has\nbeen implemented to reduce the feature dimensionality of a technique described\nin one of our previous papers by S. Bhowmik et al.[1]. In the said paper, a set\nof 65 elliptical features were computed for handwritten Bangla word recognition\npurpose and a recognition accuracy of 81.37% was achieved using Multi Layer\nPerceptron (MLP) classifier. In the present work, a subset containing 48\nfeatures (approximately 75% of said feature vector) has been selected by HS\nbased wrapper feature selection method which produces an accuracy rate of\n90.29%. Reasonable outcomes also validates that the introduced algorithm\nutilizes optimal number of features while showing higher classification\naccuracies when compared to two standard evolutionary algorithms like Genetic\nAlgorithm (GA), Particle Swarm Optimization (PSO) and statistical feature\ndimensionality reduction technique like Principal Component Analysis (PCA).\nThis confirms the suitability of HS algorithm to the holistic handwritten word\nrecognition problem.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A lot of search approaches have been explored for the selection of features\nin pattern classification domain in order to discover significant subset of the\nfeatures which produces better accuracy. In this paper, we introduced a Harmony\nSearch (HS) algorithm based feature selection method for feature dimensionality\nreduction in handwritten Bangla word recognition problem. This algorithm has\nbeen implemented to reduce the feature dimensionality of a technique described\nin one of our previous papers by S. Bhowmik et al.[1]. In the said paper, a set\nof 65 elliptical features were computed for handwritten Bangla word recognition\npurpose and a recognition accuracy of 81.37% was achieved using Multi Layer\nPerceptron (MLP) classifier. In the present work, a subset containing 48\nfeatures (approximately 75% of said feature vector) has been selected by HS\nbased wrapper feature selection method which produces an accuracy rate of\n90.29%. Reasonable outcomes also validates that the introduced algorithm\nutilizes optimal number of features while showing higher classification\naccuracies when compared to two standard evolutionary algorithms like Genetic\nAlgorithm (GA), Particle Swarm Optimization (PSO) and statistical feature\ndimensionality reduction technique like Principal Component Analysis (PCA).\nThis confirms the suitability of HS algorithm to the holistic handwritten word\nrecognition problem."}, "authors": ["Supratim Das", "Pawan Kumar Singh", "Showmik Bhowmik", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/1707.08398v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1707.08398v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68T10", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1707.08398v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1707.08398v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1501.05497v1", "guidislink": true, "updated": "2015-01-22T13:50:25Z", "updated_parsed": [2015, 1, 22, 13, 50, 25, 3, 22, 0], "published": "2015-01-22T13:50:25Z", "published_parsed": [2015, 1, 22, 13, 50, 25, 3, 22, 0], "title": "An Improved Feature Descriptor for Recognition of Handwritten Bangla\n  Alphabet", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An Improved Feature Descriptor for Recognition of Handwritten Bangla\n  Alphabet"}, "summary": "Appropriate feature set for representation of pattern classes is one of the\nmost important aspects of handwritten character recognition. The effectiveness\nof features depends on the discriminating power of the features chosen to\nrepresent patterns of different classes. However, discriminatory features are\nnot easily measurable. Investigative experimentation is necessary for\nidentifying discriminatory features. In the present work we have identified a\nnew variation of feature set which significantly outperforms on handwritten\nBangla alphabet from the previously used feature set. 132 number of features in\nall viz. modified shadow features, octant and centroid features, distance based\nfeatures, quad tree based longest run features are used here. Using this\nfeature set the recognition performance increases sharply from the 75.05%\nobserved in our previous work [7], to 85.40% on 50 character classes with MLP\nbased classifier on the same dataset.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Appropriate feature set for representation of pattern classes is one of the\nmost important aspects of handwritten character recognition. The effectiveness\nof features depends on the discriminating power of the features chosen to\nrepresent patterns of different classes. However, discriminatory features are\nnot easily measurable. Investigative experimentation is necessary for\nidentifying discriminatory features. In the present work we have identified a\nnew variation of feature set which significantly outperforms on handwritten\nBangla alphabet from the previously used feature set. 132 number of features in\nall viz. modified shadow features, octant and centroid features, distance based\nfeatures, quad tree based longest run features are used here. Using this\nfeature set the recognition performance increases sharply from the 75.05%\nobserved in our previous work [7], to 85.40% on 50 character classes with MLP\nbased classifier on the same dataset."}, "authors": ["Nibaran Das", "Subhadip Basu", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri", "Dipak kumar Basu"], "author_detail": {"name": "Dipak kumar Basu"}, "author": "Dipak kumar Basu", "arxiv_comment": "In proceedings of ICSIP 2009, pp. 451 to 454, August 2009, Mysore,\n  India. arXiv admin note: substantial text overlap with arXiv:1203.0882,\n  arXiv:1002.4040, arXiv:1410.0478", "links": [{"href": "http://arxiv.org/abs/1501.05497v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1501.05497v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1501.05497v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1501.05497v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.01434v1", "guidislink": true, "updated": "2017-12-05T01:12:25Z", "updated_parsed": [2017, 12, 5, 1, 12, 25, 1, 339, 0], "published": "2017-12-05T01:12:25Z", "published_parsed": [2017, 12, 5, 1, 12, 25, 1, 339, 0], "title": "Zone-based Keyword Spotting in Bangla and Devanagari Documents", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Zone-based Keyword Spotting in Bangla and Devanagari Documents"}, "summary": "In this paper we present a word spotting system in text lines for offline\nIndic scripts such as Bangla (Bengali) and Devanagari. Recently, it was shown\nthat zone-wise recognition method improves the word recognition performance\nthan conventional full word recognition system in Indic scripts. Inspired with\nthis idea we consider the zone segmentation approach and use middle zone\ninformation to improve the traditional word spotting performance. To avoid the\nproblem of zone segmentation using heuristic approach, we propose here an HMM\nbased approach to segment the upper and lower zone components from the text\nline images. The candidate keywords are searched from a line without segmenting\ncharacters or words. Also, we propose a novel feature combining foreground and\nbackground information of text line images for keyword-spotting by character\nfiller models. A significant improvement in performance is noted by using both\nforeground and background information than their individual one. Pyramid\nHistogram of Oriented Gradient (PHOG) feature has been used in our word\nspotting framework. From the experiment, it has been noted that the proposed\nzone-segmentation based system outperforms traditional approaches of word\nspotting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper we present a word spotting system in text lines for offline\nIndic scripts such as Bangla (Bengali) and Devanagari. Recently, it was shown\nthat zone-wise recognition method improves the word recognition performance\nthan conventional full word recognition system in Indic scripts. Inspired with\nthis idea we consider the zone segmentation approach and use middle zone\ninformation to improve the traditional word spotting performance. To avoid the\nproblem of zone segmentation using heuristic approach, we propose here an HMM\nbased approach to segment the upper and lower zone components from the text\nline images. The candidate keywords are searched from a line without segmenting\ncharacters or words. Also, we propose a novel feature combining foreground and\nbackground information of text line images for keyword-spotting by character\nfiller models. A significant improvement in performance is noted by using both\nforeground and background information than their individual one. Pyramid\nHistogram of Oriented Gradient (PHOG) feature has been used in our word\nspotting framework. From the experiment, it has been noted that the proposed\nzone-segmentation based system outperforms traditional approaches of word\nspotting."}, "authors": ["Ayan Kumar Bhunia", "Partha Pratim Roy", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "arxiv_comment": "Preprint Submitted", "links": [{"href": "http://arxiv.org/abs/1712.01434v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.01434v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.01434v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.01434v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1802.00671v1", "guidislink": true, "updated": "2018-02-02T13:06:43Z", "updated_parsed": [2018, 2, 2, 13, 6, 43, 4, 33, 0], "published": "2018-02-02T13:06:43Z", "published_parsed": [2018, 2, 2, 13, 6, 43, 4, 33, 0], "title": "Handwritten Isolated Bangla Compound Character Recognition: a new\n  benchmark using a novel deep learning approach", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten Isolated Bangla Compound Character Recognition: a new\n  benchmark using a novel deep learning approach"}, "summary": "In this work, a novel deep learning technique for the recognition of\nhandwritten Bangla isolated compound character is presented and a new benchmark\nof recognition accuracy on the CMATERdb 3.1.3.3 dataset is reported. Greedy\nlayer wise training of Deep Neural Network has helped to make significant\nstrides in various pattern recognition problems. We employ layerwise training\nto Deep Convolutional Neural Networks (DCNN) in a supervised fashion and\naugment the training process with the RMSProp algorithm to achieve faster\nconvergence. We compare results with those obtained from standard shallow\nlearning methods with predefined features, as well as standard DCNNs.\nSupervised layerwise trained DCNNs are found to outperform standard shallow\nlearning models such as Support Vector Machines as well as regular DCNNs of\nsimilar architecture by achieving error rate of 9.67% thereby setting a new\nbenchmark on the CMATERdb 3.1.3.3 with recognition accuracy of 90.33%,\nrepresenting an improvement of nearly 10%.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this work, a novel deep learning technique for the recognition of\nhandwritten Bangla isolated compound character is presented and a new benchmark\nof recognition accuracy on the CMATERdb 3.1.3.3 dataset is reported. Greedy\nlayer wise training of Deep Neural Network has helped to make significant\nstrides in various pattern recognition problems. We employ layerwise training\nto Deep Convolutional Neural Networks (DCNN) in a supervised fashion and\naugment the training process with the RMSProp algorithm to achieve faster\nconvergence. We compare results with those obtained from standard shallow\nlearning methods with predefined features, as well as standard DCNNs.\nSupervised layerwise trained DCNNs are found to outperform standard shallow\nlearning models such as Support Vector Machines as well as regular DCNNs of\nsimilar architecture by achieving error rate of 9.67% thereby setting a new\nbenchmark on the CMATERdb 3.1.3.3 with recognition accuracy of 90.33%,\nrepresenting an improvement of nearly 10%."}, "authors": ["Saikat Roy", "Nibaran Das", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patrec.2017.03.004", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1802.00671v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1802.00671v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1802.00671v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1802.00671v1", "arxiv_comment": null, "journal_reference": "Pattern Recognition Letters, Elsevier, Vol. 90, Pages 15-21, 2017", "doi": "10.1016/j.patrec.2017.03.004"}
{"id": "http://arxiv.org/abs/1806.08037v1", "guidislink": true, "updated": "2018-06-21T01:30:30Z", "updated_parsed": [2018, 6, 21, 1, 30, 30, 3, 172, 0], "published": "2018-06-21T01:30:30Z", "published_parsed": [2018, 6, 21, 1, 30, 30, 3, 172, 0], "title": "Pixel-level Reconstruction and Classification for Noisy Handwritten\n  Bangla Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Pixel-level Reconstruction and Classification for Noisy Handwritten\n  Bangla Characters"}, "summary": "Classification techniques for images of handwritten characters are\nsusceptible to noise. Quadtrees can be an efficient representation for learning\nfrom sparse features. In this paper, we improve the effectiveness of\nprobabilistic quadtrees by using a pixel level classifier to extract the\ncharacter pixels and remove noise from handwritten character images. The pixel\nlevel denoiser (a deep belief network) uses the map responses obtained from a\npretrained CNN as features for reconstructing the characters eliminating noise.\nWe experimentally demonstrate the effectiveness of our approach by\nreconstructing and classifying a noisy version of handwritten Bangla Numeral\nand Basic Character datasets.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Classification techniques for images of handwritten characters are\nsusceptible to noise. Quadtrees can be an efficient representation for learning\nfrom sparse features. In this paper, we improve the effectiveness of\nprobabilistic quadtrees by using a pixel level classifier to extract the\ncharacter pixels and remove noise from handwritten character images. The pixel\nlevel denoiser (a deep belief network) uses the map responses obtained from a\npretrained CNN as features for reconstructing the characters eliminating noise.\nWe experimentally demonstrate the effectiveness of our approach by\nreconstructing and classifying a noisy version of handwritten Bangla Numeral\nand Basic Character datasets."}, "authors": ["Manohar Karki", "Qun Liu", "Robert DiBiano", "Saikat Basu", "Supratik Mukhopadhyay"], "author_detail": {"name": "Supratik Mukhopadhyay"}, "author": "Supratik Mukhopadhyay", "arxiv_comment": "Paper was accepted at the 16th International Conference on Frontiers\n  in Handwriting Recognition (ICFHR 2018)", "links": [{"href": "http://arxiv.org/abs/1806.08037v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1806.08037v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1806.08037v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1806.08037v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1907.07826v1", "guidislink": true, "updated": "2019-07-18T01:00:42Z", "updated_parsed": [2019, 7, 18, 1, 0, 42, 3, 199, 0], "published": "2019-07-18T01:00:42Z", "published_parsed": [2019, 7, 18, 1, 0, 42, 3, 199, 0], "title": "Comparison of Classical Machine Learning Approaches on Bangla Textual\n  Emotion Analysis", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Comparison of Classical Machine Learning Approaches on Bangla Textual\n  Emotion Analysis"}, "summary": "Detecting emotions from text is an extension of simple sentiment polarity\ndetection. Instead of considering only positive or negative sentiments,\nemotions are conveyed using more tangible manner; thus, they can be expressed\nas many shades of gray. This paper manifests the results of our experimentation\nfor fine-grained emotion analysis on Bangla text. We gathered and annotated a\ntext corpus consisting of user comments from several Facebook groups regarding\nsocio-economic and political issues, and we made efforts to extract the basic\nemotions (sadness, happiness, disgust, surprise, fear, anger) conveyed through\nthese comments. Finally, we compared the results of the five most popular\nclassical machine learning techniques namely Naive Bayes, Decision Tree,\nk-Nearest Neighbor (k-NN), Support Vector Machine (SVM) and K-Means Clustering\nwith several combinations of features. Our best model (SVM with a non-linear\nradial-basis function (RBF) kernel) achieved an overall average accuracy score\nof 52.98% and an F1 score (macro) of 0.3324", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Detecting emotions from text is an extension of simple sentiment polarity\ndetection. Instead of considering only positive or negative sentiments,\nemotions are conveyed using more tangible manner; thus, they can be expressed\nas many shades of gray. This paper manifests the results of our experimentation\nfor fine-grained emotion analysis on Bangla text. We gathered and annotated a\ntext corpus consisting of user comments from several Facebook groups regarding\nsocio-economic and political issues, and we made efforts to extract the basic\nemotions (sadness, happiness, disgust, surprise, fear, anger) conveyed through\nthese comments. Finally, we compared the results of the five most popular\nclassical machine learning techniques namely Naive Bayes, Decision Tree,\nk-Nearest Neighbor (k-NN), Support Vector Machine (SVM) and K-Means Clustering\nwith several combinations of features. Our best model (SVM with a non-linear\nradial-basis function (RBF) kernel) achieved an overall average accuracy score\nof 52.98% and an F1 score (macro) of 0.3324"}, "authors": ["Md. Ataur Rahman", "Md. Hanif Seddiqui"], "author_detail": {"name": "Md. Hanif Seddiqui"}, "author": "Md. Hanif Seddiqui", "links": [{"href": "http://arxiv.org/abs/1907.07826v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1907.07826v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1907.07826v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1907.07826v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1908.08987v1", "guidislink": true, "updated": "2019-08-11T08:01:58Z", "updated_parsed": [2019, 8, 11, 8, 1, 58, 6, 223, 0], "published": "2019-08-11T08:01:58Z", "published_parsed": [2019, 8, 11, 8, 1, 58, 6, 223, 0], "title": "PCGAN-CHAR: Progressively Trained Classifier Generative Adversarial\n  Networks for Classification of Noisy Handwritten Bangla Characters", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "PCGAN-CHAR: Progressively Trained Classifier Generative Adversarial\n  Networks for Classification of Noisy Handwritten Bangla Characters"}, "summary": "Due to the sparsity of features, noise has proven to be a great inhibitor in\nthe classification of handwritten characters. To combat this, most techniques\nperform denoising of the data before classification. In this paper, we\nconsolidate the approach by training an all-in-one model that is able to\nclassify even noisy characters. For classification, we progressively train a\nclassifier generative adversarial network on the characters from low to high\nresolution. We show that by learning the features at each resolution\nindependently a trained model is able to accurately classify characters even in\nthe presence of noise. We experimentally demonstrate the effectiveness of our\napproach by classifying noisy versions of MNIST, handwritten Bangla Numeral,\nand Basic Character datasets.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Due to the sparsity of features, noise has proven to be a great inhibitor in\nthe classification of handwritten characters. To combat this, most techniques\nperform denoising of the data before classification. In this paper, we\nconsolidate the approach by training an all-in-one model that is able to\nclassify even noisy characters. For classification, we progressively train a\nclassifier generative adversarial network on the characters from low to high\nresolution. We show that by learning the features at each resolution\nindependently a trained model is able to accurately classify characters even in\nthe presence of noise. We experimentally demonstrate the effectiveness of our\napproach by classifying noisy versions of MNIST, handwritten Bangla Numeral,\nand Basic Character datasets."}, "authors": ["Qun Liu", "Edward Collier", "Supratik Mukhopadhyay"], "author_detail": {"name": "Supratik Mukhopadhyay"}, "author": "Supratik Mukhopadhyay", "arxiv_comment": "Paper was accepted at the 21st International Conference on\n  Asia-Pacific Digital Libraries (ICADL 2019)", "links": [{"href": "http://arxiv.org/abs/1908.08987v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1908.08987v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1908.08987v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1908.08987v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1912.11612v1", "guidislink": true, "updated": "2019-12-25T07:31:44Z", "updated_parsed": [2019, 12, 25, 7, 31, 44, 2, 359, 0], "published": "2019-12-25T07:31:44Z", "published_parsed": [2019, 12, 25, 7, 31, 44, 2, 359, 0], "title": "N-gram Statistical Stemmer for Bangla Corpus", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "N-gram Statistical Stemmer for Bangla Corpus"}, "summary": "Stemming is a process that can be utilized to trim inflected words to stem or\nroot form. It is useful for enhancing the retrieval effectiveness, especially\nfor text search in order to solve the mismatch problems. Previous research on\nBangla stemming mostly relied on eliminating multiple suffixes from a solitary\nword through a recursive rule based procedure to recover progressively\napplicable relative root. Our proposed system has enhanced the aforementioned\nexploration by actualizing one of the stemming algorithms called N-gram\nstemming. By utilizing an affiliation measure called dice coefficient, related\nsets of words are clustered depending on their character structure. The\nsmallest word in one cluster may be considered as the stem. We additionally\nanalyzed Affinity Propagation clustering algorithms with coefficient similarity\nas well as with median similarity. Our result indicates N-gram stemming\ntechniques to be effective in general which gave us around 87% accurate\nclusters.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Stemming is a process that can be utilized to trim inflected words to stem or\nroot form. It is useful for enhancing the retrieval effectiveness, especially\nfor text search in order to solve the mismatch problems. Previous research on\nBangla stemming mostly relied on eliminating multiple suffixes from a solitary\nword through a recursive rule based procedure to recover progressively\napplicable relative root. Our proposed system has enhanced the aforementioned\nexploration by actualizing one of the stemming algorithms called N-gram\nstemming. By utilizing an affiliation measure called dice coefficient, related\nsets of words are clustered depending on their character structure. The\nsmallest word in one cluster may be considered as the stem. We additionally\nanalyzed Affinity Propagation clustering algorithms with coefficient similarity\nas well as with median similarity. Our result indicates N-gram stemming\ntechniques to be effective in general which gave us around 87% accurate\nclusters."}, "authors": ["Rabeya Sadia", "Md Ataur Rahman", "Md Hanif Seddiqui"], "author_detail": {"name": "Md Hanif Seddiqui"}, "author": "Md Hanif Seddiqui", "links": [{"href": "http://arxiv.org/abs/1912.11612v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1912.11612v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1912.11612v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1912.11612v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2004.12769v1", "guidislink": true, "updated": "2020-04-27T13:18:58Z", "updated_parsed": [2020, 4, 27, 13, 18, 58, 0, 118, 0], "published": "2020-04-27T13:18:58Z", "published_parsed": [2020, 4, 27, 13, 18, 58, 0, 118, 0], "title": "A Skip-connected Multi-column Network for Isolated Handwritten Bangla\n  Character and Digit recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Skip-connected Multi-column Network for Isolated Handwritten Bangla\n  Character and Digit recognition"}, "summary": "Finding local invariant patterns in handwrit-ten characters and/or digits for\noptical character recognition is a difficult task. Variations in writing styles\nfrom one person to another make this task challenging. We have proposed a\nnon-explicit feature extraction method using a multi-scale multi-column skip\nconvolutional neural network in this work. Local and global features extracted\nfrom different layers of the proposed architecture are combined to derive the\nfinal feature descriptor encoding a character or digit image. Our method is\nevaluated on four publicly available datasets of isolated handwritten Bangla\ncharacters and digits. Exhaustive comparative analysis against contemporary\nmethods establishes the efficacy of our proposed approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Finding local invariant patterns in handwrit-ten characters and/or digits for\noptical character recognition is a difficult task. Variations in writing styles\nfrom one person to another make this task challenging. We have proposed a\nnon-explicit feature extraction method using a multi-scale multi-column skip\nconvolutional neural network in this work. Local and global features extracted\nfrom different layers of the proposed architecture are combined to derive the\nfinal feature descriptor encoding a character or digit image. Our method is\nevaluated on four publicly available datasets of isolated handwritten Bangla\ncharacters and digits. Exhaustive comparative analysis against contemporary\nmethods establishes the efficacy of our proposed approach."}, "authors": ["Animesh Singh", "Ritesh Sarkhel", "Nibaran Das", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "links": [{"href": "http://arxiv.org/abs/2004.12769v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.12769v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.12769v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.12769v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2009.08037v1", "guidislink": true, "updated": "2020-09-17T03:14:27Z", "updated_parsed": [2020, 9, 17, 3, 14, 27, 3, 261, 0], "published": "2020-09-17T03:14:27Z", "published_parsed": [2020, 9, 17, 3, 14, 27, 3, 261, 0], "title": "Word Segmentation from Unconstrained Handwritten Bangla Document Images\n  using Distance Transform", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word Segmentation from Unconstrained Handwritten Bangla Document Images\n  using Distance Transform"}, "summary": "Segmentation of handwritten document images into text lines and words is one\nof the most significant and challenging tasks in the development of a complete\nOptical Character Recognition (OCR) system. This paper addresses the automatic\nsegmentation of text words directly from unconstrained Bangla handwritten\ndocument images. The popular Distance transform (DT) algorithm is applied for\nlocating the outer boundary of the word images. This technique is free from\ngenerating the over-segmented words. A simple post-processing procedure is\napplied to isolate the under-segmented word images, if any. The proposed\ntechnique is tested on 50 random images taken from CMATERdb1.1.1 database.\nSatisfactory result is achieved with a segmentation accuracy of 91.88% which\nconfirms the robustness of the proposed methodology.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=40&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Segmentation of handwritten document images into text lines and words is one\nof the most significant and challenging tasks in the development of a complete\nOptical Character Recognition (OCR) system. This paper addresses the automatic\nsegmentation of text words directly from unconstrained Bangla handwritten\ndocument images. The popular Distance transform (DT) algorithm is applied for\nlocating the outer boundary of the word images. This technique is free from\ngenerating the over-segmented words. A simple post-processing procedure is\napplied to isolate the under-segmented word images, if any. The proposed\ntechnique is tested on 50 random images taken from CMATERdb1.1.1 database.\nSatisfactory result is achieved with a segmentation accuracy of 91.88% which\nconfirms the robustness of the proposed methodology."}, "authors": ["Pawan Kumar Singh", "Shubham Sinha", "Sagnik Pal Chowdhury", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "12 pages, 5 figures, conference", "links": [{"href": "http://arxiv.org/abs/2009.08037v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2009.08037v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.MM", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "68U10, 68U15", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2009.08037v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2009.08037v1", "journal_reference": "7th International Conference on Advances in Communication, Network\n  and Computing (CNC),pp. 271-282, 2016", "doi": null}
{"id": "http://arxiv.org/abs/1206.0238v1", "guidislink": true, "updated": "2012-06-01T16:20:41Z", "updated_parsed": [2012, 6, 1, 16, 20, 41, 4, 153, 0], "published": "2012-06-01T16:20:41Z", "published_parsed": [2012, 6, 1, 16, 20, 41, 4, 153, 0], "title": "Rapid Feature Extraction for Optical Character Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Rapid Feature Extraction for Optical Character Recognition"}, "summary": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Feature extraction is one of the fundamental problems of character\nrecognition. The performance of character recognition system is depends on\nproper feature extraction and correct classifier selection. In this article, a\nrapid feature extraction method is proposed and named as Celled Projection (CP)\nthat compute the projection of each section formed through partitioning an\nimage. The recognition performance of the proposed method is compared with\nother widely used feature extraction methods that are intensively studied for\nmany different scripts in literature. The experiments have been conducted using\nBangla handwritten numerals along with three different well known classifiers\nwhich demonstrate comparable results including 94.12% recognition accuracy\nusing celled projection."}, "authors": ["M. Zahid Hossain", "M. Ashraful Amin", "Hong Yan"], "author_detail": {"name": "Hong Yan"}, "author": "Hong Yan", "arxiv_comment": "5 pages, 1 figure", "links": [{"href": "http://arxiv.org/abs/1206.0238v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1206.0238v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "I.5.2; I.7.5", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1206.0238v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1206.0238v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1701.08156v2", "guidislink": true, "updated": "2018-04-26T18:17:00Z", "updated_parsed": [2018, 4, 26, 18, 17, 0, 3, 116, 0], "published": "2017-01-27T12:38:47Z", "published_parsed": [2017, 1, 27, 12, 38, 47, 4, 27, 0], "title": "A Comprehensive Survey on Bengali Phoneme Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Comprehensive Survey on Bengali Phoneme Recognition"}, "summary": "Hidden Markov model based various phoneme recognition methods for Bengali\nlanguage is reviewed. Automatic phoneme recognition for Bengali language using\nmultilayer neural network is reviewed. Usefulness of multilayer neural network\nover single layer neural network is discussed. Bangla phonetic feature table\nconstruction and enhancement for Bengali speech recognition is also discussed.\nComparison among these methods is discussed.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Hidden Markov model based various phoneme recognition methods for Bengali\nlanguage is reviewed. Automatic phoneme recognition for Bengali language using\nmultilayer neural network is reviewed. Usefulness of multilayer neural network\nover single layer neural network is discussed. Bangla phonetic feature table\nconstruction and enhancement for Bengali speech recognition is also discussed.\nComparison among these methods is discussed."}, "authors": ["Sadia Tasnim Swarna", "Shamim Ehsan", "Md. Saiful Islam", "Marium E Jannat"], "author_detail": {"name": "Marium E Jannat"}, "author": "Marium E Jannat", "arxiv_comment": "7 pages, reference added in phoneme recognition methods", "links": [{"href": "http://arxiv.org/abs/1701.08156v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1701.08156v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.SD", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.SD", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1701.08156v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1701.08156v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2008.07853v1", "guidislink": true, "updated": "2020-08-18T11:02:25Z", "updated_parsed": [2020, 8, 18, 11, 2, 25, 1, 231, 0], "published": "2020-08-18T11:02:25Z", "published_parsed": [2020, 8, 18, 11, 2, 25, 1, 231, 0], "title": "Image Pre-processing on NumtaDB for Bengali Handwritten Digit\n  Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Image Pre-processing on NumtaDB for Bengali Handwritten Digit\n  Recognition"}, "summary": "NumtaDB is by far the largest data-set collection for handwritten digits in\nBengali. This is a diverse dataset containing more than 85000 images. But this\ndiversity also makes this dataset very difficult to work with. The goal of this\npaper is to find the benchmark for pre-processed images which gives good\naccuracy on any machine learning models. The reason being, there are no\navailable pre-processed data for Bengali digit recognition to work with like\nthe English digits for MNIST.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "NumtaDB is by far the largest data-set collection for handwritten digits in\nBengali. This is a diverse dataset containing more than 85000 images. But this\ndiversity also makes this dataset very difficult to work with. The goal of this\npaper is to find the benchmark for pre-processed images which gives good\naccuracy on any machine learning models. The reason being, there are no\navailable pre-processed data for Bengali digit recognition to work with like\nthe English digits for MNIST."}, "authors": ["Ovi Paul"], "author_detail": {"name": "Ovi Paul"}, "author": "Ovi Paul", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ICBSLP.2018.8554910", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/2008.07853v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2008.07853v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "5 pages, 8 figures and 4 tables", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2008.07853v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2008.07853v1", "journal_reference": "2018 International Conference on Bangla Speech and Language\n  Processing (ICBSLP), Sylhet, 2018, pp. 1-6", "doi": "10.1109/ICBSLP.2018.8554910"}
{"id": "http://arxiv.org/abs/1501.05495v1", "guidislink": true, "updated": "2015-01-22T13:46:06Z", "updated_parsed": [2015, 1, 22, 13, 46, 6, 3, 22, 0], "published": "2015-01-22T13:46:06Z", "published_parsed": [2015, 1, 22, 13, 46, 6, 3, 22, 0], "title": "A GA Based approach for selection of local features for recognition of\n  handwritten Bangla numerals", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A GA Based approach for selection of local features for recognition of\n  handwritten Bangla numerals"}, "summary": "Soft computing approaches are mainly designed to address the real world\nill-defined, imprecisely formulated problems, combining different kind of novel\nmodels of computation, such as neural networks, genetic algorithms (GAs.\nHandwritten digit recognition is a typical example of one such problem. In the\ncurrent work we have developed a two-pass approach where the first pass\nclassifier performs a coarse classification, based on some global features of\nthe input pattern by restricting the possibility of classification decisions\nwithin a group of classes, smaller than the number of classes considered\ninitially. In the second pass, the group specific classifiers concentrate on\nthe features extracted from the selected local regions, and refine the earlier\ndecision by combining the local and the global features for selecting the true\nclass of the input pattern from the group of candidate classes selected in the\nfirst pass. To optimize the selection of local regions a GA based approach has\nbeen developed here. The maximum recognition performance on Bangla digit\nsamples as achieved on the test set, during the first pass of the two pass\napproach is 93.35%. After combining the results of the two stage classifiers,\nan overall success rate of 95.25% is achieved.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Soft computing approaches are mainly designed to address the real world\nill-defined, imprecisely formulated problems, combining different kind of novel\nmodels of computation, such as neural networks, genetic algorithms (GAs.\nHandwritten digit recognition is a typical example of one such problem. In the\ncurrent work we have developed a two-pass approach where the first pass\nclassifier performs a coarse classification, based on some global features of\nthe input pattern by restricting the possibility of classification decisions\nwithin a group of classes, smaller than the number of classes considered\ninitially. In the second pass, the group specific classifiers concentrate on\nthe features extracted from the selected local regions, and refine the earlier\ndecision by combining the local and the global features for selecting the true\nclass of the input pattern from the group of candidate classes selected in the\nfirst pass. To optimize the selection of local regions a GA based approach has\nbeen developed here. The maximum recognition performance on Bangla digit\nsamples as achieved on the test set, during the first pass of the two pass\napproach is 93.35%. After combining the results of the two stage classifiers,\nan overall success rate of 95.25% is achieved."}, "authors": ["Nibaran Das", "Subhadip Basu", "Punam Kumar Saha", "Ram Sarkar", "Mahantapas Kundu", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "In proceedings of UB NE ASEE 2009 conference, University of\n  Bridgeport, USA", "links": [{"href": "http://arxiv.org/abs/1501.05495v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1501.05495v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1501.05495v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1501.05495v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1605.00420v1", "guidislink": true, "updated": "2016-05-02T10:28:07Z", "updated_parsed": [2016, 5, 2, 10, 28, 7, 0, 123, 0], "published": "2016-05-02T10:28:07Z", "published_parsed": [2016, 5, 2, 10, 28, 7, 0, 123, 0], "title": "An Enhanced Harmony Search Method for Bangla Handwritten Character\n  Recognition Using Region Sampling", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An Enhanced Harmony Search Method for Bangla Handwritten Character\n  Recognition Using Region Sampling"}, "summary": "Identification of minimum number of local regions of a handwritten character\nimage, containing well-defined discriminating features which are sufficient for\na minimal but complete description of the character is a challenging task. A\nnew region selection technique based on the idea of an enhanced Harmony Search\nmethodology has been proposed here. The powerful framework of Harmony Search\nhas been utilized to search the region space and detect only the most\ninformative regions for correctly recognizing the handwritten character. The\nproposed method has been tested on handwritten samples of Bangla Basic,\nCompound and mixed (Basic and Compound characters) characters separately with\nSVM based classifier using a longest run based feature-set obtained from the\nimage subregions formed by a CG based quad-tree partitioning approach. Applying\nthis methodology on the above mentioned three types of datasets, respectively\n43.75%, 12.5% and 37.5% gains have been achieved in terms of region reduction\nand 2.3%, 0.6% and 1.2% gains have been achieved in terms of recognition\naccuracy. The results show a sizeable reduction in the minimal number of\ndescriptive regions as well a significant increase in recognition accuracy for\nall the datasets using the proposed technique. Thus the time and cost related\nto feature extraction is decreased without dampening the corresponding\nrecognition accuracy.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Identification of minimum number of local regions of a handwritten character\nimage, containing well-defined discriminating features which are sufficient for\na minimal but complete description of the character is a challenging task. A\nnew region selection technique based on the idea of an enhanced Harmony Search\nmethodology has been proposed here. The powerful framework of Harmony Search\nhas been utilized to search the region space and detect only the most\ninformative regions for correctly recognizing the handwritten character. The\nproposed method has been tested on handwritten samples of Bangla Basic,\nCompound and mixed (Basic and Compound characters) characters separately with\nSVM based classifier using a longest run based feature-set obtained from the\nimage subregions formed by a CG based quad-tree partitioning approach. Applying\nthis methodology on the above mentioned three types of datasets, respectively\n43.75%, 12.5% and 37.5% gains have been achieved in terms of region reduction\nand 2.3%, 0.6% and 1.2% gains have been achieved in terms of recognition\naccuracy. The results show a sizeable reduction in the minimal number of\ndescriptive regions as well a significant increase in recognition accuracy for\nall the datasets using the proposed technique. Thus the time and cost related\nto feature extraction is decreased without dampening the corresponding\nrecognition accuracy."}, "authors": ["Ritesh Sarkhel", "Amit K Saha", "Nibaran Das"], "author_detail": {"name": "Nibaran Das"}, "author": "Nibaran Das", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1109/ReTIS.2015.7232899", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1605.00420v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1605.00420v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "2nd IEEE International Conference on Recent Trends in Information\n  Systems, 2015", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1605.00420v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1605.00420v1", "journal_reference": null, "doi": "10.1109/ReTIS.2015.7232899"}
{"id": "http://arxiv.org/abs/2101.05081v1", "guidislink": true, "updated": "2020-12-10T15:36:41Z", "updated_parsed": [2020, 12, 10, 15, 36, 41, 3, 345, 0], "published": "2020-12-10T15:36:41Z", "published_parsed": [2020, 12, 10, 15, 36, 41, 3, 345, 0], "title": "Deep Learning Approach Combining Lightweight CNN Architecture with\n  Transfer Learning: An Automatic Approach for the Detection and Recognition of\n  Bangladeshi Banknotes", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Deep Learning Approach Combining Lightweight CNN Architecture with\n  Transfer Learning: An Automatic Approach for the Detection and Recognition of\n  Bangladeshi Banknotes"}, "summary": "Automatic detection and recognition of banknotes can be a very useful\ntechnology for people with visual difficulties and also for the banks itself by\nproviding efficient management for handling different paper currencies.\nLightweight models can easily be integrated into any handy IoT based\ngadgets/devices. This article presents our experiments on several\nstate-of-the-art deep learning methods based on Lightweight Convolutional\nNeural Network architectures combining with transfer learning. ResNet152v2,\nMobileNet, and NASNetMobile were used as the base models with two different\ndatasets containing Bangladeshi banknote images. The Bangla Currency dataset\nhas 8000 Bangladeshi banknote images where the Bangla Money dataset consists of\n1970 images. The performances of the models were measured using both the\ndatasets and the combination of the two datasets. In order to achieve maximum\nefficiency, we used various augmentations, hyperparameter tuning, and\noptimizations techniques. We have achieved maximum test accuracy of 98.88\\% on\n8000 images dataset using MobileNet, 100\\% on the 1970 images dataset using\nNASNetMobile, and 97.77\\% on the combined dataset (9970 images) using\nMobileNet.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Automatic detection and recognition of banknotes can be a very useful\ntechnology for people with visual difficulties and also for the banks itself by\nproviding efficient management for handling different paper currencies.\nLightweight models can easily be integrated into any handy IoT based\ngadgets/devices. This article presents our experiments on several\nstate-of-the-art deep learning methods based on Lightweight Convolutional\nNeural Network architectures combining with transfer learning. ResNet152v2,\nMobileNet, and NASNetMobile were used as the base models with two different\ndatasets containing Bangladeshi banknote images. The Bangla Currency dataset\nhas 8000 Bangladeshi banknote images where the Bangla Money dataset consists of\n1970 images. The performances of the models were measured using both the\ndatasets and the combination of the two datasets. In order to achieve maximum\nefficiency, we used various augmentations, hyperparameter tuning, and\noptimizations techniques. We have achieved maximum test accuracy of 98.88\\% on\n8000 images dataset using MobileNet, 100\\% on the 1970 images dataset using\nNASNetMobile, and 97.77\\% on the combined dataset (9970 images) using\nMobileNet."}, "authors": ["Ali Hasan Md. Linkon", "Md. Mahir Labib", "Faisal Haque Bappy", "Soumik Sarker", "Marium-E-Jannat", "Md Saiful Islam"], "author_detail": {"name": "Md Saiful Islam"}, "author": "Md Saiful Islam", "arxiv_comment": "4 pages", "links": [{"href": "http://arxiv.org/abs/2101.05081v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2101.05081v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.AI", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2101.05081v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2101.05081v1", "journal_reference": "2020 11th International Conference on Electrical and Computer\n  Engineering (ICECE)", "doi": null}
{"id": "http://arxiv.org/abs/1708.00227v1", "guidislink": true, "updated": "2017-08-01T09:52:03Z", "updated_parsed": [2017, 8, 1, 9, 52, 3, 1, 213, 0], "published": "2017-08-01T09:52:03Z", "published_parsed": [2017, 8, 1, 9, 52, 3, 1, 213, 0], "title": "HMM-based Indic Handwritten Word Recognition using Zone Segmentation", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "HMM-based Indic Handwritten Word Recognition using Zone Segmentation"}, "summary": "This paper presents a novel approach towards Indic handwritten word\nrecognition using zone-wise information. Because of complex nature due to\ncompound characters, modifiers, overlapping and touching, etc., character\nsegmentation and recognition is a tedious job in Indic scripts (e.g.\nDevanagari, Bangla, Gurumukhi, and other similar scripts). To avoid character\nsegmentation in such scripts, HMM-based sequence modeling has been used earlier\nin holistic way. This paper proposes an efficient word recognition framework by\nsegmenting the handwritten word images horizontally into three zones (upper,\nmiddle and lower) and recognize the corresponding zones. The main aim of this\nzone segmentation approach is to reduce the number of distinct component\nclasses compared to the total number of classes in Indic scripts. As a result,\nuse of this zone segmentation approach enhances the recognition performance of\nthe system. The components in middle zone where characters are mostly touching\nare recognized using HMM. After the recognition of middle zone, HMM based\nViterbi forced alignment is applied to mark the left and right boundaries of\nthe characters. Next, the residue components, if any, in upper and lower zones\nin their respective boundary are combined to achieve the final word level\nrecognition. Water reservoir feature has been integrated in this framework to\nimprove the zone segmentation and character alignment defects while\nsegmentation. A novel sliding window-based feature, called Pyramid Histogram of\nOriented Gradient (PHOG) is proposed for middle zone recognition. An exhaustive\nexperiment is performed on two Indic scripts namely, Bangla and Devanagari for\nthe performance evaluation. From the experiment, it has been noted that\nproposed zone-wise recognition improves accuracy with respect to the\ntraditional way of Indic word recognition.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents a novel approach towards Indic handwritten word\nrecognition using zone-wise information. Because of complex nature due to\ncompound characters, modifiers, overlapping and touching, etc., character\nsegmentation and recognition is a tedious job in Indic scripts (e.g.\nDevanagari, Bangla, Gurumukhi, and other similar scripts). To avoid character\nsegmentation in such scripts, HMM-based sequence modeling has been used earlier\nin holistic way. This paper proposes an efficient word recognition framework by\nsegmenting the handwritten word images horizontally into three zones (upper,\nmiddle and lower) and recognize the corresponding zones. The main aim of this\nzone segmentation approach is to reduce the number of distinct component\nclasses compared to the total number of classes in Indic scripts. As a result,\nuse of this zone segmentation approach enhances the recognition performance of\nthe system. The components in middle zone where characters are mostly touching\nare recognized using HMM. After the recognition of middle zone, HMM based\nViterbi forced alignment is applied to mark the left and right boundaries of\nthe characters. Next, the residue components, if any, in upper and lower zones\nin their respective boundary are combined to achieve the final word level\nrecognition. Water reservoir feature has been integrated in this framework to\nimprove the zone segmentation and character alignment defects while\nsegmentation. A novel sliding window-based feature, called Pyramid Histogram of\nOriented Gradient (PHOG) is proposed for middle zone recognition. An exhaustive\nexperiment is performed on two Indic scripts namely, Bangla and Devanagari for\nthe performance evaluation. From the experiment, it has been noted that\nproposed zone-wise recognition improves accuracy with respect to the\ntraditional way of Indic word recognition."}, "authors": ["Partha Pratim Roy", "Ayan Kumar Bhunia", "Ayan Das", "Prasenjit Dey", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patcog.2016.04.012", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1708.00227v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1708.00227v1", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Published in Pattern Recognition(2016)", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1708.00227v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1708.00227v1", "journal_reference": "Pattern Recognition, Volume 60, December 2016, Pages 1057-1075", "doi": "10.1016/j.patcog.2016.04.012"}
{"id": "http://arxiv.org/abs/1708.05529v6", "guidislink": true, "updated": "2018-07-30T10:41:30Z", "updated_parsed": [2018, 7, 30, 10, 41, 30, 0, 211, 0], "published": "2017-08-18T07:47:05Z", "published_parsed": [2017, 8, 18, 7, 47, 5, 4, 230, 0], "title": "Word Searching in Scene Image and Video Frame in Multi-Script Scenario\n  using Dynamic Shape Coding", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Word Searching in Scene Image and Video Frame in Multi-Script Scenario\n  using Dynamic Shape Coding"}, "summary": "Retrieval of text information from natural scene images and video frames is a\nchallenging task due to its inherent problems like complex character shapes,\nlow resolution, background noise, etc. Available OCR systems often fail to\nretrieve such information in scene/video frames. Keyword spotting, an\nalternative way to retrieve information, performs efficient text searching in\nsuch scenarios. However, current word spotting techniques in scene/video images\nare script-specific and they are mainly developed for Latin script. This paper\npresents a novel word spotting framework using dynamic shape coding for text\nretrieval in natural scene image and video frames. The framework is designed to\nsearch query keyword from multiple scripts with the help of on-the-fly\nscript-wise keyword generation for the corresponding script. We have used a\ntwo-stage word spotting approach using Hidden Markov Model (HMM) to detect the\ntranslated keyword in a given text line by identifying the script of the line.\nA novel unsupervised dynamic shape coding based scheme has been used to group\nsimilar shape characters to avoid confusion and to improve text alignment.\nNext, the hypotheses locations are verified to improve retrieval performance.\nTo evaluate the proposed system for searching keyword from natural scene image\nand video frames, we have considered two popular Indic scripts such as Bangla\n(Bengali) and Devanagari along with English. Inspired by the zone-wise\nrecognition approach in Indic scripts[1], zone-wise text information has been\nused to improve the traditional word spotting performance in Indic scripts. For\nour experiment, a dataset consisting of images of different scenes and video\nframes of English, Bangla and Devanagari scripts were considered. The results\nobtained showed the effectiveness of our proposed word spotting approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Retrieval of text information from natural scene images and video frames is a\nchallenging task due to its inherent problems like complex character shapes,\nlow resolution, background noise, etc. Available OCR systems often fail to\nretrieve such information in scene/video frames. Keyword spotting, an\nalternative way to retrieve information, performs efficient text searching in\nsuch scenarios. However, current word spotting techniques in scene/video images\nare script-specific and they are mainly developed for Latin script. This paper\npresents a novel word spotting framework using dynamic shape coding for text\nretrieval in natural scene image and video frames. The framework is designed to\nsearch query keyword from multiple scripts with the help of on-the-fly\nscript-wise keyword generation for the corresponding script. We have used a\ntwo-stage word spotting approach using Hidden Markov Model (HMM) to detect the\ntranslated keyword in a given text line by identifying the script of the line.\nA novel unsupervised dynamic shape coding based scheme has been used to group\nsimilar shape characters to avoid confusion and to improve text alignment.\nNext, the hypotheses locations are verified to improve retrieval performance.\nTo evaluate the proposed system for searching keyword from natural scene image\nand video frames, we have considered two popular Indic scripts such as Bangla\n(Bengali) and Devanagari along with English. Inspired by the zone-wise\nrecognition approach in Indic scripts[1], zone-wise text information has been\nused to improve the traditional word spotting performance in Indic scripts. For\nour experiment, a dataset consisting of images of different scenes and video\nframes of English, Bangla and Devanagari scripts were considered. The results\nobtained showed the effectiveness of our proposed word spotting approach."}, "authors": ["Partha Pratim Roy", "Ayan Kumar Bhunia", "Avirup Bhattacharyya", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "arxiv_comment": "Multimedia Tools and Applications, Springer", "links": [{"href": "http://arxiv.org/abs/1708.05529v6", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1708.05529v6", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1708.05529v6", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1708.05529v6", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1410.4013v1", "guidislink": true, "updated": "2014-10-15T11:19:33Z", "updated_parsed": [2014, 10, 15, 11, 19, 33, 2, 288, 0], "published": "2014-10-15T11:19:33Z", "published_parsed": [2014, 10, 15, 11, 19, 33, 2, 288, 0], "title": "A two-pass fuzzy-geno approach to pattern classification", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A two-pass fuzzy-geno approach to pattern classification"}, "summary": "The work presents an extension of the fuzzy approach to 2-D shape recognition\n[1] through refinement of initial or coarse classification decisions under a\ntwo pass approach. In this approach, an unknown pattern is classified by\nrefining possible classification decisions obtained through coarse\nclassification of the same. To build a fuzzy model of a pattern class\nhorizontal and vertical fuzzy partitions on the sample images of the class are\noptimized using genetic algorithm. To make coarse classification decisions\nabout an unknown pattern, the fuzzy representation of the pattern is compared\nwith models of all pattern classes through a specially designed similarity\nmeasure. Coarse classification decisions are refined in the second pass to\nobtain the final classification decision of the unknown pattern. To do so,\noptimized horizontal and vertical fuzzy partitions are again created on certain\nregions of the image frame, specific to each group of similar type of pattern\nclasses. It is observed through experiments that the technique improves the\noverall recognition rate from 86.2%, in the first pass, to 90.4% after the\nsecond pass, with 500 training samples of handwritten digits.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "The work presents an extension of the fuzzy approach to 2-D shape recognition\n[1] through refinement of initial or coarse classification decisions under a\ntwo pass approach. In this approach, an unknown pattern is classified by\nrefining possible classification decisions obtained through coarse\nclassification of the same. To build a fuzzy model of a pattern class\nhorizontal and vertical fuzzy partitions on the sample images of the class are\noptimized using genetic algorithm. To make coarse classification decisions\nabout an unknown pattern, the fuzzy representation of the pattern is compared\nwith models of all pattern classes through a specially designed similarity\nmeasure. Coarse classification decisions are refined in the second pass to\nobtain the final classification decision of the unknown pattern. To do so,\noptimized horizontal and vertical fuzzy partitions are again created on certain\nregions of the image frame, specific to each group of similar type of pattern\nclasses. It is observed through experiments that the technique improves the\noverall recognition rate from 86.2%, in the first pass, to 90.4% after the\nsecond pass, with 500 training samples of handwritten digits."}, "authors": ["Subhadip Basu", "Mahantapas Kundu", "Mita Nasipuri", "Dipak Kumar Basu"], "author_detail": {"name": "Dipak Kumar Basu"}, "author": "Dipak Kumar Basu", "links": [{"href": "http://arxiv.org/abs/1410.4013v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1410.4013v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1410.4013v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1410.4013v1", "arxiv_comment": null, "journal_reference": "Proc. of International Conference on Computer Processing of\n  Bangla, pp. 130-134, Feb-2006, Dhaka", "doi": null}
{"id": "http://arxiv.org/abs/1009.4979v1", "guidislink": true, "updated": "2010-09-25T06:27:49Z", "updated_parsed": [2010, 9, 25, 6, 27, 49, 5, 268, 0], "published": "2010-09-25T06:27:49Z", "published_parsed": [2010, 9, 25, 6, 27, 49, 5, 268, 0], "title": "Smart Bengali Cell Phone Keypad Layout", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Smart Bengali Cell Phone Keypad Layout"}, "summary": "Nowadays cell phone is the most common communicating used by mass people. SMS\nbased communication is a cheap and popular communication method. It is human\ntendency to have the opportunity to write SMS in their mother language. Text\ninput in mother language is more flexible when the alphabets of that language\nare printed on the keypad. Bangla mobile keypad based on phonetics has been\nproposed earlier. But the keypad is not scientific from frequency and\nflexibility point of view. Since it is not a feasible solution in this paper we\nhave proposed an efficient Bengali keypad for cell phone and other cellular\ndevice. The proposed keypad is based on the frequency of the alphabets in\nBengali language and also with the view of structure of human finger movements.\nWe took the two points in count to provide a flexible and fast cell phone\nkeypad.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=50&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Nowadays cell phone is the most common communicating used by mass people. SMS\nbased communication is a cheap and popular communication method. It is human\ntendency to have the opportunity to write SMS in their mother language. Text\ninput in mother language is more flexible when the alphabets of that language\nare printed on the keypad. Bangla mobile keypad based on phonetics has been\nproposed earlier. But the keypad is not scientific from frequency and\nflexibility point of view. Since it is not a feasible solution in this paper we\nhave proposed an efficient Bengali keypad for cell phone and other cellular\ndevice. The proposed keypad is based on the frequency of the alphabets in\nBengali language and also with the view of structure of human finger movements.\nWe took the two points in count to provide a flexible and fast cell phone\nkeypad."}, "authors": ["Md. Abul Kalam Azad", "Rezwana Sharmeen", "Shabbir Ahmad", "S. M. Kamruzzaman"], "author_detail": {"name": "S. M. Kamruzzaman"}, "author": "S. M. Kamruzzaman", "arxiv_comment": "4 Pages, International Conference", "links": [{"href": "http://arxiv.org/abs/1009.4979v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1009.4979v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.HC", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1009.4979v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1009.4979v1", "journal_reference": "Proc. 8th International Conference on Computer and Information\n  Technology (ICCIT 2005), Dhaka, Bangladesh, pp. 1208-1211, Dec. 2005", "doi": null}
{"id": "http://arxiv.org/abs/1707.08385v1", "guidislink": true, "updated": "2017-07-26T11:40:13Z", "updated_parsed": [2017, 7, 26, 11, 40, 13, 2, 207, 0], "published": "2017-07-26T11:40:13Z", "published_parsed": [2017, 7, 26, 11, 40, 13, 2, 207, 0], "title": "A Novel Transfer Learning Approach upon Hindi, Arabic, and Bangla\n  Numerals using Convolutional Neural Networks", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Novel Transfer Learning Approach upon Hindi, Arabic, and Bangla\n  Numerals using Convolutional Neural Networks"}, "summary": "Increased accuracy in predictive models for handwritten character recognition\nwill open up new frontiers for optical character recognition. Major drawbacks\nof predictive machine learning models are headed by the elongated training time\ntaken by some models, and the requirement that training and test data be in the\nsame feature space and consist of the same distribution. In this study, these\nobstacles are minimized by presenting a model for transferring knowledge from\none task to another. This model is presented for the recognition of handwritten\nnumerals in Indic languages. The model utilizes convolutional neural networks\nwith backpropagation for error reduction and dropout for data overfitting. The\noutput performance of the proposed neural network is shown to have closely\nmatched other state-of-the-art methods using only a fraction of time used by\nthe state-of-the-arts.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Increased accuracy in predictive models for handwritten character recognition\nwill open up new frontiers for optical character recognition. Major drawbacks\nof predictive machine learning models are headed by the elongated training time\ntaken by some models, and the requirement that training and test data be in the\nsame feature space and consist of the same distribution. In this study, these\nobstacles are minimized by presenting a model for transferring knowledge from\none task to another. This model is presented for the recognition of handwritten\nnumerals in Indic languages. The model utilizes convolutional neural networks\nwith backpropagation for error reduction and dropout for data overfitting. The\noutput performance of the proposed neural network is shown to have closely\nmatched other state-of-the-art methods using only a fraction of time used by\nthe state-of-the-arts."}, "authors": ["Abdul Kawsar Tushar", "Akm Ashiquzzaman", "Afia Afrin", "Md. Rashedul Islam"], "author_detail": {"name": "Md. Rashedul Islam"}, "author": "Md. Rashedul Islam", "arxiv_comment": "10 pages; 2 figures, 4 tables; conference - International Conference\n  On Computational Vision and Bio Inspired Computing 2017 (http://iccvbic.com/)\n  (accepted)", "links": [{"href": "http://arxiv.org/abs/1707.08385v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1707.08385v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1707.08385v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1707.08385v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1804.04475v1", "guidislink": true, "updated": "2018-04-12T12:46:08Z", "updated_parsed": [2018, 4, 12, 12, 46, 8, 3, 102, 0], "published": "2018-04-12T12:46:08Z", "published_parsed": [2018, 4, 12, 12, 46, 8, 3, 102, 0], "title": "Learning Multilingual Embeddings for Cross-Lingual Information Retrieval\n  in the Presence of Topically Aligned Corpora", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Learning Multilingual Embeddings for Cross-Lingual Information Retrieval\n  in the Presence of Topically Aligned Corpora"}, "summary": "Cross-lingual information retrieval is a challenging task in the absence of\naligned parallel corpora. In this paper, we address this problem by considering\ntopically aligned corpora designed for evaluating an IR setup. To emphasize, we\nneither use any sentence-aligned corpora or document-aligned corpora, nor do we\nuse any language specific resources such as dictionary, thesaurus, or grammar\nrules. Instead, we use an embedding into a common space and learn word\ncorrespondences directly from there. We test our proposed approach for\nbilingual IR on standard FIRE datasets for Bangla, Hindi and English. The\nproposed method is superior to the state-of-the-art method not only for IR\nevaluation measures but also in terms of time requirements. We extend our\nmethod successfully to the trilingual setting.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Cross-lingual information retrieval is a challenging task in the absence of\naligned parallel corpora. In this paper, we address this problem by considering\ntopically aligned corpora designed for evaluating an IR setup. To emphasize, we\nneither use any sentence-aligned corpora or document-aligned corpora, nor do we\nuse any language specific resources such as dictionary, thesaurus, or grammar\nrules. Instead, we use an embedding into a common space and learn word\ncorrespondences directly from there. We test our proposed approach for\nbilingual IR on standard FIRE datasets for Bangla, Hindi and English. The\nproposed method is superior to the state-of-the-art method not only for IR\nevaluation measures but also in terms of time requirements. We extend our\nmethod successfully to the trilingual setting."}, "authors": ["Mitodru Niyogi", "Kripabandhu Ghosh", "Arnab Bhattacharya"], "author_detail": {"name": "Arnab Bhattacharya"}, "author": "Arnab Bhattacharya", "links": [{"href": "http://arxiv.org/abs/1804.04475v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1804.04475v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.IR", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1804.04475v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1804.04475v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1902.11133v1", "guidislink": true, "updated": "2019-02-25T13:52:53Z", "updated_parsed": [2019, 2, 25, 13, 52, 53, 0, 56, 0], "published": "2019-02-25T13:52:53Z", "published_parsed": [2019, 2, 25, 13, 52, 53, 0, 56, 0], "title": "Bengali Handwritten Character Classification using Transfer Learning on\n  Deep Convolutional Neural Network", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bengali Handwritten Character Classification using Transfer Learning on\n  Deep Convolutional Neural Network"}, "summary": "In this paper, we propose a solution which uses state-of-the-art techniques\nin Deep Learning to tackle the problem of Bengali Handwritten Character\nRecognition ( HCR ). Our method uses lesser iterations to train than most other\ncomparable methods. We employ Transfer Learning on ResNet 50, a\nstate-of-the-art deep Convolutional Neural Network Model, pretrained on\nImageNet dataset. We also use other techniques like a modified version of One\nCycle Policy, varying the input image sizes etc. to ensure that our training\noccurs fast. We use the BanglaLekha-Isolated Dataset for evaluation of our\ntechnique which consists of 84 classes (50 Basic, 10 Numerals and 24 Compound\nCharacters). We are able to achieve 96.12% accuracy in just 47 epochs on\nBanglaLekha-Isolated dataset. When comparing our method with that of other\nresearchers, considering number of classes and without using Ensemble Learning,\nthe proposed solution achieves state of the art result for Handwritten Bengali\nCharacter Recognition. Code and weight files are available at\nhttps://github.com/swagato-c/bangla-hwcr-present.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we propose a solution which uses state-of-the-art techniques\nin Deep Learning to tackle the problem of Bengali Handwritten Character\nRecognition ( HCR ). Our method uses lesser iterations to train than most other\ncomparable methods. We employ Transfer Learning on ResNet 50, a\nstate-of-the-art deep Convolutional Neural Network Model, pretrained on\nImageNet dataset. We also use other techniques like a modified version of One\nCycle Policy, varying the input image sizes etc. to ensure that our training\noccurs fast. We use the BanglaLekha-Isolated Dataset for evaluation of our\ntechnique which consists of 84 classes (50 Basic, 10 Numerals and 24 Compound\nCharacters). We are able to achieve 96.12% accuracy in just 47 epochs on\nBanglaLekha-Isolated dataset. When comparing our method with that of other\nresearchers, considering number of classes and without using Ensemble Learning,\nthe proposed solution achieves state of the art result for Handwritten Bengali\nCharacter Recognition. Code and weight files are available at\nhttps://github.com/swagato-c/bangla-hwcr-present."}, "authors": ["Swagato Chatterjee", "Rwik Kumar Dutta", "Debayan Ganguly", "Kingshuk Chatterjee", "Sudipta Roy"], "author_detail": {"name": "Sudipta Roy"}, "author": "Sudipta Roy", "links": [{"href": "http://arxiv.org/abs/1902.11133v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1902.11133v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1902.11133v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1902.11133v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1912.12405v2", "guidislink": true, "updated": "2020-03-16T17:06:44Z", "updated_parsed": [2020, 3, 16, 17, 6, 44, 0, 76, 0], "published": "2019-12-28T05:37:28Z", "published_parsed": [2019, 12, 28, 5, 37, 28, 5, 362, 0], "title": "A Genetic Algorithm based Kernel-size Selection Approach for a\n  Multi-column Convolutional Neural Network", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A Genetic Algorithm based Kernel-size Selection Approach for a\n  Multi-column Convolutional Neural Network"}, "summary": "Deep neural network-based architectures give promising results in various\ndomains including pattern recognition. Finding the optimal combination of the\nhyper-parameters of such a large-sized architecture is tedious and requires a\nlarge number of laboratory experiments. But, identifying the optimal\ncombination of a hyper-parameter or appropriate kernel size for a given\narchitecture of deep learning is always a challenging and tedious task. Here,\nwe introduced a genetic algorithm-based technique to reduce the efforts of\nfinding the optimal combination of a hyper-parameter (kernel size) of a\nconvolutional neural network-based architecture. The method is evaluated on\nthree popular datasets of different handwritten Bangla characters and digits.\nThe implementation of the proposed methodology can be found in the following\nlink: https://github.com/DeepQn/GA-Based-Kernel-Size.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Deep neural network-based architectures give promising results in various\ndomains including pattern recognition. Finding the optimal combination of the\nhyper-parameters of such a large-sized architecture is tedious and requires a\nlarge number of laboratory experiments. But, identifying the optimal\ncombination of a hyper-parameter or appropriate kernel size for a given\narchitecture of deep learning is always a challenging and tedious task. Here,\nwe introduced a genetic algorithm-based technique to reduce the efforts of\nfinding the optimal combination of a hyper-parameter (kernel size) of a\nconvolutional neural network-based architecture. The method is evaluated on\nthree popular datasets of different handwritten Bangla characters and digits.\nThe implementation of the proposed methodology can be found in the following\nlink: https://github.com/DeepQn/GA-Based-Kernel-Size."}, "authors": ["Animesh Singh", "Sandip Saha", "Ritesh Sarkhel", "Mahantapas Kundu", "Mita Nasipuri", "Nibaran Das"], "author_detail": {"name": "Nibaran Das"}, "author": "Nibaran Das", "links": [{"href": "http://arxiv.org/abs/1912.12405v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1912.12405v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1912.12405v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1912.12405v2", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2003.07428v1", "guidislink": true, "updated": "2020-03-16T20:19:21Z", "updated_parsed": [2020, 3, 16, 20, 19, 21, 0, 76, 0], "published": "2020-03-16T20:19:21Z", "published_parsed": [2020, 3, 16, 20, 19, 21, 0, 76, 0], "title": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Developing a Multilingual Annotated Corpus of Misogyny and Aggression"}, "summary": "In this paper, we discuss the development of a multilingual annotated corpus\nof misogyny and aggression in Indian English, Hindi, and Indian Bangla as part\nof a project on studying and automatically identifying misogyny and communalism\non social media (the ComMA Project). The dataset is collected from comments on\nYouTube videos and currently contains a total of over 20,000 comments. The\ncomments are annotated at two levels - aggression (overtly aggressive, covertly\naggressive, and non-aggressive) and misogyny (gendered and non-gendered). We\ndescribe the process of data collection, the tagset used for annotation, and\nissues and challenges faced during the process of annotation. Finally, we\ndiscuss the results of the baseline experiments conducted to develop a\nclassifier for misogyny in the three languages.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In this paper, we discuss the development of a multilingual annotated corpus\nof misogyny and aggression in Indian English, Hindi, and Indian Bangla as part\nof a project on studying and automatically identifying misogyny and communalism\non social media (the ComMA Project). The dataset is collected from comments on\nYouTube videos and currently contains a total of over 20,000 comments. The\ncomments are annotated at two levels - aggression (overtly aggressive, covertly\naggressive, and non-aggressive) and misogyny (gendered and non-gendered). We\ndescribe the process of data collection, the tagset used for annotation, and\nissues and challenges faced during the process of annotation. Finally, we\ndiscuss the results of the baseline experiments conducted to develop a\nclassifier for misogyny in the three languages."}, "authors": ["Shiladitya Bhattacharya", "Siddharth Singh", "Ritesh Kumar", "Akanksha Bansal", "Akash Bhagat", "Yogesh Dawer", "Bornini Lahiri", "Atul Kr. Ojha"], "author_detail": {"name": "Atul Kr. Ojha"}, "author": "Atul Kr. Ojha", "arxiv_comment": "Submitted for review to Second Workshop on Trolling, Aggression and\n  Cyberbullying (TRAC 2020)", "links": [{"href": "http://arxiv.org/abs/2003.07428v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2003.07428v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2003.07428v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2003.07428v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2003.08384v5", "guidislink": true, "updated": "2021-01-05T18:11:50Z", "updated_parsed": [2021, 1, 5, 18, 11, 50, 1, 5, 0], "published": "2020-03-18T17:58:05Z", "published_parsed": [2020, 3, 18, 17, 58, 5, 2, 78, 0], "title": "Confronting the Constraints for Optical Character Segmentation from\n  Printed Bangla Text Image", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Confronting the Constraints for Optical Character Segmentation from\n  Printed Bangla Text Image"}, "summary": "In a world of digitization, optical character recognition holds the\nautomation to written history. Optical character recognition system basically\nconverts printed images into editable texts for better storage and usability.\nTo be completely functional, the system needs to go through some crucial\nmethods such as pre-processing and segmentation. Pre-processing helps printed\ndata to be noise free and gets rid of skewness efficiently whereas segmentation\nhelps the image fragment into line, word and character precisely for better\nconversion. These steps hold the door to better accuracy and consistent results\nfor a printed image to be ready for conversion. Our proposed algorithm is able\nto segment characters both from ideal and non-ideal cases of scanned or\ncaptured images giving a sustainable outcome. The implementation of our work is\nprovided here: https://cutt.ly/rgdfBIa", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "In a world of digitization, optical character recognition holds the\nautomation to written history. Optical character recognition system basically\nconverts printed images into editable texts for better storage and usability.\nTo be completely functional, the system needs to go through some crucial\nmethods such as pre-processing and segmentation. Pre-processing helps printed\ndata to be noise free and gets rid of skewness efficiently whereas segmentation\nhelps the image fragment into line, word and character precisely for better\nconversion. These steps hold the door to better accuracy and consistent results\nfor a printed image to be ready for conversion. Our proposed algorithm is able\nto segment characters both from ideal and non-ideal cases of scanned or\ncaptured images giving a sustainable outcome. The implementation of our work is\nprovided here: https://cutt.ly/rgdfBIa"}, "authors": ["Abu Saleh Md. Abir", "Sanjana Rahman", "Samia Ellin", "Maisha Farzana", "Md Hridoy Manik", "Chowdhury Rafeed Rahman"], "author_detail": {"name": "Chowdhury Rafeed Rahman"}, "author": "Chowdhury Rafeed Rahman", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1145/3428363.3428367", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/2003.08384v5", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2003.08384v5", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2003.08384v5", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2003.08384v5", "arxiv_comment": null, "journal_reference": null, "doi": "10.1145/3428363.3428367"}
{"id": "http://arxiv.org/abs/2004.01551v1", "guidislink": true, "updated": "2020-04-03T13:20:12Z", "updated_parsed": [2020, 4, 3, 13, 20, 12, 4, 94, 0], "published": "2020-04-03T13:20:12Z", "published_parsed": [2020, 4, 3, 13, 20, 12, 4, 94, 0], "title": "Sparse Concept Coded Tetrolet Transform for Unconstrained Odia Character\n  Recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Sparse Concept Coded Tetrolet Transform for Unconstrained Odia Character\n  Recognition"}, "summary": "Feature representation in the form of spatio-spectral decomposition is one of\nthe robust techniques adopted in automatic handwritten character recognition\nsystems. In this regard, we propose a new image representation approach for\nunconstrained handwritten alphanumeric characters using sparse concept coded\nTetrolets. Tetrolets, which does not use fixed dyadic square blocks for\nspectral decomposition like conventional wavelets, preserve the localized\nvariations in handwritings by adopting tetrominoes those capture the shape\ngeometry. The sparse concept coding of low entropy Tetrolet representation is\nfound to extract the important hidden information (concept) for superior\npattern discrimination. Large scale experimentation using ten databases in six\ndifferent scripts (Bangla, Devanagari, Odia, English, Arabic and Telugu) has\nbeen performed. The proposed feature representation along with standard\nclassifiers such as random forest, support vector machine (SVM), nearest\nneighbor and modified quadratic discriminant function (MQDF) is found to\nachieve state-of-the-art recognition performance in all the databases, viz.\n99.40% (MNIST); 98.72% and 93.24% (IITBBS); 99.38% and 99.22% (ISI Kolkata).\nThe proposed OCR system is shown to perform better than other sparse based\ntechniques such as PCA, SparsePCA and SparseLDA, as well as better than\nexisting transforms (Wavelet, Slantlet and Stockwell).", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Feature representation in the form of spatio-spectral decomposition is one of\nthe robust techniques adopted in automatic handwritten character recognition\nsystems. In this regard, we propose a new image representation approach for\nunconstrained handwritten alphanumeric characters using sparse concept coded\nTetrolets. Tetrolets, which does not use fixed dyadic square blocks for\nspectral decomposition like conventional wavelets, preserve the localized\nvariations in handwritings by adopting tetrominoes those capture the shape\ngeometry. The sparse concept coding of low entropy Tetrolet representation is\nfound to extract the important hidden information (concept) for superior\npattern discrimination. Large scale experimentation using ten databases in six\ndifferent scripts (Bangla, Devanagari, Odia, English, Arabic and Telugu) has\nbeen performed. The proposed feature representation along with standard\nclassifiers such as random forest, support vector machine (SVM), nearest\nneighbor and modified quadratic discriminant function (MQDF) is found to\nachieve state-of-the-art recognition performance in all the databases, viz.\n99.40% (MNIST); 98.72% and 93.24% (IITBBS); 99.38% and 99.22% (ISI Kolkata).\nThe proposed OCR system is shown to perform better than other sparse based\ntechniques such as PCA, SparsePCA and SparseLDA, as well as better than\nexisting transforms (Wavelet, Slantlet and Stockwell)."}, "authors": ["Kalyan S Dash", "N B Puhan", "G Panda"], "author_detail": {"name": "G Panda"}, "author": "G Panda", "links": [{"href": "http://arxiv.org/abs/2004.01551v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2004.01551v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "eess.IV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2004.01551v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2004.01551v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2009.07435v1", "guidislink": true, "updated": "2020-09-16T02:50:03Z", "updated_parsed": [2020, 9, 16, 2, 50, 3, 2, 260, 0], "published": "2020-09-16T02:50:03Z", "published_parsed": [2020, 9, 16, 2, 50, 3, 2, 260, 0], "title": "A New Approach for Texture based Script Identification At Block Level\n  using Quad Tree Decomposition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A New Approach for Texture based Script Identification At Block Level\n  using Quad Tree Decomposition"}, "summary": "A considerable amount of success has been achieved in developing monolingual\nOCR systems for Indic scripts. But in a country like India, where multi-script\nscenario is prevalent, identifying scripts beforehand becomes obligatory. In\nthis paper, we present the significance of Gabor wavelets filters in extracting\ndirectional energy and entropy distributions for 11 official handwritten\nscripts namely, Bangla, Devanagari, Gujarati, Gurumukhi, Kannada, Malayalam,\nOriya, Tamil, Telugu, Urdu and Roman. The experimentation is conducted at block\nlevel based on a quad-tree decomposition approach and evaluated using six\ndifferent well-known classifiers. Finally, the best identification accuracy of\n96.86% has been achieved by Multi Layer Perceptron (MLP) classifier for 3-fold\ncross validation at level-2 decomposition. The results serve to establish the\nefficacy of the present approach to the classification of handwritten Indic\nscripts", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "A considerable amount of success has been achieved in developing monolingual\nOCR systems for Indic scripts. But in a country like India, where multi-script\nscenario is prevalent, identifying scripts beforehand becomes obligatory. In\nthis paper, we present the significance of Gabor wavelets filters in extracting\ndirectional energy and entropy distributions for 11 official handwritten\nscripts namely, Bangla, Devanagari, Gujarati, Gurumukhi, Kannada, Malayalam,\nOriya, Tamil, Telugu, Urdu and Roman. The experimentation is conducted at block\nlevel based on a quad-tree decomposition approach and evaluated using six\ndifferent well-known classifiers. Finally, the best identification accuracy of\n96.86% has been achieved by Multi Layer Perceptron (MLP) classifier for 3-fold\ncross validation at level-2 decomposition. The results serve to establish the\nefficacy of the present approach to the classification of handwritten Indic\nscripts"}, "authors": ["Pawan Kumar Singh", "Supratim Das", "Ram Sarkar", "Mita Nasipuri"], "author_detail": {"name": "Mita Nasipuri"}, "author": "Mita Nasipuri", "arxiv_comment": "13 pages, 5 figures, conference", "links": [{"href": "http://arxiv.org/abs/2009.07435v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2009.07435v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2009.07435v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2009.07435v1", "journal_reference": "7th International Conference on Advances in Communication, Network\n  and Computing (CNC), pp. 247-259, 2016", "doi": null}
{"id": "http://arxiv.org/abs/2010.03065v1", "guidislink": true, "updated": "2020-10-06T22:33:58Z", "updated_parsed": [2020, 10, 6, 22, 33, 58, 1, 280, 0], "published": "2020-10-06T22:33:58Z", "published_parsed": [2020, 10, 6, 22, 33, 58, 1, 280, 0], "title": "Anubhuti -- An annotated dataset for emotional analysis of Bengali short\n  stories", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Anubhuti -- An annotated dataset for emotional analysis of Bengali short\n  stories"}, "summary": "Thousands of short stories and articles are being written in many different\nlanguages all around the world today. Bengali, or Bangla, is the second highest\nspoken language in India after Hindi and is the national language of the\ncountry of Bangladesh. This work reports in detail the creation of Anubhuti --\nthe first and largest text corpus for analyzing emotions expressed by writers\nof Bengali short stories. We explain the data collection methods, the manual\nannotation process and the resulting high inter-annotator agreement of the\ndataset due to the linguistic expertise of the annotators and the clear\nmethodology of labelling followed. We also address some of the challenges faced\nin the collection of raw data and annotation process of a low resource language\nlike Bengali. We have verified the performance of our dataset with baseline\nMachine Learning as well as a Deep Learning model for emotion classification\nand have found that these standard models have a high accuracy and relevant\nfeature selection on Anubhuti. In addition, we also explain how this dataset\ncan be of interest to linguists and data analysts to study the flow of emotions\nas expressed by writers of Bengali literature.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Thousands of short stories and articles are being written in many different\nlanguages all around the world today. Bengali, or Bangla, is the second highest\nspoken language in India after Hindi and is the national language of the\ncountry of Bangladesh. This work reports in detail the creation of Anubhuti --\nthe first and largest text corpus for analyzing emotions expressed by writers\nof Bengali short stories. We explain the data collection methods, the manual\nannotation process and the resulting high inter-annotator agreement of the\ndataset due to the linguistic expertise of the annotators and the clear\nmethodology of labelling followed. We also address some of the challenges faced\nin the collection of raw data and annotation process of a low resource language\nlike Bengali. We have verified the performance of our dataset with baseline\nMachine Learning as well as a Deep Learning model for emotion classification\nand have found that these standard models have a high accuracy and relevant\nfeature selection on Anubhuti. In addition, we also explain how this dataset\ncan be of interest to linguists and data analysts to study the flow of emotions\nas expressed by writers of Bengali literature."}, "authors": ["Aditya Pal", "Bhaskar Karn"], "author_detail": {"name": "Bhaskar Karn"}, "author": "Bhaskar Karn", "arxiv_comment": "4 pages, 6 figures", "links": [{"href": "http://arxiv.org/abs/2010.03065v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.03065v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.03065v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.03065v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2010.08066v1", "guidislink": true, "updated": "2020-10-15T23:24:15Z", "updated_parsed": [2020, 10, 15, 23, 24, 15, 3, 289, 0], "published": "2020-10-15T23:24:15Z", "published_parsed": [2020, 10, 15, 23, 24, 15, 3, 289, 0], "title": "TextMage: The Automated Bangla Caption Generator Based On Deep Learning", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "TextMage: The Automated Bangla Caption Generator Based On Deep Learning"}, "summary": "Neural Networks and Deep Learning have seen an upsurge of research in the\npast decade due to the improved results. Generates text from the given image is\na crucial task that requires the combination of both sectors which are computer\nvision and natural language processing in order to understand an image and\nrepresent it using a natural language. However existing works have all been\ndone on a particular lingual domain and on the same set of data. This leads to\nthe systems being developed to perform poorly on images that belong to specific\nlocales' geographical context. TextMage is a system that is capable of\nunderstanding visual scenes that belong to the Bangladeshi geographical context\nand use its knowledge to represent what it understands in Bengali. Hence, we\nhave trained a model on our previously developed and published dataset named\nBanglaLekhaImageCaptions. This dataset contains 9,154 images along with two\nannotations for each image. In order to access performance, the proposed model\nhas been implemented and evaluated.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=60&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Neural Networks and Deep Learning have seen an upsurge of research in the\npast decade due to the improved results. Generates text from the given image is\na crucial task that requires the combination of both sectors which are computer\nvision and natural language processing in order to understand an image and\nrepresent it using a natural language. However existing works have all been\ndone on a particular lingual domain and on the same set of data. This leads to\nthe systems being developed to perform poorly on images that belong to specific\nlocales' geographical context. TextMage is a system that is capable of\nunderstanding visual scenes that belong to the Bangladeshi geographical context\nand use its knowledge to represent what it understands in Bengali. Hence, we\nhave trained a model on our previously developed and published dataset named\nBanglaLekhaImageCaptions. This dataset contains 9,154 images along with two\nannotations for each image. In order to access performance, the proposed model\nhas been implemented and evaluated."}, "authors": ["Abrar Hasin Kamal", "Md. Asifuzzaman Jishan", "Nafees Mansoor"], "author_detail": {"name": "Nafees Mansoor"}, "author": "Nafees Mansoor", "arxiv_comment": "5 pages", "links": [{"href": "http://arxiv.org/abs/2010.08066v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2010.08066v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2010.08066v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2010.08066v1", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1712.06908v2", "guidislink": true, "updated": "2018-01-28T15:10:48Z", "updated_parsed": [2018, 1, 28, 15, 10, 48, 6, 28, 0], "published": "2017-12-19T13:12:29Z", "published_parsed": [2017, 12, 19, 13, 12, 29, 1, 353, 0], "title": "Cross-language Framework for Word Recognition and Spotting of Indic\n  Scripts", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Cross-language Framework for Word Recognition and Spotting of Indic\n  Scripts"}, "summary": "Handwritten word recognition and spotting of low-resource scripts are\ndifficult as sufficient training data is not available and it is often\nexpensive for collecting data of such scripts. This paper presents a novel\ncross language platform for handwritten word recognition and spotting for such\nlow-resource scripts where training is performed with a sufficiently large\ndataset of an available script (considered as source script) and testing is\ndone on other scripts (considered as target script). Training with one source\nscript and testing with another script to have a reasonable result is not easy\nin handwriting domain due to the complex nature of handwriting variability\namong scripts. Also it is difficult in mapping between source and target\ncharacters when they appear in cursive word images. The proposed Indic cross\nlanguage framework exploits a large resource of dataset for training and uses\nit for recognizing and spotting text of other target scripts where sufficient\namount of training data is not available. Since, Indic scripts are mostly\nwritten in 3 zones, namely, upper, middle and lower, we employ zone-wise\ncharacter (or component) mapping for efficient learning purpose. The\nperformance of our cross-language framework depends on the extent of similarity\nbetween the source and target scripts. Hence, we devise an entropy based script\nsimilarity score using source to target character mapping that will provide a\nfeasibility of cross language transcription. We have tested our approach in\nthree Indic scripts, namely, Bangla, Devanagari and Gurumukhi, and the\ncorresponding results are reported.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Handwritten word recognition and spotting of low-resource scripts are\ndifficult as sufficient training data is not available and it is often\nexpensive for collecting data of such scripts. This paper presents a novel\ncross language platform for handwritten word recognition and spotting for such\nlow-resource scripts where training is performed with a sufficiently large\ndataset of an available script (considered as source script) and testing is\ndone on other scripts (considered as target script). Training with one source\nscript and testing with another script to have a reasonable result is not easy\nin handwriting domain due to the complex nature of handwriting variability\namong scripts. Also it is difficult in mapping between source and target\ncharacters when they appear in cursive word images. The proposed Indic cross\nlanguage framework exploits a large resource of dataset for training and uses\nit for recognizing and spotting text of other target scripts where sufficient\namount of training data is not available. Since, Indic scripts are mostly\nwritten in 3 zones, namely, upper, middle and lower, we employ zone-wise\ncharacter (or component) mapping for efficient learning purpose. The\nperformance of our cross-language framework depends on the extent of similarity\nbetween the source and target scripts. Hence, we devise an entropy based script\nsimilarity score using source to target character mapping that will provide a\nfeasibility of cross language transcription. We have tested our approach in\nthree Indic scripts, namely, Bangla, Devanagari and Gurumukhi, and the\ncorresponding results are reported."}, "authors": ["Ayan Kumar Bhunia", "Partha Pratim Roy", "Akash Mohta", "Umapada Pal"], "author_detail": {"name": "Umapada Pal"}, "author": "Umapada Pal", "links": [{"title": "doi", "href": "http://dx.doi.org/10.1016/j.patcog.2018.01.034", "rel": "related", "type": "text/html"}, {"href": "http://arxiv.org/abs/1712.06908v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1712.06908v2", "rel": "related", "type": "application/pdf"}], "arxiv_comment": "Accepted in Pattern Recognition, Elsevier(2018)", "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1712.06908v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1712.06908v2", "journal_reference": null, "doi": "10.1016/j.patcog.2018.01.034"}
{"id": "http://arxiv.org/abs/1804.06254v1", "guidislink": true, "updated": "2018-04-17T13:52:59Z", "updated_parsed": [2018, 4, 17, 13, 52, 59, 1, 107, 0], "published": "2018-04-17T13:52:59Z", "published_parsed": [2018, 4, 17, 13, 52, 59, 1, 107, 0], "title": "Synthetic data generation for Indic handwritten text recognition", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Synthetic data generation for Indic handwritten text recognition"}, "summary": "This paper presents a novel approach to generate synthetic dataset for\nhandwritten word recognition systems. It is difficult to recognize handwritten\nscripts for which sufficient training data is not readily available or it may\nbe expensive to collect such data. Hence, it becomes hard to train recognition\nsystems owing to lack of proper dataset. To overcome such problems, synthetic\ndata could be used to create or expand the existing training dataset to improve\nrecognition performance. Any available digital data from online newspaper and\nsuch sources can be used to generate synthetic data. In this paper, we propose\nto add distortion/deformation to digital data in such a way that the underlying\npattern is preserved, so that the image so produced bears a close similarity to\nactual handwritten samples. The images thus produced can be used independently\nto train the system or be combined with natural handwritten data to augment the\noriginal dataset and improve the recognition system. We experimented using\nsynthetic data to improve the recognition accuracy of isolated characters and\nwords. The framework is tested on 2 Indic scripts - Devanagari (Hindi) and\nBengali (Bangla), for numeral, character and word recognition. We have obtained\nencouraging results from the experiment. Finally, the experiment with Latin\ntext verifies the utility of the approach.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "This paper presents a novel approach to generate synthetic dataset for\nhandwritten word recognition systems. It is difficult to recognize handwritten\nscripts for which sufficient training data is not readily available or it may\nbe expensive to collect such data. Hence, it becomes hard to train recognition\nsystems owing to lack of proper dataset. To overcome such problems, synthetic\ndata could be used to create or expand the existing training dataset to improve\nrecognition performance. Any available digital data from online newspaper and\nsuch sources can be used to generate synthetic data. In this paper, we propose\nto add distortion/deformation to digital data in such a way that the underlying\npattern is preserved, so that the image so produced bears a close similarity to\nactual handwritten samples. The images thus produced can be used independently\nto train the system or be combined with natural handwritten data to augment the\noriginal dataset and improve the recognition system. We experimented using\nsynthetic data to improve the recognition accuracy of isolated characters and\nwords. The framework is tested on 2 Indic scripts - Devanagari (Hindi) and\nBengali (Bangla), for numeral, character and word recognition. We have obtained\nencouraging results from the experiment. Finally, the experiment with Latin\ntext verifies the utility of the approach."}, "authors": ["Partha Pratim Roy", "Akash Mohta", "Bidyut B. Chaudhuri"], "author_detail": {"name": "Bidyut B. Chaudhuri"}, "author": "Bidyut B. Chaudhuri", "links": [{"href": "http://arxiv.org/abs/1804.06254v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1804.06254v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1804.06254v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1804.06254v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1807.06772v1", "guidislink": true, "updated": "2018-07-18T04:29:20Z", "updated_parsed": [2018, 7, 18, 4, 29, 20, 2, 199, 0], "published": "2018-07-18T04:29:20Z", "published_parsed": [2018, 7, 18, 4, 29, 20, 2, 199, 0], "title": "Bag-of-Visual-Words for Signature-Based Multi-Script Document Retrieval", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Bag-of-Visual-Words for Signature-Based Multi-Script Document Retrieval"}, "summary": "An end-to-end architecture for multi-script document retrieval using\nhandwritten signatures is proposed in this paper. The user supplies a query\nsignature sample and the system exclusively returns a set of documents that\ncontain the query signature. In the first stage, a component-wise\nclassification technique separates the potential signature components from all\nother components. A bag-of-visual-words powered by SIFT descriptors in a\npatch-based framework is proposed to compute the features and a Support Vector\nMachine (SVM)-based classifier was used to separate signatures from the\ndocuments. In the second stage, features from the foreground (i.e. signature\nstrokes) and the background spatial information (i.e. background loops,\nreservoirs etc.) were combined to characterize the signature object to match\nwith the query signature. Finally, three distance measures were used to match a\nquery signature with the signature present in target documents for retrieval.\nThe `Tobacco' document database and an Indian script database containing 560\ndocuments of Devanagari (Hindi) and Bangla scripts were used for the\nperformance evaluation. The proposed system was also tested on noisy documents\nand promising results were obtained. A comparative study shows that the\nproposed method outperforms the state-of-the-art approaches.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "An end-to-end architecture for multi-script document retrieval using\nhandwritten signatures is proposed in this paper. The user supplies a query\nsignature sample and the system exclusively returns a set of documents that\ncontain the query signature. In the first stage, a component-wise\nclassification technique separates the potential signature components from all\nother components. A bag-of-visual-words powered by SIFT descriptors in a\npatch-based framework is proposed to compute the features and a Support Vector\nMachine (SVM)-based classifier was used to separate signatures from the\ndocuments. In the second stage, features from the foreground (i.e. signature\nstrokes) and the background spatial information (i.e. background loops,\nreservoirs etc.) were combined to characterize the signature object to match\nwith the query signature. Finally, three distance measures were used to match a\nquery signature with the signature present in target documents for retrieval.\nThe `Tobacco' document database and an Indian script database containing 560\ndocuments of Devanagari (Hindi) and Bangla scripts were used for the\nperformance evaluation. The proposed system was also tested on noisy documents\nand promising results were obtained. A comparative study shows that the\nproposed method outperforms the state-of-the-art approaches."}, "authors": ["Ranju Mandal", "Partha Pratim Roy", "Umapada Pal", "Michael Blumenstein"], "author_detail": {"name": "Michael Blumenstein"}, "author": "Michael Blumenstein", "links": [{"href": "http://arxiv.org/abs/1807.06772v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1807.06772v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CV", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1807.06772v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1807.06772v1", "arxiv_comment": null, "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/1811.08816v2", "guidislink": true, "updated": "2019-07-22T11:02:06Z", "updated_parsed": [2019, 7, 22, 11, 2, 6, 0, 203, 0], "published": "2018-11-21T16:36:08Z", "published_parsed": [2018, 11, 21, 16, 36, 8, 2, 325, 0], "title": "Learning cross-lingual phonological and orthagraphic adaptations: a case\n  study in improving neural machine translation between low-resource languages", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Learning cross-lingual phonological and orthagraphic adaptations: a case\n  study in improving neural machine translation between low-resource languages"}, "summary": "Out-of-vocabulary (OOV) words can pose serious challenges for machine\ntranslation (MT) tasks, and in particular, for low-resource language (LRL)\npairs, i.e., language pairs for which few or no parallel corpora exist. Our\nwork adapts variants of seq2seq models to perform transduction of such words\nfrom Hindi to Bhojpuri (an LRL instance), learning from a set of cognate pairs\nbuilt from a bilingual dictionary of Hindi--Bhojpuri words. We demonstrate that\nour models can be effectively used for language pairs that have limited\nparallel corpora; our models work at the character level to grasp phonetic and\northographic similarities across multiple types of word adaptations, whether\nsynchronic or diachronic, loan words or cognates. We describe the training\naspects of several character level NMT systems that we adapted to this task and\ncharacterize their typical errors. Our method improves BLEU score by 6.3 on the\nHindi-to-Bhojpuri translation task. Further, we show that such transductions\ncan generalize well to other languages by applying it successfully to Hindi --\nBangla cognate pairs. Our work can be seen as an important step in the process\nof: (i) resolving the OOV words problem arising in MT tasks, (ii) creating\neffective parallel corpora for resource-constrained languages, and (iii)\nleveraging the enhanced semantic knowledge captured by word-level embeddings to\nperform character-level tasks.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Out-of-vocabulary (OOV) words can pose serious challenges for machine\ntranslation (MT) tasks, and in particular, for low-resource language (LRL)\npairs, i.e., language pairs for which few or no parallel corpora exist. Our\nwork adapts variants of seq2seq models to perform transduction of such words\nfrom Hindi to Bhojpuri (an LRL instance), learning from a set of cognate pairs\nbuilt from a bilingual dictionary of Hindi--Bhojpuri words. We demonstrate that\nour models can be effectively used for language pairs that have limited\nparallel corpora; our models work at the character level to grasp phonetic and\northographic similarities across multiple types of word adaptations, whether\nsynchronic or diachronic, loan words or cognates. We describe the training\naspects of several character level NMT systems that we adapted to this task and\ncharacterize their typical errors. Our method improves BLEU score by 6.3 on the\nHindi-to-Bhojpuri translation task. Further, we show that such transductions\ncan generalize well to other languages by applying it successfully to Hindi --\nBangla cognate pairs. Our work can be seen as an important step in the process\nof: (i) resolving the OOV words problem arising in MT tasks, (ii) creating\neffective parallel corpora for resource-constrained languages, and (iii)\nleveraging the enhanced semantic knowledge captured by word-level embeddings to\nperform character-level tasks."}, "authors": ["Saurav Jha", "Akhilesh Sudhakar", "Anil Kumar Singh"], "author_detail": {"name": "Anil Kumar Singh"}, "author": "Anil Kumar Singh", "arxiv_comment": "47 pages, 4 figures, 21 tables (including Appendices)", "links": [{"href": "http://arxiv.org/abs/1811.08816v2", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/1811.08816v2", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/1811.08816v2", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/1811.08816v2", "journal_reference": null, "doi": null}
{"id": "http://arxiv.org/abs/2012.14353v1", "guidislink": true, "updated": "2020-12-28T16:46:03Z", "updated_parsed": [2020, 12, 28, 16, 46, 3, 0, 363, 0], "published": "2020-12-28T16:46:03Z", "published_parsed": [2020, 12, 28, 16, 46, 3, 0, 363, 0], "title": "DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced\n  Bengali Language", "title_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced\n  Bengali Language"}, "summary": "Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices, but also\nenables people to express anti-social behavior like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behavior analysis, by predicting the\ncontexts mostly for highly-resourced languages like English. However, some\nlanguages such as Bengali are under-resourced that lack of computational\nresources for natural language processing(NLP). In this paper, we propose an\nexplainable approach for hate speech detection from under-resourced Bengali\nlanguage, which we called DeepHateExplainer. In our approach, Bengali texts are\nfirst comprehensively preprocessed, before classifying them into political,\npersonal, geopolitical, and religious hates, by employing neural ensemble of\ndifferent transformer-based neural architectures(i.e., monolingual Bangla\nBERT-base, multilingual BERT-cased and uncased, and XLM-RoBERTa), followed by\nidentifying important terms with sensitivity analysis and layer-wise relevance\npropagation(LRP) to provide human-interpretable explanations. Evaluations\nagainst several machine learning~(linear and tree-based models) and deep neural\nnetworks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines\nyield F1 scores of 84%, 90%, 88%, and 88%, for political, personal,\ngeopolitical, and religious hates, respectively, during 3-fold cross-validation\ntests.", "summary_detail": {"type": "text/plain", "language": null, "base": "http://export.arxiv.org/api/query?search_query=bangla&id_list=&start=70&max_results=10&sortBy=relevance&sortOrder=descending", "value": "Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices, but also\nenables people to express anti-social behavior like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behavior analysis, by predicting the\ncontexts mostly for highly-resourced languages like English. However, some\nlanguages such as Bengali are under-resourced that lack of computational\nresources for natural language processing(NLP). In this paper, we propose an\nexplainable approach for hate speech detection from under-resourced Bengali\nlanguage, which we called DeepHateExplainer. In our approach, Bengali texts are\nfirst comprehensively preprocessed, before classifying them into political,\npersonal, geopolitical, and religious hates, by employing neural ensemble of\ndifferent transformer-based neural architectures(i.e., monolingual Bangla\nBERT-base, multilingual BERT-cased and uncased, and XLM-RoBERTa), followed by\nidentifying important terms with sensitivity analysis and layer-wise relevance\npropagation(LRP) to provide human-interpretable explanations. Evaluations\nagainst several machine learning~(linear and tree-based models) and deep neural\nnetworks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines\nyield F1 scores of 84%, 90%, 88%, and 88%, for political, personal,\ngeopolitical, and religious hates, respectively, during 3-fold cross-validation\ntests."}, "authors": ["Md. Rezaul Karim", "Sumon Kanti Dey", "Bharathi Raja Chakravarthi"], "author_detail": {"name": "Bharathi Raja Chakravarthi"}, "author": "Bharathi Raja Chakravarthi", "arxiv_comment": "Extended version of this paper is currently under review in the IEEE\n  Access journal", "links": [{"href": "http://arxiv.org/abs/2012.14353v1", "rel": "alternate", "type": "text/html"}, {"title": "pdf", "href": "http://arxiv.org/pdf/2012.14353v1", "rel": "related", "type": "application/pdf"}], "arxiv_primary_category": {"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom"}, "tags": [{"term": "cs.CL", "scheme": "http://arxiv.org/schemas/atom", "label": null}, {"term": "cs.LG", "scheme": "http://arxiv.org/schemas/atom", "label": null}], "pdf_url": "http://arxiv.org/pdf/2012.14353v1", "affiliation": "None", "arxiv_url": "http://arxiv.org/abs/2012.14353v1", "journal_reference": null, "doi": null}
